{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5351886540005352,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010703773080010704,
      "grad_norm": 8.051277160644531,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.6634620428085327,
      "logits/rejected": 1.6339889764785767,
      "logps/chosen": -154.83262634277344,
      "logps/rejected": -68.8427734375,
      "loss": 0.6906611442565918,
      "rewards/accuracies": 0.3375000059604645,
      "rewards/chosen": 0.0038951016031205654,
      "rewards/margins": 0.005355882458388805,
      "rewards/rejected": -0.0014607814373448491,
      "step": 10
    },
    {
      "epoch": 0.02140754616002141,
      "grad_norm": 8.103742599487305,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.6807512044906616,
      "logits/rejected": 1.6834901571273804,
      "logps/chosen": -172.0310516357422,
      "logps/rejected": -69.37297058105469,
      "loss": 0.6950807094573974,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": -0.00255882297642529,
      "rewards/margins": -0.0032169297337532043,
      "rewards/rejected": 0.0006581068737432361,
      "step": 20
    },
    {
      "epoch": 0.03211131924003211,
      "grad_norm": 9.027518272399902,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.7286850214004517,
      "logits/rejected": 1.7165313959121704,
      "logps/chosen": -156.46807861328125,
      "logps/rejected": -68.60604858398438,
      "loss": 0.6947118282318115,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00559225445613265,
      "rewards/margins": -0.002517533488571644,
      "rewards/rejected": -0.0030747223645448685,
      "step": 30
    },
    {
      "epoch": 0.04281509232004282,
      "grad_norm": 7.641145706176758,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.6941430568695068,
      "logits/rejected": 1.6695566177368164,
      "logps/chosen": -163.2023468017578,
      "logps/rejected": -68.39588928222656,
      "loss": 0.6940316677093505,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00019513629376888275,
      "rewards/margins": -0.0010265589226037264,
      "rewards/rejected": 0.0008314229780808091,
      "step": 40
    },
    {
      "epoch": 0.05351886540005352,
      "grad_norm": 7.41262149810791,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.6595462560653687,
      "logits/rejected": 1.6949503421783447,
      "logps/chosen": -164.45040893554688,
      "logps/rejected": -69.53597259521484,
      "loss": 0.6935943603515625,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.0018275268375873566,
      "rewards/margins": -0.00024599971948191524,
      "rewards/rejected": 0.0020735259167850018,
      "step": 50
    },
    {
      "epoch": 0.06422263848006422,
      "grad_norm": 8.288795471191406,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.581322431564331,
      "logits/rejected": 1.6643187999725342,
      "logps/chosen": -165.56704711914062,
      "logps/rejected": -69.37995147705078,
      "loss": 0.6921476364135742,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.005006222985684872,
      "rewards/margins": 0.002533865161240101,
      "rewards/rejected": -0.007540087215602398,
      "step": 60
    },
    {
      "epoch": 0.07492641156007493,
      "grad_norm": 8.452958106994629,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.713987112045288,
      "logits/rejected": 1.6693675518035889,
      "logps/chosen": -158.31729125976562,
      "logps/rejected": -69.83329772949219,
      "loss": 0.6940874576568603,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -0.0003922265022993088,
      "rewards/margins": -0.0011894702911376953,
      "rewards/rejected": 0.0007972431485541165,
      "step": 70
    },
    {
      "epoch": 0.08563018464008564,
      "grad_norm": 8.082233428955078,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.7064793109893799,
      "logits/rejected": 1.6590654850006104,
      "logps/chosen": -148.58627319335938,
      "logps/rejected": -68.53128051757812,
      "loss": 0.6942787647247315,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.009061388671398163,
      "rewards/margins": -0.0016204502899199724,
      "rewards/rejected": -0.007440939545631409,
      "step": 80
    },
    {
      "epoch": 0.09633395772009633,
      "grad_norm": 8.941459655761719,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.6620925664901733,
      "logits/rejected": 1.6241304874420166,
      "logps/chosen": -158.19827270507812,
      "logps/rejected": -70.13581085205078,
      "loss": 0.6828952312469483,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.013836907222867012,
      "rewards/margins": 0.021085070446133614,
      "rewards/rejected": -0.0072481585666537285,
      "step": 90
    },
    {
      "epoch": 0.10703773080010703,
      "grad_norm": 9.477556228637695,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.6417697668075562,
      "logits/rejected": 1.6652454137802124,
      "logps/chosen": -157.5154266357422,
      "logps/rejected": -69.01292419433594,
      "loss": 0.6810918331146241,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.013241472654044628,
      "rewards/margins": 0.025156762450933456,
      "rewards/rejected": -0.011915292590856552,
      "step": 100
    },
    {
      "epoch": 0.11774150388011774,
      "grad_norm": 9.907868385314941,
      "learning_rate": 4.946107784431138e-07,
      "logits/chosen": 1.7187845706939697,
      "logits/rejected": 1.6601899862289429,
      "logps/chosen": -174.94845581054688,
      "logps/rejected": -68.09835815429688,
      "loss": 0.6751767635345459,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.026746144518256187,
      "rewards/margins": 0.036985136568546295,
      "rewards/rejected": -0.010238990187644958,
      "step": 110
    },
    {
      "epoch": 0.12844527696012845,
      "grad_norm": 8.414681434631348,
      "learning_rate": 4.886227544910179e-07,
      "logits/chosen": 1.6912540197372437,
      "logits/rejected": 1.6567302942276,
      "logps/chosen": -167.2913360595703,
      "logps/rejected": -69.48331451416016,
      "loss": 0.6647579193115234,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": 0.035296402871608734,
      "rewards/margins": 0.05834057927131653,
      "rewards/rejected": -0.023044176399707794,
      "step": 120
    },
    {
      "epoch": 0.13914905004013914,
      "grad_norm": 9.679850578308105,
      "learning_rate": 4.826347305389221e-07,
      "logits/chosen": 1.6198238134384155,
      "logits/rejected": 1.6615989208221436,
      "logps/chosen": -152.72979736328125,
      "logps/rejected": -69.10826110839844,
      "loss": 0.6642953872680664,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": 0.041971899569034576,
      "rewards/margins": 0.05922989919781685,
      "rewards/rejected": -0.017257995903491974,
      "step": 130
    },
    {
      "epoch": 0.14985282312014986,
      "grad_norm": 7.898091793060303,
      "learning_rate": 4.766467065868263e-07,
      "logits/chosen": 1.6546618938446045,
      "logits/rejected": 1.6688381433486938,
      "logps/chosen": -149.33282470703125,
      "logps/rejected": -68.16299438476562,
      "loss": 0.6529937267303467,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": 0.05573592707514763,
      "rewards/margins": 0.08263923972845078,
      "rewards/rejected": -0.026903312653303146,
      "step": 140
    },
    {
      "epoch": 0.16055659620016055,
      "grad_norm": 9.090982437133789,
      "learning_rate": 4.7065868263473054e-07,
      "logits/chosen": 1.6320327520370483,
      "logits/rejected": 1.7216646671295166,
      "logps/chosen": -164.4097137451172,
      "logps/rejected": -69.40516662597656,
      "loss": 0.6523058414459229,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": 0.05836792662739754,
      "rewards/margins": 0.0842328742146492,
      "rewards/rejected": -0.02586493454873562,
      "step": 150
    },
    {
      "epoch": 0.17126036928017127,
      "grad_norm": 10.153979301452637,
      "learning_rate": 4.646706586826347e-07,
      "logits/chosen": 1.7300634384155273,
      "logits/rejected": 1.6958558559417725,
      "logps/chosen": -163.41688537597656,
      "logps/rejected": -69.34498596191406,
      "loss": 0.6442587852478028,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": 0.06702692806720734,
      "rewards/margins": 0.10126636177301407,
      "rewards/rejected": -0.03423944115638733,
      "step": 160
    },
    {
      "epoch": 0.18196414236018196,
      "grad_norm": 8.439712524414062,
      "learning_rate": 4.586826347305389e-07,
      "logits/chosen": 1.7112945318222046,
      "logits/rejected": 1.6683473587036133,
      "logps/chosen": -160.30043029785156,
      "logps/rejected": -69.94189453125,
      "loss": 0.6333407878875732,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.08342016488313675,
      "rewards/margins": 0.12451233714818954,
      "rewards/rejected": -0.04109218716621399,
      "step": 170
    },
    {
      "epoch": 0.19266791544019266,
      "grad_norm": 8.419052124023438,
      "learning_rate": 4.5269461077844314e-07,
      "logits/chosen": 1.6918938159942627,
      "logits/rejected": 1.6417911052703857,
      "logps/chosen": -156.48843383789062,
      "logps/rejected": -68.96297454833984,
      "loss": 0.6186578750610352,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10455403476953506,
      "rewards/margins": 0.15585380792617798,
      "rewards/rejected": -0.051299769431352615,
      "step": 180
    },
    {
      "epoch": 0.20337168852020338,
      "grad_norm": 8.72351360321045,
      "learning_rate": 4.4670658682634725e-07,
      "logits/chosen": 1.7848360538482666,
      "logits/rejected": 1.641558051109314,
      "logps/chosen": -158.29830932617188,
      "logps/rejected": -70.50563049316406,
      "loss": 0.6079248905181884,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.11383785307407379,
      "rewards/margins": 0.17978045344352722,
      "rewards/rejected": -0.06594260036945343,
      "step": 190
    },
    {
      "epoch": 0.21407546160021407,
      "grad_norm": 8.374517440795898,
      "learning_rate": 4.4071856287425147e-07,
      "logits/chosen": 1.6964657306671143,
      "logits/rejected": 1.6487194299697876,
      "logps/chosen": -152.27642822265625,
      "logps/rejected": -68.17781066894531,
      "loss": 0.6071927070617675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12195947021245956,
      "rewards/margins": 0.18166710436344147,
      "rewards/rejected": -0.05970761924982071,
      "step": 200
    },
    {
      "epoch": 0.2247792346802248,
      "grad_norm": 9.960506439208984,
      "learning_rate": 4.347305389221557e-07,
      "logits/chosen": 1.6393535137176514,
      "logits/rejected": 1.7381763458251953,
      "logps/chosen": -157.91964721679688,
      "logps/rejected": -70.6246337890625,
      "loss": 0.5921638965606689,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.14581289887428284,
      "rewards/margins": 0.21548986434936523,
      "rewards/rejected": -0.069676972925663,
      "step": 210
    },
    {
      "epoch": 0.23548300776023548,
      "grad_norm": 7.362833023071289,
      "learning_rate": 4.2874251497005985e-07,
      "logits/chosen": 1.6622581481933594,
      "logits/rejected": 1.7025314569473267,
      "logps/chosen": -148.51846313476562,
      "logps/rejected": -69.18360137939453,
      "loss": 0.580422830581665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15772202610969543,
      "rewards/margins": 0.24149970710277557,
      "rewards/rejected": -0.08377766609191895,
      "step": 220
    },
    {
      "epoch": 0.2461867808402462,
      "grad_norm": 8.221761703491211,
      "learning_rate": 4.2275449101796407e-07,
      "logits/chosen": 1.6311614513397217,
      "logits/rejected": 1.727065086364746,
      "logps/chosen": -154.7620086669922,
      "logps/rejected": -70.14659118652344,
      "loss": 0.5704712390899658,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.17022760212421417,
      "rewards/margins": 0.2646709084510803,
      "rewards/rejected": -0.09444327652454376,
      "step": 230
    },
    {
      "epoch": 0.2568905539202569,
      "grad_norm": 7.792185306549072,
      "learning_rate": 4.167664670658683e-07,
      "logits/chosen": 1.694369912147522,
      "logits/rejected": 1.7511169910430908,
      "logps/chosen": -151.84014892578125,
      "logps/rejected": -70.27996063232422,
      "loss": 0.5625833034515381,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18402381241321564,
      "rewards/margins": 0.2839474678039551,
      "rewards/rejected": -0.09992361813783646,
      "step": 240
    },
    {
      "epoch": 0.2675943270002676,
      "grad_norm": 7.754075050354004,
      "learning_rate": 4.107784431137724e-07,
      "logits/chosen": 1.7369474172592163,
      "logits/rejected": 1.6882002353668213,
      "logps/chosen": -156.65423583984375,
      "logps/rejected": -70.4563980102539,
      "loss": 0.5435427665710449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21277812123298645,
      "rewards/margins": 0.3285081088542938,
      "rewards/rejected": -0.11573000997304916,
      "step": 250
    },
    {
      "epoch": 0.2782981000802783,
      "grad_norm": 7.714420318603516,
      "learning_rate": 4.047904191616766e-07,
      "logits/chosen": 1.7461427450180054,
      "logits/rejected": 1.710466742515564,
      "logps/chosen": -159.9123992919922,
      "logps/rejected": -69.30850982666016,
      "loss": 0.5364123821258545,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2308335304260254,
      "rewards/margins": 0.3453132212162018,
      "rewards/rejected": -0.1144796833395958,
      "step": 260
    },
    {
      "epoch": 0.289001873160289,
      "grad_norm": 7.21415901184082,
      "learning_rate": 3.9880239520958084e-07,
      "logits/chosen": 1.657374620437622,
      "logits/rejected": 1.716713547706604,
      "logps/chosen": -158.9282684326172,
      "logps/rejected": -70.50715637207031,
      "loss": 0.5303668975830078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22556725144386292,
      "rewards/margins": 0.36220842599868774,
      "rewards/rejected": -0.13664118945598602,
      "step": 270
    },
    {
      "epoch": 0.2997056462402997,
      "grad_norm": 7.359683036804199,
      "learning_rate": 3.92814371257485e-07,
      "logits/chosen": 1.7286056280136108,
      "logits/rejected": 1.7379964590072632,
      "logps/chosen": -156.60171508789062,
      "logps/rejected": -70.239990234375,
      "loss": 0.5203768253326416,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2389817237854004,
      "rewards/margins": 0.3864768445491791,
      "rewards/rejected": -0.1474951207637787,
      "step": 280
    },
    {
      "epoch": 0.3104094193203104,
      "grad_norm": 8.671098709106445,
      "learning_rate": 3.868263473053892e-07,
      "logits/chosen": 1.8002102375030518,
      "logits/rejected": 1.7914083003997803,
      "logps/chosen": -163.15560913085938,
      "logps/rejected": -71.9171142578125,
      "loss": 0.504340934753418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2613446116447449,
      "rewards/margins": 0.4267834722995758,
      "rewards/rejected": -0.16543890535831451,
      "step": 290
    },
    {
      "epoch": 0.3211131924003211,
      "grad_norm": 7.48513126373291,
      "learning_rate": 3.8083832335329344e-07,
      "logits/chosen": 1.6990091800689697,
      "logits/rejected": 1.7400424480438232,
      "logps/chosen": -156.43197631835938,
      "logps/rejected": -69.75971984863281,
      "loss": 0.4844677925109863,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2985616624355316,
      "rewards/margins": 0.4776776432991028,
      "rewards/rejected": -0.17911598086357117,
      "step": 300
    },
    {
      "epoch": 0.3318169654803318,
      "grad_norm": 7.136350631713867,
      "learning_rate": 3.748502994011976e-07,
      "logits/chosen": 1.7912031412124634,
      "logits/rejected": 1.725523591041565,
      "logps/chosen": -153.400146484375,
      "logps/rejected": -70.76631164550781,
      "loss": 0.4894254684448242,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2871531546115875,
      "rewards/margins": 0.4658544063568115,
      "rewards/rejected": -0.1787012368440628,
      "step": 310
    },
    {
      "epoch": 0.34252073856034254,
      "grad_norm": 6.620776176452637,
      "learning_rate": 3.6886227544910177e-07,
      "logits/chosen": 1.7464278936386108,
      "logits/rejected": 1.742342233657837,
      "logps/chosen": -168.5391387939453,
      "logps/rejected": -70.63771057128906,
      "loss": 0.46918787956237795,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3177717328071594,
      "rewards/margins": 0.5208636522293091,
      "rewards/rejected": -0.20309194922447205,
      "step": 320
    },
    {
      "epoch": 0.35322451164035323,
      "grad_norm": 7.1932148933410645,
      "learning_rate": 3.6287425149700593e-07,
      "logits/chosen": 1.8086957931518555,
      "logits/rejected": 1.738358497619629,
      "logps/chosen": -177.856689453125,
      "logps/rejected": -70.68397521972656,
      "loss": 0.45201597213745115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3489115536212921,
      "rewards/margins": 0.5655619502067566,
      "rewards/rejected": -0.21665039658546448,
      "step": 330
    },
    {
      "epoch": 0.3639282847203639,
      "grad_norm": 7.171958923339844,
      "learning_rate": 3.5688622754491015e-07,
      "logits/chosen": 1.7698720693588257,
      "logits/rejected": 1.7953792810440063,
      "logps/chosen": -159.91726684570312,
      "logps/rejected": -70.71522521972656,
      "loss": 0.43293027877807616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3751294016838074,
      "rewards/margins": 0.621981143951416,
      "rewards/rejected": -0.24685175716876984,
      "step": 340
    },
    {
      "epoch": 0.3746320578003746,
      "grad_norm": 5.949852466583252,
      "learning_rate": 3.5089820359281437e-07,
      "logits/chosen": 1.777918815612793,
      "logits/rejected": 1.7644821405410767,
      "logps/chosen": -158.0286865234375,
      "logps/rejected": -70.19429016113281,
      "loss": 0.4423679351806641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35098764300346375,
      "rewards/margins": 0.5937544107437134,
      "rewards/rejected": -0.24276673793792725,
      "step": 350
    },
    {
      "epoch": 0.3853358308803853,
      "grad_norm": 7.169526100158691,
      "learning_rate": 3.4491017964071854e-07,
      "logits/chosen": 1.7639968395233154,
      "logits/rejected": 1.7791551351547241,
      "logps/chosen": -163.9099578857422,
      "logps/rejected": -70.51515197753906,
      "loss": 0.42521085739135744,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37591031193733215,
      "rewards/margins": 0.6454294323921204,
      "rewards/rejected": -0.2695190906524658,
      "step": 360
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 6.478632926940918,
      "learning_rate": 3.3892215568862275e-07,
      "logits/chosen": 1.7478431463241577,
      "logits/rejected": 1.7402607202529907,
      "logps/chosen": -158.5614013671875,
      "logps/rejected": -70.65251159667969,
      "loss": 0.4226096153259277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3807930052280426,
      "rewards/margins": 0.6555624604225159,
      "rewards/rejected": -0.2747694253921509,
      "step": 370
    },
    {
      "epoch": 0.40674337704040675,
      "grad_norm": 6.612639427185059,
      "learning_rate": 3.3293413173652697e-07,
      "logits/chosen": 1.7278316020965576,
      "logits/rejected": 1.729334831237793,
      "logps/chosen": -165.6972198486328,
      "logps/rejected": -71.84222412109375,
      "loss": 0.39657618999481203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43572568893432617,
      "rewards/margins": 0.732917308807373,
      "rewards/rejected": -0.2971916198730469,
      "step": 380
    },
    {
      "epoch": 0.41744715012041744,
      "grad_norm": 6.1286940574646,
      "learning_rate": 3.269461077844311e-07,
      "logits/chosen": 1.6758067607879639,
      "logits/rejected": 1.7733802795410156,
      "logps/chosen": -152.27896118164062,
      "logps/rejected": -72.2264175415039,
      "loss": 0.3839158058166504,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46665340662002563,
      "rewards/margins": 0.7699450254440308,
      "rewards/rejected": -0.3032916486263275,
      "step": 390
    },
    {
      "epoch": 0.42815092320042814,
      "grad_norm": 6.23543643951416,
      "learning_rate": 3.209580838323353e-07,
      "logits/chosen": 1.7565456628799438,
      "logits/rejected": 1.7698053121566772,
      "logps/chosen": -157.11212158203125,
      "logps/rejected": -71.5601806640625,
      "loss": 0.3910945415496826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43029680848121643,
      "rewards/margins": 0.7487980723381042,
      "rewards/rejected": -0.3185012936592102,
      "step": 400
    },
    {
      "epoch": 0.4388546962804388,
      "grad_norm": 6.28948974609375,
      "learning_rate": 3.149700598802395e-07,
      "logits/chosen": 1.759067177772522,
      "logits/rejected": 1.7308323383331299,
      "logps/chosen": -161.7775421142578,
      "logps/rejected": -72.33509063720703,
      "loss": 0.3685615062713623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5020124316215515,
      "rewards/margins": 0.8277686238288879,
      "rewards/rejected": -0.32575613260269165,
      "step": 410
    },
    {
      "epoch": 0.4495584693604496,
      "grad_norm": 5.919633388519287,
      "learning_rate": 3.089820359281437e-07,
      "logits/chosen": 1.7893489599227905,
      "logits/rejected": 1.8463239669799805,
      "logps/chosen": -161.2848358154297,
      "logps/rejected": -71.51163482666016,
      "loss": 0.37374272346496584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45797449350357056,
      "rewards/margins": 0.8017574548721313,
      "rewards/rejected": -0.3437829315662384,
      "step": 420
    },
    {
      "epoch": 0.46026224244046027,
      "grad_norm": 6.106878280639648,
      "learning_rate": 3.029940119760479e-07,
      "logits/chosen": 1.747452735900879,
      "logits/rejected": 1.8020496368408203,
      "logps/chosen": -159.88272094726562,
      "logps/rejected": -71.7718734741211,
      "loss": 0.3705310583114624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4668917655944824,
      "rewards/margins": 0.8182605504989624,
      "rewards/rejected": -0.3513686954975128,
      "step": 430
    },
    {
      "epoch": 0.47096601552047096,
      "grad_norm": 5.83473539352417,
      "learning_rate": 2.970059880239521e-07,
      "logits/chosen": 1.805728554725647,
      "logits/rejected": 1.817588210105896,
      "logps/chosen": -155.33705139160156,
      "logps/rejected": -72.45240020751953,
      "loss": 0.35789918899536133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4986165165901184,
      "rewards/margins": 0.8617266416549683,
      "rewards/rejected": -0.36311012506484985,
      "step": 440
    },
    {
      "epoch": 0.48166978860048165,
      "grad_norm": 6.262120246887207,
      "learning_rate": 2.9101796407185623e-07,
      "logits/chosen": 1.7688219547271729,
      "logits/rejected": 1.794703722000122,
      "logps/chosen": -160.7371063232422,
      "logps/rejected": -73.21669006347656,
      "loss": 0.3428905725479126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5376484394073486,
      "rewards/margins": 0.9157134890556335,
      "rewards/rejected": -0.37806493043899536,
      "step": 450
    },
    {
      "epoch": 0.4923735616804924,
      "grad_norm": 5.3677167892456055,
      "learning_rate": 2.8502994011976045e-07,
      "logits/chosen": 1.7953178882598877,
      "logits/rejected": 1.772540807723999,
      "logps/chosen": -155.5399169921875,
      "logps/rejected": -72.81478118896484,
      "loss": 0.3390610933303833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5243449807167053,
      "rewards/margins": 0.9240484237670898,
      "rewards/rejected": -0.3997035026550293,
      "step": 460
    },
    {
      "epoch": 0.5030773347605031,
      "grad_norm": 5.636107921600342,
      "learning_rate": 2.7904191616766467e-07,
      "logits/chosen": 1.8175522089004517,
      "logits/rejected": 1.8141968250274658,
      "logps/chosen": -163.5902099609375,
      "logps/rejected": -73.2023696899414,
      "loss": 0.32942512035369875,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5344223380088806,
      "rewards/margins": 0.9579919576644897,
      "rewards/rejected": -0.4235696792602539,
      "step": 470
    },
    {
      "epoch": 0.5137811078405138,
      "grad_norm": 5.684364318847656,
      "learning_rate": 2.7305389221556884e-07,
      "logits/chosen": 1.774632453918457,
      "logits/rejected": 1.768472671508789,
      "logps/chosen": -160.8123321533203,
      "logps/rejected": -73.27583312988281,
      "loss": 0.31229088306427,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5831418037414551,
      "rewards/margins": 1.0233112573623657,
      "rewards/rejected": -0.4401695132255554,
      "step": 480
    },
    {
      "epoch": 0.5244848809205245,
      "grad_norm": 5.383895397186279,
      "learning_rate": 2.6706586826347305e-07,
      "logits/chosen": 1.76302170753479,
      "logits/rejected": 1.8447272777557373,
      "logps/chosen": -166.46861267089844,
      "logps/rejected": -74.18718719482422,
      "loss": 0.3131100177764893,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5765050053596497,
      "rewards/margins": 1.022840142250061,
      "rewards/rejected": -0.4463350772857666,
      "step": 490
    },
    {
      "epoch": 0.5351886540005352,
      "grad_norm": 5.0746307373046875,
      "learning_rate": 2.6107784431137727e-07,
      "logits/chosen": 1.818164587020874,
      "logits/rejected": 1.819345474243164,
      "logps/chosen": -144.30130004882812,
      "logps/rejected": -72.77714538574219,
      "loss": 0.3194474458694458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5641644597053528,
      "rewards/margins": 1.004306435585022,
      "rewards/rejected": -0.4401419758796692,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
