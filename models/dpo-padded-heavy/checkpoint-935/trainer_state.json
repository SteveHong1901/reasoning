{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 935,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010703773080010704,
      "grad_norm": 8.051277160644531,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.6634620428085327,
      "logits/rejected": 1.6339889764785767,
      "logps/chosen": -154.83262634277344,
      "logps/rejected": -68.8427734375,
      "loss": 0.6906611442565918,
      "rewards/accuracies": 0.3375000059604645,
      "rewards/chosen": 0.0038951016031205654,
      "rewards/margins": 0.005355882458388805,
      "rewards/rejected": -0.0014607814373448491,
      "step": 10
    },
    {
      "epoch": 0.02140754616002141,
      "grad_norm": 8.103742599487305,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.6807512044906616,
      "logits/rejected": 1.6834901571273804,
      "logps/chosen": -172.0310516357422,
      "logps/rejected": -69.37297058105469,
      "loss": 0.6950807094573974,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": -0.00255882297642529,
      "rewards/margins": -0.0032169297337532043,
      "rewards/rejected": 0.0006581068737432361,
      "step": 20
    },
    {
      "epoch": 0.03211131924003211,
      "grad_norm": 9.027518272399902,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.7286850214004517,
      "logits/rejected": 1.7165313959121704,
      "logps/chosen": -156.46807861328125,
      "logps/rejected": -68.60604858398438,
      "loss": 0.6947118282318115,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00559225445613265,
      "rewards/margins": -0.002517533488571644,
      "rewards/rejected": -0.0030747223645448685,
      "step": 30
    },
    {
      "epoch": 0.04281509232004282,
      "grad_norm": 7.641145706176758,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.6941430568695068,
      "logits/rejected": 1.6695566177368164,
      "logps/chosen": -163.2023468017578,
      "logps/rejected": -68.39588928222656,
      "loss": 0.6940316677093505,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00019513629376888275,
      "rewards/margins": -0.0010265589226037264,
      "rewards/rejected": 0.0008314229780808091,
      "step": 40
    },
    {
      "epoch": 0.05351886540005352,
      "grad_norm": 7.41262149810791,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.6595462560653687,
      "logits/rejected": 1.6949503421783447,
      "logps/chosen": -164.45040893554688,
      "logps/rejected": -69.53597259521484,
      "loss": 0.6935943603515625,
      "rewards/accuracies": 0.4375,
      "rewards/chosen": 0.0018275268375873566,
      "rewards/margins": -0.00024599971948191524,
      "rewards/rejected": 0.0020735259167850018,
      "step": 50
    },
    {
      "epoch": 0.06422263848006422,
      "grad_norm": 8.288795471191406,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.581322431564331,
      "logits/rejected": 1.6643187999725342,
      "logps/chosen": -165.56704711914062,
      "logps/rejected": -69.37995147705078,
      "loss": 0.6921476364135742,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.005006222985684872,
      "rewards/margins": 0.002533865161240101,
      "rewards/rejected": -0.007540087215602398,
      "step": 60
    },
    {
      "epoch": 0.07492641156007493,
      "grad_norm": 8.452958106994629,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.713987112045288,
      "logits/rejected": 1.6693675518035889,
      "logps/chosen": -158.31729125976562,
      "logps/rejected": -69.83329772949219,
      "loss": 0.6940874576568603,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -0.0003922265022993088,
      "rewards/margins": -0.0011894702911376953,
      "rewards/rejected": 0.0007972431485541165,
      "step": 70
    },
    {
      "epoch": 0.08563018464008564,
      "grad_norm": 8.082233428955078,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.7064793109893799,
      "logits/rejected": 1.6590654850006104,
      "logps/chosen": -148.58627319335938,
      "logps/rejected": -68.53128051757812,
      "loss": 0.6942787647247315,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.009061388671398163,
      "rewards/margins": -0.0016204502899199724,
      "rewards/rejected": -0.007440939545631409,
      "step": 80
    },
    {
      "epoch": 0.09633395772009633,
      "grad_norm": 8.941459655761719,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.6620925664901733,
      "logits/rejected": 1.6241304874420166,
      "logps/chosen": -158.19827270507812,
      "logps/rejected": -70.13581085205078,
      "loss": 0.6828952312469483,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": 0.013836907222867012,
      "rewards/margins": 0.021085070446133614,
      "rewards/rejected": -0.0072481585666537285,
      "step": 90
    },
    {
      "epoch": 0.10703773080010703,
      "grad_norm": 9.477556228637695,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.6417697668075562,
      "logits/rejected": 1.6652454137802124,
      "logps/chosen": -157.5154266357422,
      "logps/rejected": -69.01292419433594,
      "loss": 0.6810918331146241,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.013241472654044628,
      "rewards/margins": 0.025156762450933456,
      "rewards/rejected": -0.011915292590856552,
      "step": 100
    },
    {
      "epoch": 0.11774150388011774,
      "grad_norm": 9.907868385314941,
      "learning_rate": 4.946107784431138e-07,
      "logits/chosen": 1.7187845706939697,
      "logits/rejected": 1.6601899862289429,
      "logps/chosen": -174.94845581054688,
      "logps/rejected": -68.09835815429688,
      "loss": 0.6751767635345459,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.026746144518256187,
      "rewards/margins": 0.036985136568546295,
      "rewards/rejected": -0.010238990187644958,
      "step": 110
    },
    {
      "epoch": 0.12844527696012845,
      "grad_norm": 8.414681434631348,
      "learning_rate": 4.886227544910179e-07,
      "logits/chosen": 1.6912540197372437,
      "logits/rejected": 1.6567302942276,
      "logps/chosen": -167.2913360595703,
      "logps/rejected": -69.48331451416016,
      "loss": 0.6647579193115234,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": 0.035296402871608734,
      "rewards/margins": 0.05834057927131653,
      "rewards/rejected": -0.023044176399707794,
      "step": 120
    },
    {
      "epoch": 0.13914905004013914,
      "grad_norm": 9.679850578308105,
      "learning_rate": 4.826347305389221e-07,
      "logits/chosen": 1.6198238134384155,
      "logits/rejected": 1.6615989208221436,
      "logps/chosen": -152.72979736328125,
      "logps/rejected": -69.10826110839844,
      "loss": 0.6642953872680664,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": 0.041971899569034576,
      "rewards/margins": 0.05922989919781685,
      "rewards/rejected": -0.017257995903491974,
      "step": 130
    },
    {
      "epoch": 0.14985282312014986,
      "grad_norm": 7.898091793060303,
      "learning_rate": 4.766467065868263e-07,
      "logits/chosen": 1.6546618938446045,
      "logits/rejected": 1.6688381433486938,
      "logps/chosen": -149.33282470703125,
      "logps/rejected": -68.16299438476562,
      "loss": 0.6529937267303467,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": 0.05573592707514763,
      "rewards/margins": 0.08263923972845078,
      "rewards/rejected": -0.026903312653303146,
      "step": 140
    },
    {
      "epoch": 0.16055659620016055,
      "grad_norm": 9.090982437133789,
      "learning_rate": 4.7065868263473054e-07,
      "logits/chosen": 1.6320327520370483,
      "logits/rejected": 1.7216646671295166,
      "logps/chosen": -164.4097137451172,
      "logps/rejected": -69.40516662597656,
      "loss": 0.6523058414459229,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": 0.05836792662739754,
      "rewards/margins": 0.0842328742146492,
      "rewards/rejected": -0.02586493454873562,
      "step": 150
    },
    {
      "epoch": 0.17126036928017127,
      "grad_norm": 10.153979301452637,
      "learning_rate": 4.646706586826347e-07,
      "logits/chosen": 1.7300634384155273,
      "logits/rejected": 1.6958558559417725,
      "logps/chosen": -163.41688537597656,
      "logps/rejected": -69.34498596191406,
      "loss": 0.6442587852478028,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": 0.06702692806720734,
      "rewards/margins": 0.10126636177301407,
      "rewards/rejected": -0.03423944115638733,
      "step": 160
    },
    {
      "epoch": 0.18196414236018196,
      "grad_norm": 8.439712524414062,
      "learning_rate": 4.586826347305389e-07,
      "logits/chosen": 1.7112945318222046,
      "logits/rejected": 1.6683473587036133,
      "logps/chosen": -160.30043029785156,
      "logps/rejected": -69.94189453125,
      "loss": 0.6333407878875732,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.08342016488313675,
      "rewards/margins": 0.12451233714818954,
      "rewards/rejected": -0.04109218716621399,
      "step": 170
    },
    {
      "epoch": 0.19266791544019266,
      "grad_norm": 8.419052124023438,
      "learning_rate": 4.5269461077844314e-07,
      "logits/chosen": 1.6918938159942627,
      "logits/rejected": 1.6417911052703857,
      "logps/chosen": -156.48843383789062,
      "logps/rejected": -68.96297454833984,
      "loss": 0.6186578750610352,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10455403476953506,
      "rewards/margins": 0.15585380792617798,
      "rewards/rejected": -0.051299769431352615,
      "step": 180
    },
    {
      "epoch": 0.20337168852020338,
      "grad_norm": 8.72351360321045,
      "learning_rate": 4.4670658682634725e-07,
      "logits/chosen": 1.7848360538482666,
      "logits/rejected": 1.641558051109314,
      "logps/chosen": -158.29830932617188,
      "logps/rejected": -70.50563049316406,
      "loss": 0.6079248905181884,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.11383785307407379,
      "rewards/margins": 0.17978045344352722,
      "rewards/rejected": -0.06594260036945343,
      "step": 190
    },
    {
      "epoch": 0.21407546160021407,
      "grad_norm": 8.374517440795898,
      "learning_rate": 4.4071856287425147e-07,
      "logits/chosen": 1.6964657306671143,
      "logits/rejected": 1.6487194299697876,
      "logps/chosen": -152.27642822265625,
      "logps/rejected": -68.17781066894531,
      "loss": 0.6071927070617675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12195947021245956,
      "rewards/margins": 0.18166710436344147,
      "rewards/rejected": -0.05970761924982071,
      "step": 200
    },
    {
      "epoch": 0.2247792346802248,
      "grad_norm": 9.960506439208984,
      "learning_rate": 4.347305389221557e-07,
      "logits/chosen": 1.6393535137176514,
      "logits/rejected": 1.7381763458251953,
      "logps/chosen": -157.91964721679688,
      "logps/rejected": -70.6246337890625,
      "loss": 0.5921638965606689,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.14581289887428284,
      "rewards/margins": 0.21548986434936523,
      "rewards/rejected": -0.069676972925663,
      "step": 210
    },
    {
      "epoch": 0.23548300776023548,
      "grad_norm": 7.362833023071289,
      "learning_rate": 4.2874251497005985e-07,
      "logits/chosen": 1.6622581481933594,
      "logits/rejected": 1.7025314569473267,
      "logps/chosen": -148.51846313476562,
      "logps/rejected": -69.18360137939453,
      "loss": 0.580422830581665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15772202610969543,
      "rewards/margins": 0.24149970710277557,
      "rewards/rejected": -0.08377766609191895,
      "step": 220
    },
    {
      "epoch": 0.2461867808402462,
      "grad_norm": 8.221761703491211,
      "learning_rate": 4.2275449101796407e-07,
      "logits/chosen": 1.6311614513397217,
      "logits/rejected": 1.727065086364746,
      "logps/chosen": -154.7620086669922,
      "logps/rejected": -70.14659118652344,
      "loss": 0.5704712390899658,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.17022760212421417,
      "rewards/margins": 0.2646709084510803,
      "rewards/rejected": -0.09444327652454376,
      "step": 230
    },
    {
      "epoch": 0.2568905539202569,
      "grad_norm": 7.792185306549072,
      "learning_rate": 4.167664670658683e-07,
      "logits/chosen": 1.694369912147522,
      "logits/rejected": 1.7511169910430908,
      "logps/chosen": -151.84014892578125,
      "logps/rejected": -70.27996063232422,
      "loss": 0.5625833034515381,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18402381241321564,
      "rewards/margins": 0.2839474678039551,
      "rewards/rejected": -0.09992361813783646,
      "step": 240
    },
    {
      "epoch": 0.2675943270002676,
      "grad_norm": 7.754075050354004,
      "learning_rate": 4.107784431137724e-07,
      "logits/chosen": 1.7369474172592163,
      "logits/rejected": 1.6882002353668213,
      "logps/chosen": -156.65423583984375,
      "logps/rejected": -70.4563980102539,
      "loss": 0.5435427665710449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21277812123298645,
      "rewards/margins": 0.3285081088542938,
      "rewards/rejected": -0.11573000997304916,
      "step": 250
    },
    {
      "epoch": 0.2782981000802783,
      "grad_norm": 7.714420318603516,
      "learning_rate": 4.047904191616766e-07,
      "logits/chosen": 1.7461427450180054,
      "logits/rejected": 1.710466742515564,
      "logps/chosen": -159.9123992919922,
      "logps/rejected": -69.30850982666016,
      "loss": 0.5364123821258545,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2308335304260254,
      "rewards/margins": 0.3453132212162018,
      "rewards/rejected": -0.1144796833395958,
      "step": 260
    },
    {
      "epoch": 0.289001873160289,
      "grad_norm": 7.21415901184082,
      "learning_rate": 3.9880239520958084e-07,
      "logits/chosen": 1.657374620437622,
      "logits/rejected": 1.716713547706604,
      "logps/chosen": -158.9282684326172,
      "logps/rejected": -70.50715637207031,
      "loss": 0.5303668975830078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22556725144386292,
      "rewards/margins": 0.36220842599868774,
      "rewards/rejected": -0.13664118945598602,
      "step": 270
    },
    {
      "epoch": 0.2997056462402997,
      "grad_norm": 7.359683036804199,
      "learning_rate": 3.92814371257485e-07,
      "logits/chosen": 1.7286056280136108,
      "logits/rejected": 1.7379964590072632,
      "logps/chosen": -156.60171508789062,
      "logps/rejected": -70.239990234375,
      "loss": 0.5203768253326416,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2389817237854004,
      "rewards/margins": 0.3864768445491791,
      "rewards/rejected": -0.1474951207637787,
      "step": 280
    },
    {
      "epoch": 0.3104094193203104,
      "grad_norm": 8.671098709106445,
      "learning_rate": 3.868263473053892e-07,
      "logits/chosen": 1.8002102375030518,
      "logits/rejected": 1.7914083003997803,
      "logps/chosen": -163.15560913085938,
      "logps/rejected": -71.9171142578125,
      "loss": 0.504340934753418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2613446116447449,
      "rewards/margins": 0.4267834722995758,
      "rewards/rejected": -0.16543890535831451,
      "step": 290
    },
    {
      "epoch": 0.3211131924003211,
      "grad_norm": 7.48513126373291,
      "learning_rate": 3.8083832335329344e-07,
      "logits/chosen": 1.6990091800689697,
      "logits/rejected": 1.7400424480438232,
      "logps/chosen": -156.43197631835938,
      "logps/rejected": -69.75971984863281,
      "loss": 0.4844677925109863,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2985616624355316,
      "rewards/margins": 0.4776776432991028,
      "rewards/rejected": -0.17911598086357117,
      "step": 300
    },
    {
      "epoch": 0.3318169654803318,
      "grad_norm": 7.136350631713867,
      "learning_rate": 3.748502994011976e-07,
      "logits/chosen": 1.7912031412124634,
      "logits/rejected": 1.725523591041565,
      "logps/chosen": -153.400146484375,
      "logps/rejected": -70.76631164550781,
      "loss": 0.4894254684448242,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2871531546115875,
      "rewards/margins": 0.4658544063568115,
      "rewards/rejected": -0.1787012368440628,
      "step": 310
    },
    {
      "epoch": 0.34252073856034254,
      "grad_norm": 6.620776176452637,
      "learning_rate": 3.6886227544910177e-07,
      "logits/chosen": 1.7464278936386108,
      "logits/rejected": 1.742342233657837,
      "logps/chosen": -168.5391387939453,
      "logps/rejected": -70.63771057128906,
      "loss": 0.46918787956237795,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3177717328071594,
      "rewards/margins": 0.5208636522293091,
      "rewards/rejected": -0.20309194922447205,
      "step": 320
    },
    {
      "epoch": 0.35322451164035323,
      "grad_norm": 7.1932148933410645,
      "learning_rate": 3.6287425149700593e-07,
      "logits/chosen": 1.8086957931518555,
      "logits/rejected": 1.738358497619629,
      "logps/chosen": -177.856689453125,
      "logps/rejected": -70.68397521972656,
      "loss": 0.45201597213745115,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3489115536212921,
      "rewards/margins": 0.5655619502067566,
      "rewards/rejected": -0.21665039658546448,
      "step": 330
    },
    {
      "epoch": 0.3639282847203639,
      "grad_norm": 7.171958923339844,
      "learning_rate": 3.5688622754491015e-07,
      "logits/chosen": 1.7698720693588257,
      "logits/rejected": 1.7953792810440063,
      "logps/chosen": -159.91726684570312,
      "logps/rejected": -70.71522521972656,
      "loss": 0.43293027877807616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3751294016838074,
      "rewards/margins": 0.621981143951416,
      "rewards/rejected": -0.24685175716876984,
      "step": 340
    },
    {
      "epoch": 0.3746320578003746,
      "grad_norm": 5.949852466583252,
      "learning_rate": 3.5089820359281437e-07,
      "logits/chosen": 1.777918815612793,
      "logits/rejected": 1.7644821405410767,
      "logps/chosen": -158.0286865234375,
      "logps/rejected": -70.19429016113281,
      "loss": 0.4423679351806641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35098764300346375,
      "rewards/margins": 0.5937544107437134,
      "rewards/rejected": -0.24276673793792725,
      "step": 350
    },
    {
      "epoch": 0.3853358308803853,
      "grad_norm": 7.169526100158691,
      "learning_rate": 3.4491017964071854e-07,
      "logits/chosen": 1.7639968395233154,
      "logits/rejected": 1.7791551351547241,
      "logps/chosen": -163.9099578857422,
      "logps/rejected": -70.51515197753906,
      "loss": 0.42521085739135744,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37591031193733215,
      "rewards/margins": 0.6454294323921204,
      "rewards/rejected": -0.2695190906524658,
      "step": 360
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 6.478632926940918,
      "learning_rate": 3.3892215568862275e-07,
      "logits/chosen": 1.7478431463241577,
      "logits/rejected": 1.7402607202529907,
      "logps/chosen": -158.5614013671875,
      "logps/rejected": -70.65251159667969,
      "loss": 0.4226096153259277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3807930052280426,
      "rewards/margins": 0.6555624604225159,
      "rewards/rejected": -0.2747694253921509,
      "step": 370
    },
    {
      "epoch": 0.40674337704040675,
      "grad_norm": 6.612639427185059,
      "learning_rate": 3.3293413173652697e-07,
      "logits/chosen": 1.7278316020965576,
      "logits/rejected": 1.729334831237793,
      "logps/chosen": -165.6972198486328,
      "logps/rejected": -71.84222412109375,
      "loss": 0.39657618999481203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43572568893432617,
      "rewards/margins": 0.732917308807373,
      "rewards/rejected": -0.2971916198730469,
      "step": 380
    },
    {
      "epoch": 0.41744715012041744,
      "grad_norm": 6.1286940574646,
      "learning_rate": 3.269461077844311e-07,
      "logits/chosen": 1.6758067607879639,
      "logits/rejected": 1.7733802795410156,
      "logps/chosen": -152.27896118164062,
      "logps/rejected": -72.2264175415039,
      "loss": 0.3839158058166504,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46665340662002563,
      "rewards/margins": 0.7699450254440308,
      "rewards/rejected": -0.3032916486263275,
      "step": 390
    },
    {
      "epoch": 0.42815092320042814,
      "grad_norm": 6.23543643951416,
      "learning_rate": 3.209580838323353e-07,
      "logits/chosen": 1.7565456628799438,
      "logits/rejected": 1.7698053121566772,
      "logps/chosen": -157.11212158203125,
      "logps/rejected": -71.5601806640625,
      "loss": 0.3910945415496826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.43029680848121643,
      "rewards/margins": 0.7487980723381042,
      "rewards/rejected": -0.3185012936592102,
      "step": 400
    },
    {
      "epoch": 0.4388546962804388,
      "grad_norm": 6.28948974609375,
      "learning_rate": 3.149700598802395e-07,
      "logits/chosen": 1.759067177772522,
      "logits/rejected": 1.7308323383331299,
      "logps/chosen": -161.7775421142578,
      "logps/rejected": -72.33509063720703,
      "loss": 0.3685615062713623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5020124316215515,
      "rewards/margins": 0.8277686238288879,
      "rewards/rejected": -0.32575613260269165,
      "step": 410
    },
    {
      "epoch": 0.4495584693604496,
      "grad_norm": 5.919633388519287,
      "learning_rate": 3.089820359281437e-07,
      "logits/chosen": 1.7893489599227905,
      "logits/rejected": 1.8463239669799805,
      "logps/chosen": -161.2848358154297,
      "logps/rejected": -71.51163482666016,
      "loss": 0.37374272346496584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45797449350357056,
      "rewards/margins": 0.8017574548721313,
      "rewards/rejected": -0.3437829315662384,
      "step": 420
    },
    {
      "epoch": 0.46026224244046027,
      "grad_norm": 6.106878280639648,
      "learning_rate": 3.029940119760479e-07,
      "logits/chosen": 1.747452735900879,
      "logits/rejected": 1.8020496368408203,
      "logps/chosen": -159.88272094726562,
      "logps/rejected": -71.7718734741211,
      "loss": 0.3705310583114624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4668917655944824,
      "rewards/margins": 0.8182605504989624,
      "rewards/rejected": -0.3513686954975128,
      "step": 430
    },
    {
      "epoch": 0.47096601552047096,
      "grad_norm": 5.83473539352417,
      "learning_rate": 2.970059880239521e-07,
      "logits/chosen": 1.805728554725647,
      "logits/rejected": 1.817588210105896,
      "logps/chosen": -155.33705139160156,
      "logps/rejected": -72.45240020751953,
      "loss": 0.35789918899536133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4986165165901184,
      "rewards/margins": 0.8617266416549683,
      "rewards/rejected": -0.36311012506484985,
      "step": 440
    },
    {
      "epoch": 0.48166978860048165,
      "grad_norm": 6.262120246887207,
      "learning_rate": 2.9101796407185623e-07,
      "logits/chosen": 1.7688219547271729,
      "logits/rejected": 1.794703722000122,
      "logps/chosen": -160.7371063232422,
      "logps/rejected": -73.21669006347656,
      "loss": 0.3428905725479126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5376484394073486,
      "rewards/margins": 0.9157134890556335,
      "rewards/rejected": -0.37806493043899536,
      "step": 450
    },
    {
      "epoch": 0.4923735616804924,
      "grad_norm": 5.3677167892456055,
      "learning_rate": 2.8502994011976045e-07,
      "logits/chosen": 1.7953178882598877,
      "logits/rejected": 1.772540807723999,
      "logps/chosen": -155.5399169921875,
      "logps/rejected": -72.81478118896484,
      "loss": 0.3390610933303833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5243449807167053,
      "rewards/margins": 0.9240484237670898,
      "rewards/rejected": -0.3997035026550293,
      "step": 460
    },
    {
      "epoch": 0.5030773347605031,
      "grad_norm": 5.636107921600342,
      "learning_rate": 2.7904191616766467e-07,
      "logits/chosen": 1.8175522089004517,
      "logits/rejected": 1.8141968250274658,
      "logps/chosen": -163.5902099609375,
      "logps/rejected": -73.2023696899414,
      "loss": 0.32942512035369875,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5344223380088806,
      "rewards/margins": 0.9579919576644897,
      "rewards/rejected": -0.4235696792602539,
      "step": 470
    },
    {
      "epoch": 0.5137811078405138,
      "grad_norm": 5.684364318847656,
      "learning_rate": 2.7305389221556884e-07,
      "logits/chosen": 1.774632453918457,
      "logits/rejected": 1.768472671508789,
      "logps/chosen": -160.8123321533203,
      "logps/rejected": -73.27583312988281,
      "loss": 0.31229088306427,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5831418037414551,
      "rewards/margins": 1.0233112573623657,
      "rewards/rejected": -0.4401695132255554,
      "step": 480
    },
    {
      "epoch": 0.5244848809205245,
      "grad_norm": 5.383895397186279,
      "learning_rate": 2.6706586826347305e-07,
      "logits/chosen": 1.76302170753479,
      "logits/rejected": 1.8447272777557373,
      "logps/chosen": -166.46861267089844,
      "logps/rejected": -74.18718719482422,
      "loss": 0.3131100177764893,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5765050053596497,
      "rewards/margins": 1.022840142250061,
      "rewards/rejected": -0.4463350772857666,
      "step": 490
    },
    {
      "epoch": 0.5351886540005352,
      "grad_norm": 5.0746307373046875,
      "learning_rate": 2.6107784431137727e-07,
      "logits/chosen": 1.818164587020874,
      "logits/rejected": 1.819345474243164,
      "logps/chosen": -144.30130004882812,
      "logps/rejected": -72.77714538574219,
      "loss": 0.3194474458694458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5641644597053528,
      "rewards/margins": 1.004306435585022,
      "rewards/rejected": -0.4401419758796692,
      "step": 500
    },
    {
      "epoch": 0.5458924270805459,
      "grad_norm": 5.223479747772217,
      "learning_rate": 2.5508982035928144e-07,
      "logits/chosen": 1.7925752401351929,
      "logits/rejected": 1.7872097492218018,
      "logps/chosen": -151.84982299804688,
      "logps/rejected": -72.69499206542969,
      "loss": 0.30630357265472413,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5847562551498413,
      "rewards/margins": 1.0532876253128052,
      "rewards/rejected": -0.46853137016296387,
      "step": 510
    },
    {
      "epoch": 0.5565962001605566,
      "grad_norm": 5.001507759094238,
      "learning_rate": 2.491017964071856e-07,
      "logits/chosen": 1.7855384349822998,
      "logits/rejected": 1.7747552394866943,
      "logps/chosen": -152.76742553710938,
      "logps/rejected": -73.23832702636719,
      "loss": 0.29660632610321047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6130293607711792,
      "rewards/margins": 1.0876117944717407,
      "rewards/rejected": -0.4745822846889496,
      "step": 520
    },
    {
      "epoch": 0.5672999732405672,
      "grad_norm": 4.840521812438965,
      "learning_rate": 2.431137724550898e-07,
      "logits/chosen": 1.7756420373916626,
      "logits/rejected": 1.8153364658355713,
      "logps/chosen": -157.13934326171875,
      "logps/rejected": -73.211669921875,
      "loss": 0.29920384883880613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6054874062538147,
      "rewards/margins": 1.0910979509353638,
      "rewards/rejected": -0.4856105446815491,
      "step": 530
    },
    {
      "epoch": 0.578003746320578,
      "grad_norm": 5.206826210021973,
      "learning_rate": 2.3712574850299399e-07,
      "logits/chosen": 1.743731141090393,
      "logits/rejected": 1.813643217086792,
      "logps/chosen": -147.0794219970703,
      "logps/rejected": -74.040283203125,
      "loss": 0.29068105220794677,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5838624835014343,
      "rewards/margins": 1.1150035858154297,
      "rewards/rejected": -0.5311411023139954,
      "step": 540
    },
    {
      "epoch": 0.5887075194005887,
      "grad_norm": 4.498152732849121,
      "learning_rate": 2.311377245508982e-07,
      "logits/chosen": 1.7539637088775635,
      "logits/rejected": 1.7891775369644165,
      "logps/chosen": -154.2647705078125,
      "logps/rejected": -73.38945770263672,
      "loss": 0.270136284828186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6573830246925354,
      "rewards/margins": 1.1972132921218872,
      "rewards/rejected": -0.5398303270339966,
      "step": 550
    },
    {
      "epoch": 0.5994112924805994,
      "grad_norm": 4.542431831359863,
      "learning_rate": 2.251497005988024e-07,
      "logits/chosen": 1.7710682153701782,
      "logits/rejected": 1.808462142944336,
      "logps/chosen": -144.77491760253906,
      "logps/rejected": -74.47857666015625,
      "loss": 0.2860373020172119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.603866457939148,
      "rewards/margins": 1.1405961513519287,
      "rewards/rejected": -0.5367296934127808,
      "step": 560
    },
    {
      "epoch": 0.6101150655606101,
      "grad_norm": 4.633514404296875,
      "learning_rate": 2.1916167664670656e-07,
      "logits/chosen": 1.7823692560195923,
      "logits/rejected": 1.8288055658340454,
      "logps/chosen": -156.32827758789062,
      "logps/rejected": -75.8743896484375,
      "loss": 0.2572850465774536,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6569620370864868,
      "rewards/margins": 1.2582838535308838,
      "rewards/rejected": -0.601321816444397,
      "step": 570
    },
    {
      "epoch": 0.6208188386406208,
      "grad_norm": 4.6131744384765625,
      "learning_rate": 2.1317365269461078e-07,
      "logits/chosen": 1.7239048480987549,
      "logits/rejected": 1.8183647394180298,
      "logps/chosen": -148.2583770751953,
      "logps/rejected": -75.26058197021484,
      "loss": 0.25773594379425047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6914815306663513,
      "rewards/margins": 1.2574684619903564,
      "rewards/rejected": -0.5659868121147156,
      "step": 580
    },
    {
      "epoch": 0.6315226117206315,
      "grad_norm": 4.4825944900512695,
      "learning_rate": 2.0718562874251497e-07,
      "logits/chosen": 1.8225129842758179,
      "logits/rejected": 1.8122409582138062,
      "logps/chosen": -162.38043212890625,
      "logps/rejected": -74.34320068359375,
      "loss": 0.24859297275543213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7003523707389832,
      "rewards/margins": 1.2894210815429688,
      "rewards/rejected": -0.5890687108039856,
      "step": 590
    },
    {
      "epoch": 0.6422263848006422,
      "grad_norm": 4.309817314147949,
      "learning_rate": 2.0119760479041914e-07,
      "logits/chosen": 1.8029634952545166,
      "logits/rejected": 1.8738235235214233,
      "logps/chosen": -152.4327392578125,
      "logps/rejected": -74.62601470947266,
      "loss": 0.24711716175079346,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6988378763198853,
      "rewards/margins": 1.303388237953186,
      "rewards/rejected": -0.6045504808425903,
      "step": 600
    },
    {
      "epoch": 0.6529301578806529,
      "grad_norm": 4.562813758850098,
      "learning_rate": 1.9520958083832333e-07,
      "logits/chosen": 1.7760225534439087,
      "logits/rejected": 1.7783151865005493,
      "logps/chosen": -157.9393768310547,
      "logps/rejected": -74.42626953125,
      "loss": 0.25757265090942383,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6515711545944214,
      "rewards/margins": 1.2551637887954712,
      "rewards/rejected": -0.603592574596405,
      "step": 610
    },
    {
      "epoch": 0.6636339309606636,
      "grad_norm": 4.0843706130981445,
      "learning_rate": 1.8922155688622755e-07,
      "logits/chosen": 1.7688944339752197,
      "logits/rejected": 1.844280481338501,
      "logps/chosen": -154.381591796875,
      "logps/rejected": -74.51331329345703,
      "loss": 0.2495283842086792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6801286339759827,
      "rewards/margins": 1.2998765707015991,
      "rewards/rejected": -0.6197479963302612,
      "step": 620
    },
    {
      "epoch": 0.6743377040406744,
      "grad_norm": 4.464092254638672,
      "learning_rate": 1.8323353293413174e-07,
      "logits/chosen": 1.7642539739608765,
      "logits/rejected": 1.8217275142669678,
      "logps/chosen": -157.03182983398438,
      "logps/rejected": -75.87959289550781,
      "loss": 0.2582508325576782,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.612326443195343,
      "rewards/margins": 1.2632255554199219,
      "rewards/rejected": -0.6508990526199341,
      "step": 630
    },
    {
      "epoch": 0.6850414771206851,
      "grad_norm": 4.775583744049072,
      "learning_rate": 1.772455089820359e-07,
      "logits/chosen": 1.7719157934188843,
      "logits/rejected": 1.795090675354004,
      "logps/chosen": -152.7842559814453,
      "logps/rejected": -73.87369537353516,
      "loss": 0.2483595609664917,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6724613904953003,
      "rewards/margins": 1.3094780445098877,
      "rewards/rejected": -0.6370167136192322,
      "step": 640
    },
    {
      "epoch": 0.6957452502006958,
      "grad_norm": 4.444608211517334,
      "learning_rate": 1.7125748502994012e-07,
      "logits/chosen": 1.8310457468032837,
      "logits/rejected": 1.822463035583496,
      "logps/chosen": -152.2064971923828,
      "logps/rejected": -75.70262145996094,
      "loss": 0.22629158496856688,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7540256977081299,
      "rewards/margins": 1.4160101413726807,
      "rewards/rejected": -0.6619843244552612,
      "step": 650
    },
    {
      "epoch": 0.7064490232807065,
      "grad_norm": 3.7854011058807373,
      "learning_rate": 1.6526946107784431e-07,
      "logits/chosen": 1.7527564764022827,
      "logits/rejected": 1.8122169971466064,
      "logps/chosen": -145.171630859375,
      "logps/rejected": -75.68634796142578,
      "loss": 0.23520116806030272,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6973332762718201,
      "rewards/margins": 1.3724817037582397,
      "rewards/rejected": -0.6751484870910645,
      "step": 660
    },
    {
      "epoch": 0.7171527963607172,
      "grad_norm": 4.218249320983887,
      "learning_rate": 1.5928143712574848e-07,
      "logits/chosen": 1.842172384262085,
      "logits/rejected": 1.8595682382583618,
      "logps/chosen": -161.24179077148438,
      "logps/rejected": -75.35706329345703,
      "loss": 0.2325195074081421,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7189681529998779,
      "rewards/margins": 1.3843579292297363,
      "rewards/rejected": -0.6653897762298584,
      "step": 670
    },
    {
      "epoch": 0.7278565694407279,
      "grad_norm": 4.008293151855469,
      "learning_rate": 1.532934131736527e-07,
      "logits/chosen": 1.8072702884674072,
      "logits/rejected": 1.8826110363006592,
      "logps/chosen": -141.64564514160156,
      "logps/rejected": -76.41644287109375,
      "loss": 0.22369613647460937,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7074041366577148,
      "rewards/margins": 1.4123942852020264,
      "rewards/rejected": -0.7049902677536011,
      "step": 680
    },
    {
      "epoch": 0.7385603425207385,
      "grad_norm": 4.202423572540283,
      "learning_rate": 1.473053892215569e-07,
      "logits/chosen": 1.7800133228302002,
      "logits/rejected": 1.773537278175354,
      "logps/chosen": -164.24839782714844,
      "logps/rejected": -75.98621368408203,
      "loss": 0.21926467418670653,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7596831917762756,
      "rewards/margins": 1.452344298362732,
      "rewards/rejected": -0.6926611065864563,
      "step": 690
    },
    {
      "epoch": 0.7492641156007492,
      "grad_norm": 4.192325592041016,
      "learning_rate": 1.4131736526946105e-07,
      "logits/chosen": 1.7708015441894531,
      "logits/rejected": 1.8498165607452393,
      "logps/chosen": -151.57725524902344,
      "logps/rejected": -76.09286499023438,
      "loss": 0.21987359523773192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7453122735023499,
      "rewards/margins": 1.437493920326233,
      "rewards/rejected": -0.6921817064285278,
      "step": 700
    },
    {
      "epoch": 0.7599678886807599,
      "grad_norm": 3.677157163619995,
      "learning_rate": 1.3532934131736525e-07,
      "logits/chosen": 1.82870352268219,
      "logits/rejected": 1.8434333801269531,
      "logps/chosen": -171.95333862304688,
      "logps/rejected": -75.69657897949219,
      "loss": 0.2088693618774414,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7921797037124634,
      "rewards/margins": 1.5008856058120728,
      "rewards/rejected": -0.7087059020996094,
      "step": 710
    },
    {
      "epoch": 0.7706716617607706,
      "grad_norm": 4.000278472900391,
      "learning_rate": 1.2934131736526946e-07,
      "logits/chosen": 1.7920653820037842,
      "logits/rejected": 1.8383643627166748,
      "logps/chosen": -151.28347778320312,
      "logps/rejected": -76.20635986328125,
      "loss": 0.21799991130828858,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7381735444068909,
      "rewards/margins": 1.461441993713379,
      "rewards/rejected": -0.7232683300971985,
      "step": 720
    },
    {
      "epoch": 0.7813754348407814,
      "grad_norm": 4.081520080566406,
      "learning_rate": 1.2335329341317366e-07,
      "logits/chosen": 1.7531280517578125,
      "logits/rejected": 1.7939468622207642,
      "logps/chosen": -150.78189086914062,
      "logps/rejected": -77.31071472167969,
      "loss": 0.2109961986541748,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7555360198020935,
      "rewards/margins": 1.493741750717163,
      "rewards/rejected": -0.7382058501243591,
      "step": 730
    },
    {
      "epoch": 0.7920792079207921,
      "grad_norm": 3.768695592880249,
      "learning_rate": 1.1736526946107785e-07,
      "logits/chosen": 1.8066890239715576,
      "logits/rejected": 1.7843414545059204,
      "logps/chosen": -166.06942749023438,
      "logps/rejected": -76.58885955810547,
      "loss": 0.20064256191253663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8284308314323425,
      "rewards/margins": 1.5588735342025757,
      "rewards/rejected": -0.7304428219795227,
      "step": 740
    },
    {
      "epoch": 0.8027829810008028,
      "grad_norm": 3.7974863052368164,
      "learning_rate": 1.1137724550898203e-07,
      "logits/chosen": 1.8393049240112305,
      "logits/rejected": 1.763546347618103,
      "logps/chosen": -160.11727905273438,
      "logps/rejected": -76.10553741455078,
      "loss": 0.2002436637878418,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7996441721916199,
      "rewards/margins": 1.5484354496002197,
      "rewards/rejected": -0.7487913370132446,
      "step": 750
    },
    {
      "epoch": 0.8134867540808135,
      "grad_norm": 3.5025339126586914,
      "learning_rate": 1.0538922155688622e-07,
      "logits/chosen": 1.6828895807266235,
      "logits/rejected": 1.7686221599578857,
      "logps/chosen": -148.5743865966797,
      "logps/rejected": -75.7417221069336,
      "loss": 0.1993952989578247,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7902451753616333,
      "rewards/margins": 1.5553122758865356,
      "rewards/rejected": -0.7650671005249023,
      "step": 760
    },
    {
      "epoch": 0.8241905271608242,
      "grad_norm": 3.5608770847320557,
      "learning_rate": 9.940119760479042e-08,
      "logits/chosen": 1.7815406322479248,
      "logits/rejected": 1.810638666152954,
      "logps/chosen": -165.80409240722656,
      "logps/rejected": -77.32066345214844,
      "loss": 0.20363078117370606,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7688776254653931,
      "rewards/margins": 1.533996820449829,
      "rewards/rejected": -0.765119194984436,
      "step": 770
    },
    {
      "epoch": 0.8348943002408349,
      "grad_norm": 3.6465699672698975,
      "learning_rate": 9.34131736526946e-08,
      "logits/chosen": 1.773271918296814,
      "logits/rejected": 1.875345230102539,
      "logps/chosen": -160.69137573242188,
      "logps/rejected": -75.8323745727539,
      "loss": 0.2128734827041626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7595525979995728,
      "rewards/margins": 1.4998260736465454,
      "rewards/rejected": -0.7402735948562622,
      "step": 780
    },
    {
      "epoch": 0.8455980733208456,
      "grad_norm": 3.5819716453552246,
      "learning_rate": 8.74251497005988e-08,
      "logits/chosen": 1.7015249729156494,
      "logits/rejected": 1.7957080602645874,
      "logps/chosen": -143.64913940429688,
      "logps/rejected": -76.23876190185547,
      "loss": 0.20468308925628662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7533854246139526,
      "rewards/margins": 1.5298655033111572,
      "rewards/rejected": -0.7764802575111389,
      "step": 790
    },
    {
      "epoch": 0.8563018464008563,
      "grad_norm": 3.6957175731658936,
      "learning_rate": 8.143712574850298e-08,
      "logits/chosen": 1.7430284023284912,
      "logits/rejected": 1.7310165166854858,
      "logps/chosen": -142.98800659179688,
      "logps/rejected": -77.13548278808594,
      "loss": 0.20033652782440187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8011943101882935,
      "rewards/margins": 1.5589643716812134,
      "rewards/rejected": -0.7577700614929199,
      "step": 800
    },
    {
      "epoch": 0.867005619480867,
      "grad_norm": 3.4908666610717773,
      "learning_rate": 7.544910179640718e-08,
      "logits/chosen": 1.8051204681396484,
      "logits/rejected": 1.8428548574447632,
      "logps/chosen": -157.9907684326172,
      "logps/rejected": -76.19637298583984,
      "loss": 0.2028646230697632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7891581058502197,
      "rewards/margins": 1.5372846126556396,
      "rewards/rejected": -0.7481266260147095,
      "step": 810
    },
    {
      "epoch": 0.8777093925608777,
      "grad_norm": 3.413574457168579,
      "learning_rate": 6.946107784431138e-08,
      "logits/chosen": 1.84567129611969,
      "logits/rejected": 1.9074060916900635,
      "logps/chosen": -152.1465301513672,
      "logps/rejected": -76.62020111083984,
      "loss": 0.21140313148498535,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7535273432731628,
      "rewards/margins": 1.5098832845687866,
      "rewards/rejected": -0.756355881690979,
      "step": 820
    },
    {
      "epoch": 0.8884131656408885,
      "grad_norm": 4.057119369506836,
      "learning_rate": 6.347305389221556e-08,
      "logits/chosen": 1.7475643157958984,
      "logits/rejected": 1.8563896417617798,
      "logps/chosen": -145.08657836914062,
      "logps/rejected": -77.3937759399414,
      "loss": 0.20466287136077882,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7540609240531921,
      "rewards/margins": 1.5285966396331787,
      "rewards/rejected": -0.7745357751846313,
      "step": 830
    },
    {
      "epoch": 0.8991169387208992,
      "grad_norm": 3.5540497303009033,
      "learning_rate": 5.748502994011976e-08,
      "logits/chosen": 1.8124555349349976,
      "logits/rejected": 1.8094037771224976,
      "logps/chosen": -163.609375,
      "logps/rejected": -76.10777282714844,
      "loss": 0.1928992509841919,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.81438809633255,
      "rewards/margins": 1.60502028465271,
      "rewards/rejected": -0.7906321287155151,
      "step": 840
    },
    {
      "epoch": 0.9098207118009098,
      "grad_norm": 3.027778148651123,
      "learning_rate": 5.149700598802395e-08,
      "logits/chosen": 1.82096266746521,
      "logits/rejected": 1.8043569326400757,
      "logps/chosen": -164.63235473632812,
      "logps/rejected": -76.35253143310547,
      "loss": 0.18926966190338135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8419148325920105,
      "rewards/margins": 1.6187918186187744,
      "rewards/rejected": -0.7768768668174744,
      "step": 850
    },
    {
      "epoch": 0.9205244848809205,
      "grad_norm": 3.256948709487915,
      "learning_rate": 4.550898203592814e-08,
      "logits/chosen": 1.7957160472869873,
      "logits/rejected": 1.8420108556747437,
      "logps/chosen": -153.01101684570312,
      "logps/rejected": -76.40182495117188,
      "loss": 0.19676823616027833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7768832445144653,
      "rewards/margins": 1.5621328353881836,
      "rewards/rejected": -0.7852495908737183,
      "step": 860
    },
    {
      "epoch": 0.9312282579609312,
      "grad_norm": 3.446423053741455,
      "learning_rate": 3.952095808383234e-08,
      "logits/chosen": 1.771644949913025,
      "logits/rejected": 1.8672726154327393,
      "logps/chosen": -164.06820678710938,
      "logps/rejected": -77.83936309814453,
      "loss": 0.1974401593208313,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8127962350845337,
      "rewards/margins": 1.597415566444397,
      "rewards/rejected": -0.7846193313598633,
      "step": 870
    },
    {
      "epoch": 0.9419320310409419,
      "grad_norm": 4.122663497924805,
      "learning_rate": 3.3532934131736525e-08,
      "logits/chosen": 1.768355131149292,
      "logits/rejected": 1.8592029809951782,
      "logps/chosen": -148.32101440429688,
      "logps/rejected": -76.7317886352539,
      "loss": 0.20341129302978517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.744165301322937,
      "rewards/margins": 1.5407825708389282,
      "rewards/rejected": -0.7966172695159912,
      "step": 880
    },
    {
      "epoch": 0.9526358041209526,
      "grad_norm": 3.4265670776367188,
      "learning_rate": 2.7544910179640717e-08,
      "logits/chosen": 1.7579742670059204,
      "logits/rejected": 1.778061866760254,
      "logps/chosen": -159.0396270751953,
      "logps/rejected": -77.5861587524414,
      "loss": 0.20180206298828124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7456262111663818,
      "rewards/margins": 1.5595744848251343,
      "rewards/rejected": -0.8139484524726868,
      "step": 890
    },
    {
      "epoch": 0.9633395772009633,
      "grad_norm": 3.863522529602051,
      "learning_rate": 2.155688622754491e-08,
      "logits/chosen": 1.7837326526641846,
      "logits/rejected": 1.8484779596328735,
      "logps/chosen": -145.44798278808594,
      "logps/rejected": -77.45049285888672,
      "loss": 0.17784547805786133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8759862184524536,
      "rewards/margins": 1.6860586404800415,
      "rewards/rejected": -0.8100724220275879,
      "step": 900
    },
    {
      "epoch": 0.974043350280974,
      "grad_norm": 3.5212888717651367,
      "learning_rate": 1.55688622754491e-08,
      "logits/chosen": 1.7927160263061523,
      "logits/rejected": 1.8502790927886963,
      "logps/chosen": -154.87783813476562,
      "logps/rejected": -77.52911376953125,
      "loss": 0.19511414766311647,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7969852685928345,
      "rewards/margins": 1.59688401222229,
      "rewards/rejected": -0.7998989224433899,
      "step": 910
    },
    {
      "epoch": 0.9847471233609848,
      "grad_norm": 3.6904828548431396,
      "learning_rate": 9.580838323353294e-09,
      "logits/chosen": 1.8739761114120483,
      "logits/rejected": 1.8596941232681274,
      "logps/chosen": -179.69027709960938,
      "logps/rejected": -77.27470397949219,
      "loss": 0.178732967376709,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8943001627922058,
      "rewards/margins": 1.6837539672851562,
      "rewards/rejected": -0.7894536256790161,
      "step": 920
    },
    {
      "epoch": 0.9954508964409955,
      "grad_norm": 3.098395586013794,
      "learning_rate": 3.592814371257485e-09,
      "logits/chosen": 1.7877063751220703,
      "logits/rejected": 1.8167951107025146,
      "logps/chosen": -147.87942504882812,
      "logps/rejected": -77.22559356689453,
      "loss": 0.19081155061721802,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8000432848930359,
      "rewards/margins": 1.602046251296997,
      "rewards/rejected": -0.802003026008606,
      "step": 930
    }
  ],
  "logging_steps": 10,
  "max_steps": 935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
