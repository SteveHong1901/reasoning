{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 934,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010706638115631691,
      "grad_norm": 7.741055011749268,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.6414082050323486,
      "logits/rejected": 1.6470849514007568,
      "logps/chosen": -137.65316772460938,
      "logps/rejected": -68.58262634277344,
      "loss": 0.6921837806701661,
      "rewards/accuracies": 0.3499999940395355,
      "rewards/chosen": 0.0018970727687701583,
      "rewards/margins": 0.002223605988547206,
      "rewards/rejected": -0.0003265332488808781,
      "step": 10
    },
    {
      "epoch": 0.021413276231263382,
      "grad_norm": 8.083742141723633,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.6303012371063232,
      "logits/rejected": 1.619828462600708,
      "logps/chosen": -127.005615234375,
      "logps/rejected": -69.37870025634766,
      "loss": 0.6981179237365722,
      "rewards/accuracies": 0.4000000059604645,
      "rewards/chosen": -0.007431450299918652,
      "rewards/margins": -0.009424667805433273,
      "rewards/rejected": 0.001993217272683978,
      "step": 20
    },
    {
      "epoch": 0.032119914346895075,
      "grad_norm": 8.292325019836426,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.6350021362304688,
      "logits/rejected": 1.6774721145629883,
      "logps/chosen": -132.09512329101562,
      "logps/rejected": -68.65172576904297,
      "loss": 0.6949917793273925,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.004879589658230543,
      "rewards/margins": -0.0032155707012861967,
      "rewards/rejected": -0.001664018607698381,
      "step": 30
    },
    {
      "epoch": 0.042826552462526764,
      "grad_norm": 8.421181678771973,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.5207608938217163,
      "logits/rejected": 1.6680008172988892,
      "logps/chosen": -123.42039489746094,
      "logps/rejected": -69.3780517578125,
      "loss": 0.6928003311157227,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -0.0022781279403716326,
      "rewards/margins": 0.001274451962672174,
      "rewards/rejected": -0.0035525797866284847,
      "step": 40
    },
    {
      "epoch": 0.05353319057815846,
      "grad_norm": 7.814224720001221,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.7590328454971313,
      "logits/rejected": 1.623600721359253,
      "logps/chosen": -146.6126251220703,
      "logps/rejected": -69.6846923828125,
      "loss": 0.6869121074676514,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.009453506208956242,
      "rewards/margins": 0.013024091720581055,
      "rewards/rejected": -0.0035705850459635258,
      "step": 50
    },
    {
      "epoch": 0.06423982869379015,
      "grad_norm": 7.7611212730407715,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.5742673873901367,
      "logits/rejected": 1.661669135093689,
      "logps/chosen": -128.58689880371094,
      "logps/rejected": -68.86058807373047,
      "loss": 0.6956583976745605,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -0.0024095436092466116,
      "rewards/margins": -0.004303164780139923,
      "rewards/rejected": 0.0018936205888167024,
      "step": 60
    },
    {
      "epoch": 0.07494646680942184,
      "grad_norm": 8.805891990661621,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.6264060735702515,
      "logits/rejected": 1.6312564611434937,
      "logps/chosen": -131.72048950195312,
      "logps/rejected": -68.80120849609375,
      "loss": 0.6938254833221436,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.0010343979811295867,
      "rewards/margins": -0.0007398080197162926,
      "rewards/rejected": 0.001774206175468862,
      "step": 70
    },
    {
      "epoch": 0.08565310492505353,
      "grad_norm": 8.418060302734375,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.6953182220458984,
      "logits/rejected": 1.7030633687973022,
      "logps/chosen": -133.45242309570312,
      "logps/rejected": -68.4122543334961,
      "loss": 0.6912439346313477,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00254586199298501,
      "rewards/margins": 0.004318948369473219,
      "rewards/rejected": -0.006864809896796942,
      "step": 80
    },
    {
      "epoch": 0.09635974304068523,
      "grad_norm": 8.60579776763916,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.6077579259872437,
      "logits/rejected": 1.6657851934432983,
      "logps/chosen": -122.4295883178711,
      "logps/rejected": -69.25360870361328,
      "loss": 0.6869400978088379,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.009872857481241226,
      "rewards/margins": 0.013005204498767853,
      "rewards/rejected": -0.003132348181679845,
      "step": 90
    },
    {
      "epoch": 0.10706638115631692,
      "grad_norm": 8.464462280273438,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.6527435779571533,
      "logits/rejected": 1.61818528175354,
      "logps/chosen": -134.21189880371094,
      "logps/rejected": -68.3548812866211,
      "loss": 0.68349289894104,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.013684412464499474,
      "rewards/margins": 0.020024046301841736,
      "rewards/rejected": -0.006339636631309986,
      "step": 100
    },
    {
      "epoch": 0.11777301927194861,
      "grad_norm": 7.88031005859375,
      "learning_rate": 4.946043165467625e-07,
      "logits/chosen": 1.5999301671981812,
      "logits/rejected": 1.6902990341186523,
      "logps/chosen": -121.95326232910156,
      "logps/rejected": -68.95580291748047,
      "loss": 0.6762250900268555,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.02649036981165409,
      "rewards/margins": 0.03455853834748268,
      "rewards/rejected": -0.008068164810538292,
      "step": 110
    },
    {
      "epoch": 0.1284796573875803,
      "grad_norm": 8.902802467346191,
      "learning_rate": 4.886091127098321e-07,
      "logits/chosen": 1.5206339359283447,
      "logits/rejected": 1.7172397375106812,
      "logps/chosen": -111.86238861083984,
      "logps/rejected": -69.06817626953125,
      "loss": 0.6703062057495117,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": 0.028182417154312134,
      "rewards/margins": 0.04670344293117523,
      "rewards/rejected": -0.01852102391421795,
      "step": 120
    },
    {
      "epoch": 0.139186295503212,
      "grad_norm": 8.137377738952637,
      "learning_rate": 4.826139088729016e-07,
      "logits/chosen": 1.6242367029190063,
      "logits/rejected": 1.6543670892715454,
      "logps/chosen": -127.9379653930664,
      "logps/rejected": -68.19505310058594,
      "loss": 0.6634600639343262,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03936268761754036,
      "rewards/margins": 0.060975514352321625,
      "rewards/rejected": -0.021612826734781265,
      "step": 130
    },
    {
      "epoch": 0.14989293361884368,
      "grad_norm": 8.199177742004395,
      "learning_rate": 4.7661870503597116e-07,
      "logits/chosen": 1.5829235315322876,
      "logits/rejected": 1.668872594833374,
      "logps/chosen": -130.53536987304688,
      "logps/rejected": -69.46643829345703,
      "loss": 0.6529661178588867,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": 0.052739500999450684,
      "rewards/margins": 0.0826331079006195,
      "rewards/rejected": -0.029893606901168823,
      "step": 140
    },
    {
      "epoch": 0.16059957173447537,
      "grad_norm": 8.568166732788086,
      "learning_rate": 4.706235011990408e-07,
      "logits/chosen": 1.6092227697372437,
      "logits/rejected": 1.6694523096084595,
      "logps/chosen": -135.5042266845703,
      "logps/rejected": -68.8786849975586,
      "loss": 0.6507787227630615,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.04855255037546158,
      "rewards/margins": 0.087519571185112,
      "rewards/rejected": -0.03896702826023102,
      "step": 150
    },
    {
      "epoch": 0.17130620985010706,
      "grad_norm": 7.989839553833008,
      "learning_rate": 4.646282973621103e-07,
      "logits/chosen": 1.5869275331497192,
      "logits/rejected": 1.6636018753051758,
      "logps/chosen": -121.2269515991211,
      "logps/rejected": -68.49610900878906,
      "loss": 0.6393714904785156,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.0738278329372406,
      "rewards/margins": 0.11129005998373032,
      "rewards/rejected": -0.03746223822236061,
      "step": 160
    },
    {
      "epoch": 0.18201284796573874,
      "grad_norm": 7.484827041625977,
      "learning_rate": 4.586330935251798e-07,
      "logits/chosen": 1.5921857357025146,
      "logits/rejected": 1.6428565979003906,
      "logps/chosen": -128.2965850830078,
      "logps/rejected": -70.21226501464844,
      "loss": 0.6311060428619385,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.0793221965432167,
      "rewards/margins": 0.12913191318511963,
      "rewards/rejected": -0.04980972781777382,
      "step": 170
    },
    {
      "epoch": 0.19271948608137046,
      "grad_norm": 7.462615489959717,
      "learning_rate": 4.526378896882494e-07,
      "logits/chosen": 1.5806759595870972,
      "logits/rejected": 1.6912168264389038,
      "logps/chosen": -124.4361801147461,
      "logps/rejected": -68.71379089355469,
      "loss": 0.6198153972625733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09824083745479584,
      "rewards/margins": 0.15375441312789917,
      "rewards/rejected": -0.055513571947813034,
      "step": 180
    },
    {
      "epoch": 0.20342612419700215,
      "grad_norm": 7.844651222229004,
      "learning_rate": 4.466426858513189e-07,
      "logits/chosen": 1.6462863683700562,
      "logits/rejected": 1.7085870504379272,
      "logps/chosen": -128.85494995117188,
      "logps/rejected": -70.08350372314453,
      "loss": 0.6158407211303711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0967750996351242,
      "rewards/margins": 0.16226157546043396,
      "rewards/rejected": -0.06548646837472916,
      "step": 190
    },
    {
      "epoch": 0.21413276231263384,
      "grad_norm": 7.200769901275635,
      "learning_rate": 4.4064748201438843e-07,
      "logits/chosen": 1.6285110712051392,
      "logits/rejected": 1.7047147750854492,
      "logps/chosen": -127.4510269165039,
      "logps/rejected": -70.01476287841797,
      "loss": 0.5973907947540283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11917439848184586,
      "rewards/margins": 0.20283634960651398,
      "rewards/rejected": -0.08366195112466812,
      "step": 200
    },
    {
      "epoch": 0.22483940042826553,
      "grad_norm": 8.171895027160645,
      "learning_rate": 4.3465227817745806e-07,
      "logits/chosen": 1.508737564086914,
      "logits/rejected": 1.6937510967254639,
      "logps/chosen": -115.48828125,
      "logps/rejected": -69.54158782958984,
      "loss": 0.5904012680053711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12961935997009277,
      "rewards/margins": 0.2190200537443161,
      "rewards/rejected": -0.08940066397190094,
      "step": 210
    },
    {
      "epoch": 0.23554603854389722,
      "grad_norm": 8.254551887512207,
      "learning_rate": 4.286570743405276e-07,
      "logits/chosen": 1.6269643306732178,
      "logits/rejected": 1.7915422916412354,
      "logps/chosen": -138.51356506347656,
      "logps/rejected": -70.59925842285156,
      "loss": 0.5724263668060303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16693195700645447,
      "rewards/margins": 0.25981515645980835,
      "rewards/rejected": -0.09288317710161209,
      "step": 220
    },
    {
      "epoch": 0.2462526766595289,
      "grad_norm": 7.195977210998535,
      "learning_rate": 4.226618705035971e-07,
      "logits/chosen": 1.6350101232528687,
      "logits/rejected": 1.6930118799209595,
      "logps/chosen": -114.0125732421875,
      "logps/rejected": -69.8135986328125,
      "loss": 0.5691221714019775,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1704360544681549,
      "rewards/margins": 0.26742976903915405,
      "rewards/rejected": -0.09699370712041855,
      "step": 230
    },
    {
      "epoch": 0.2569593147751606,
      "grad_norm": 7.002618312835693,
      "learning_rate": 4.1666666666666667e-07,
      "logits/chosen": 1.6395642757415771,
      "logits/rejected": 1.6769828796386719,
      "logps/chosen": -132.30322265625,
      "logps/rejected": -70.18910217285156,
      "loss": 0.5501570701599121,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19723379611968994,
      "rewards/margins": 0.31206417083740234,
      "rewards/rejected": -0.11483035236597061,
      "step": 240
    },
    {
      "epoch": 0.2676659528907923,
      "grad_norm": 8.010068893432617,
      "learning_rate": 4.106714628297362e-07,
      "logits/chosen": 1.6982170343399048,
      "logits/rejected": 1.7445398569107056,
      "logps/chosen": -136.2633514404297,
      "logps/rejected": -70.20318603515625,
      "loss": 0.5497150897979737,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1870913803577423,
      "rewards/margins": 0.3127710819244385,
      "rewards/rejected": -0.12567973136901855,
      "step": 250
    },
    {
      "epoch": 0.278372591006424,
      "grad_norm": 8.242047309875488,
      "learning_rate": 4.046762589928057e-07,
      "logits/chosen": 1.6161391735076904,
      "logits/rejected": 1.7438112497329712,
      "logps/chosen": -124.64337158203125,
      "logps/rejected": -70.76585388183594,
      "loss": 0.531620454788208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22497472167015076,
      "rewards/margins": 0.3578566610813141,
      "rewards/rejected": -0.13288193941116333,
      "step": 260
    },
    {
      "epoch": 0.2890792291220557,
      "grad_norm": 6.686182498931885,
      "learning_rate": 3.9868105515587533e-07,
      "logits/chosen": 1.624447226524353,
      "logits/rejected": 1.7339435815811157,
      "logps/chosen": -128.43740844726562,
      "logps/rejected": -70.68250274658203,
      "loss": 0.5293261051177979,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21388402581214905,
      "rewards/margins": 0.36366376280784607,
      "rewards/rejected": -0.14977972209453583,
      "step": 270
    },
    {
      "epoch": 0.29978586723768735,
      "grad_norm": 6.167685031890869,
      "learning_rate": 3.9268585131894485e-07,
      "logits/chosen": 1.6475884914398193,
      "logits/rejected": 1.6943752765655518,
      "logps/chosen": -120.843505859375,
      "logps/rejected": -69.97770690917969,
      "loss": 0.5203248977661132,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.22276143729686737,
      "rewards/margins": 0.3866351544857025,
      "rewards/rejected": -0.16387371718883514,
      "step": 280
    },
    {
      "epoch": 0.31049250535331907,
      "grad_norm": 7.911632537841797,
      "learning_rate": 3.8669064748201436e-07,
      "logits/chosen": 1.6980562210083008,
      "logits/rejected": 1.7317081689834595,
      "logps/chosen": -138.04588317871094,
      "logps/rejected": -70.97135925292969,
      "loss": 0.4880954742431641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2969769537448883,
      "rewards/margins": 0.4678518772125244,
      "rewards/rejected": -0.17087490856647491,
      "step": 290
    },
    {
      "epoch": 0.32119914346895073,
      "grad_norm": 7.79892635345459,
      "learning_rate": 3.8069544364508394e-07,
      "logits/chosen": 1.7201478481292725,
      "logits/rejected": 1.764155387878418,
      "logps/chosen": -130.9140625,
      "logps/rejected": -70.36097717285156,
      "loss": 0.48144874572753904,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28139516711235046,
      "rewards/margins": 0.48678502440452576,
      "rewards/rejected": -0.2053898572921753,
      "step": 300
    },
    {
      "epoch": 0.33190578158458245,
      "grad_norm": 7.8517231941223145,
      "learning_rate": 3.7470023980815345e-07,
      "logits/chosen": 1.7134841680526733,
      "logits/rejected": 1.722998857498169,
      "logps/chosen": -141.0425262451172,
      "logps/rejected": -70.40679168701172,
      "loss": 0.4679696083068848,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3205703794956207,
      "rewards/margins": 0.5223708152770996,
      "rewards/rejected": -0.20180043578147888,
      "step": 310
    },
    {
      "epoch": 0.3426124197002141,
      "grad_norm": 6.915214538574219,
      "learning_rate": 3.6870503597122297e-07,
      "logits/chosen": 1.6239919662475586,
      "logits/rejected": 1.774981141090393,
      "logps/chosen": -121.45024108886719,
      "logps/rejected": -71.14373779296875,
      "loss": 0.46284775733947753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31710928678512573,
      "rewards/margins": 0.5380560159683228,
      "rewards/rejected": -0.22094669938087463,
      "step": 320
    },
    {
      "epoch": 0.3533190578158458,
      "grad_norm": 7.145328044891357,
      "learning_rate": 3.627098321342926e-07,
      "logits/chosen": 1.7421276569366455,
      "logits/rejected": 1.775216817855835,
      "logps/chosen": -130.68710327148438,
      "logps/rejected": -70.46624755859375,
      "loss": 0.4475550174713135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3369230329990387,
      "rewards/margins": 0.5787224769592285,
      "rewards/rejected": -0.24179942905902863,
      "step": 330
    },
    {
      "epoch": 0.3640256959314775,
      "grad_norm": 6.632793426513672,
      "learning_rate": 3.567146282973621e-07,
      "logits/chosen": 1.7010889053344727,
      "logits/rejected": 1.776019811630249,
      "logps/chosen": -144.11822509765625,
      "logps/rejected": -71.8785400390625,
      "loss": 0.43529491424560546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34599921107292175,
      "rewards/margins": 0.6157651543617249,
      "rewards/rejected": -0.2697659432888031,
      "step": 340
    },
    {
      "epoch": 0.3747323340471092,
      "grad_norm": 6.380807876586914,
      "learning_rate": 3.5071942446043163e-07,
      "logits/chosen": 1.6991281509399414,
      "logits/rejected": 1.720046043395996,
      "logps/chosen": -128.89962768554688,
      "logps/rejected": -70.43315124511719,
      "loss": 0.42685937881469727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3807167410850525,
      "rewards/margins": 0.6443994641304016,
      "rewards/rejected": -0.26368266344070435,
      "step": 350
    },
    {
      "epoch": 0.3854389721627409,
      "grad_norm": 6.079395294189453,
      "learning_rate": 3.447242206235012e-07,
      "logits/chosen": 1.7227891683578491,
      "logits/rejected": 1.852887511253357,
      "logps/chosen": -123.9052734375,
      "logps/rejected": -72.29902648925781,
      "loss": 0.42282629013061523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3517988324165344,
      "rewards/margins": 0.6531723737716675,
      "rewards/rejected": -0.30137357115745544,
      "step": 360
    },
    {
      "epoch": 0.3961456102783726,
      "grad_norm": 6.3076910972595215,
      "learning_rate": 3.387290167865707e-07,
      "logits/chosen": 1.774964690208435,
      "logits/rejected": 1.7948055267333984,
      "logps/chosen": -127.28727722167969,
      "logps/rejected": -72.2643814086914,
      "loss": 0.4216721534729004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35563454031944275,
      "rewards/margins": 0.6565887928009033,
      "rewards/rejected": -0.30095428228378296,
      "step": 370
    },
    {
      "epoch": 0.4068522483940043,
      "grad_norm": 6.376628398895264,
      "learning_rate": 3.3273381294964024e-07,
      "logits/chosen": 1.6560760736465454,
      "logits/rejected": 1.7717841863632202,
      "logps/chosen": -122.11065673828125,
      "logps/rejected": -72.16600799560547,
      "loss": 0.3968196392059326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4199541211128235,
      "rewards/margins": 0.7303374409675598,
      "rewards/rejected": -0.31038329005241394,
      "step": 380
    },
    {
      "epoch": 0.41755888650963596,
      "grad_norm": 6.101396083831787,
      "learning_rate": 3.2673860911270987e-07,
      "logits/chosen": 1.7897109985351562,
      "logits/rejected": 1.7782552242279053,
      "logps/chosen": -133.59283447265625,
      "logps/rejected": -71.7552490234375,
      "loss": 0.4028975009918213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.391545832157135,
      "rewards/margins": 0.7166863679885864,
      "rewards/rejected": -0.3251405358314514,
      "step": 390
    },
    {
      "epoch": 0.4282655246252677,
      "grad_norm": 5.62619686126709,
      "learning_rate": 3.207434052757794e-07,
      "logits/chosen": 1.7085297107696533,
      "logits/rejected": 1.768411636352539,
      "logps/chosen": -120.59797668457031,
      "logps/rejected": -72.63621520996094,
      "loss": 0.39118590354919436,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4118087887763977,
      "rewards/margins": 0.7474412322044373,
      "rewards/rejected": -0.3356325328350067,
      "step": 400
    },
    {
      "epoch": 0.43897216274089934,
      "grad_norm": 5.362334728240967,
      "learning_rate": 3.147482014388489e-07,
      "logits/chosen": 1.6492512226104736,
      "logits/rejected": 1.7654674053192139,
      "logps/chosen": -112.69343566894531,
      "logps/rejected": -72.82518005371094,
      "loss": 0.37764360904693606,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4518015384674072,
      "rewards/margins": 0.7963234186172485,
      "rewards/rejected": -0.34452182054519653,
      "step": 410
    },
    {
      "epoch": 0.44967880085653106,
      "grad_norm": 5.973454475402832,
      "learning_rate": 3.087529976019185e-07,
      "logits/chosen": 1.6632111072540283,
      "logits/rejected": 1.8019161224365234,
      "logps/chosen": -120.314697265625,
      "logps/rejected": -71.65013122558594,
      "loss": 0.35718631744384766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47905999422073364,
      "rewards/margins": 0.8620496988296509,
      "rewards/rejected": -0.38298970460891724,
      "step": 420
    },
    {
      "epoch": 0.4603854389721627,
      "grad_norm": 5.460209846496582,
      "learning_rate": 3.02757793764988e-07,
      "logits/chosen": 1.773888349533081,
      "logits/rejected": 1.8037201166152954,
      "logps/chosen": -132.87957763671875,
      "logps/rejected": -73.58642578125,
      "loss": 0.3468312740325928,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4960877001285553,
      "rewards/margins": 0.8990741968154907,
      "rewards/rejected": -0.40298646688461304,
      "step": 430
    },
    {
      "epoch": 0.47109207708779444,
      "grad_norm": 5.701747417449951,
      "learning_rate": 2.967625899280575e-07,
      "logits/chosen": 1.669395089149475,
      "logits/rejected": 1.7530901432037354,
      "logps/chosen": -131.12820434570312,
      "logps/rejected": -72.90501403808594,
      "loss": 0.3360680103302002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.512489914894104,
      "rewards/margins": 0.9309952855110168,
      "rewards/rejected": -0.4185052812099457,
      "step": 440
    },
    {
      "epoch": 0.4817987152034261,
      "grad_norm": 5.458523273468018,
      "learning_rate": 2.907673860911271e-07,
      "logits/chosen": 1.7761256694793701,
      "logits/rejected": 1.8283132314682007,
      "logps/chosen": -117.85076904296875,
      "logps/rejected": -72.65133666992188,
      "loss": 0.3489613771438599,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46487587690353394,
      "rewards/margins": 0.8949135541915894,
      "rewards/rejected": -0.43003764748573303,
      "step": 450
    },
    {
      "epoch": 0.4925053533190578,
      "grad_norm": 5.306919097900391,
      "learning_rate": 2.8477218225419665e-07,
      "logits/chosen": 1.7203201055526733,
      "logits/rejected": 1.7541296482086182,
      "logps/chosen": -119.7204360961914,
      "logps/rejected": -73.51383972167969,
      "loss": 0.3401479721069336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49809685349464417,
      "rewards/margins": 0.9191838502883911,
      "rewards/rejected": -0.42108696699142456,
      "step": 460
    },
    {
      "epoch": 0.5032119914346895,
      "grad_norm": 5.2116875648498535,
      "learning_rate": 2.7877697841726617e-07,
      "logits/chosen": 1.652305245399475,
      "logits/rejected": 1.7981897592544556,
      "logps/chosen": -118.83565521240234,
      "logps/rejected": -74.01769256591797,
      "loss": 0.3251779556274414,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5207119584083557,
      "rewards/margins": 0.9744011163711548,
      "rewards/rejected": -0.4536890387535095,
      "step": 470
    },
    {
      "epoch": 0.5139186295503212,
      "grad_norm": 5.218020915985107,
      "learning_rate": 2.7278177458033574e-07,
      "logits/chosen": 1.689134955406189,
      "logits/rejected": 1.8135219812393188,
      "logps/chosen": -126.3836898803711,
      "logps/rejected": -74.37802124023438,
      "loss": 0.30874269008636473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5642669200897217,
      "rewards/margins": 1.040651559829712,
      "rewards/rejected": -0.4763847291469574,
      "step": 480
    },
    {
      "epoch": 0.5246252676659529,
      "grad_norm": 5.253102779388428,
      "learning_rate": 2.6678657074340526e-07,
      "logits/chosen": 1.6579649448394775,
      "logits/rejected": 1.7480230331420898,
      "logps/chosen": -120.4889907836914,
      "logps/rejected": -75.39362335205078,
      "loss": 0.30684971809387207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5676183104515076,
      "rewards/margins": 1.0471782684326172,
      "rewards/rejected": -0.479559987783432,
      "step": 490
    },
    {
      "epoch": 0.5353319057815846,
      "grad_norm": 4.98911190032959,
      "learning_rate": 2.607913669064748e-07,
      "logits/chosen": 1.7070884704589844,
      "logits/rejected": 1.7949190139770508,
      "logps/chosen": -126.05009460449219,
      "logps/rejected": -73.45948791503906,
      "loss": 0.3099621534347534,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5381681323051453,
      "rewards/margins": 1.0409502983093262,
      "rewards/rejected": -0.5027821660041809,
      "step": 500
    },
    {
      "epoch": 0.5460385438972163,
      "grad_norm": 5.080059051513672,
      "learning_rate": 2.5479616306954435e-07,
      "logits/chosen": 1.710519790649414,
      "logits/rejected": 1.8033726215362549,
      "logps/chosen": -126.8452377319336,
      "logps/rejected": -73.09700012207031,
      "loss": 0.28525409698486326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.598856508731842,
      "rewards/margins": 1.1315557956695557,
      "rewards/rejected": -0.5326992273330688,
      "step": 510
    },
    {
      "epoch": 0.556745182012848,
      "grad_norm": 4.233483791351318,
      "learning_rate": 2.488009592326139e-07,
      "logits/chosen": 1.6786012649536133,
      "logits/rejected": 1.8425419330596924,
      "logps/chosen": -117.54249572753906,
      "logps/rejected": -74.08181762695312,
      "loss": 0.28357853889465334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.575531542301178,
      "rewards/margins": 1.1330516338348389,
      "rewards/rejected": -0.5575200915336609,
      "step": 520
    },
    {
      "epoch": 0.5674518201284796,
      "grad_norm": 4.390888690948486,
      "learning_rate": 2.4280575539568344e-07,
      "logits/chosen": 1.8111200332641602,
      "logits/rejected": 1.8582439422607422,
      "logps/chosen": -137.2392578125,
      "logps/rejected": -74.18267822265625,
      "loss": 0.2889716386795044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.558294415473938,
      "rewards/margins": 1.1135143041610718,
      "rewards/rejected": -0.5552199482917786,
      "step": 530
    },
    {
      "epoch": 0.5781584582441114,
      "grad_norm": 4.521941184997559,
      "learning_rate": 2.36810551558753e-07,
      "logits/chosen": 1.6920150518417358,
      "logits/rejected": 1.830157995223999,
      "logps/chosen": -116.1943359375,
      "logps/rejected": -73.59584045410156,
      "loss": 0.28380208015441893,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5645123720169067,
      "rewards/margins": 1.1412439346313477,
      "rewards/rejected": -0.5767315626144409,
      "step": 540
    },
    {
      "epoch": 0.588865096359743,
      "grad_norm": 4.318889141082764,
      "learning_rate": 2.3081534772182253e-07,
      "logits/chosen": 1.773702621459961,
      "logits/rejected": 1.8475840091705322,
      "logps/chosen": -124.20045471191406,
      "logps/rejected": -75.20610046386719,
      "loss": 0.28837625980377196,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5401887893676758,
      "rewards/margins": 1.1251903772354126,
      "rewards/rejected": -0.5850016474723816,
      "step": 550
    },
    {
      "epoch": 0.5995717344753747,
      "grad_norm": 4.768591403961182,
      "learning_rate": 2.2482014388489208e-07,
      "logits/chosen": 1.6853084564208984,
      "logits/rejected": 1.8405544757843018,
      "logps/chosen": -126.73388671875,
      "logps/rejected": -74.65670776367188,
      "loss": 0.2508845806121826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6821274161338806,
      "rewards/margins": 1.27914297580719,
      "rewards/rejected": -0.5970155000686646,
      "step": 560
    },
    {
      "epoch": 0.6102783725910065,
      "grad_norm": 4.827847957611084,
      "learning_rate": 2.1882494004796162e-07,
      "logits/chosen": 1.7210123538970947,
      "logits/rejected": 1.8483874797821045,
      "logps/chosen": -128.68051147460938,
      "logps/rejected": -75.97867584228516,
      "loss": 0.26710333824157717,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5934797525405884,
      "rewards/margins": 1.2076417207717896,
      "rewards/rejected": -0.6141620874404907,
      "step": 570
    },
    {
      "epoch": 0.6209850107066381,
      "grad_norm": 4.393861770629883,
      "learning_rate": 2.1282973621103117e-07,
      "logits/chosen": 1.6337378025054932,
      "logits/rejected": 1.784625768661499,
      "logps/chosen": -128.12469482421875,
      "logps/rejected": -75.03962707519531,
      "loss": 0.2407306909561157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7097516655921936,
      "rewards/margins": 1.3472645282745361,
      "rewards/rejected": -0.6375128030776978,
      "step": 580
    },
    {
      "epoch": 0.6316916488222698,
      "grad_norm": 4.014122486114502,
      "learning_rate": 2.068345323741007e-07,
      "logits/chosen": 1.660386085510254,
      "logits/rejected": 1.8268568515777588,
      "logps/chosen": -113.23500061035156,
      "logps/rejected": -75.56747436523438,
      "loss": 0.2566499710083008,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6165817975997925,
      "rewards/margins": 1.26558518409729,
      "rewards/rejected": -0.6490033864974976,
      "step": 590
    },
    {
      "epoch": 0.6423982869379015,
      "grad_norm": 4.061091423034668,
      "learning_rate": 2.0083932853717026e-07,
      "logits/chosen": 1.7788536548614502,
      "logits/rejected": 1.7796669006347656,
      "logps/chosen": -120.18672180175781,
      "logps/rejected": -76.9682846069336,
      "loss": 0.2636215925216675,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6143745183944702,
      "rewards/margins": 1.240124225616455,
      "rewards/rejected": -0.6257497072219849,
      "step": 600
    },
    {
      "epoch": 0.6531049250535332,
      "grad_norm": 4.446260929107666,
      "learning_rate": 1.948441247002398e-07,
      "logits/chosen": 1.7830482721328735,
      "logits/rejected": 1.8380438089370728,
      "logps/chosen": -123.80690002441406,
      "logps/rejected": -75.86262512207031,
      "loss": 0.23748352527618408,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6719506978988647,
      "rewards/margins": 1.35470449924469,
      "rewards/rejected": -0.68275386095047,
      "step": 610
    },
    {
      "epoch": 0.6638115631691649,
      "grad_norm": 4.4706034660339355,
      "learning_rate": 1.8884892086330935e-07,
      "logits/chosen": 1.7464931011199951,
      "logits/rejected": 1.8366960287094116,
      "logps/chosen": -130.46652221679688,
      "logps/rejected": -75.16764068603516,
      "loss": 0.2418867826461792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6472615003585815,
      "rewards/margins": 1.3315235376358032,
      "rewards/rejected": -0.6842619180679321,
      "step": 620
    },
    {
      "epoch": 0.6745182012847966,
      "grad_norm": 3.8721132278442383,
      "learning_rate": 1.828537170263789e-07,
      "logits/chosen": 1.6891098022460938,
      "logits/rejected": 1.7846769094467163,
      "logps/chosen": -107.69210052490234,
      "logps/rejected": -76.06917572021484,
      "loss": 0.23472177982330322,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6701866984367371,
      "rewards/margins": 1.3656688928604126,
      "rewards/rejected": -0.695482075214386,
      "step": 630
    },
    {
      "epoch": 0.6852248394004282,
      "grad_norm": 4.301502704620361,
      "learning_rate": 1.7685851318944844e-07,
      "logits/chosen": 1.745737075805664,
      "logits/rejected": 1.7761989831924438,
      "logps/chosen": -123.03749084472656,
      "logps/rejected": -76.24909210205078,
      "loss": 0.23537299633026124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6527010202407837,
      "rewards/margins": 1.3576396703720093,
      "rewards/rejected": -0.7049387097358704,
      "step": 640
    },
    {
      "epoch": 0.69593147751606,
      "grad_norm": 3.7346885204315186,
      "learning_rate": 1.7086330935251798e-07,
      "logits/chosen": 1.71116042137146,
      "logits/rejected": 1.820535659790039,
      "logps/chosen": -126.1988296508789,
      "logps/rejected": -75.85347747802734,
      "loss": 0.2228600025177002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6963850855827332,
      "rewards/margins": 1.4305223226547241,
      "rewards/rejected": -0.7341370582580566,
      "step": 650
    },
    {
      "epoch": 0.7066381156316917,
      "grad_norm": 3.520128011703491,
      "learning_rate": 1.6486810551558753e-07,
      "logits/chosen": 1.6407934427261353,
      "logits/rejected": 1.8003027439117432,
      "logps/chosen": -124.80894470214844,
      "logps/rejected": -77.22203063964844,
      "loss": 0.2134237051010132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7260820865631104,
      "rewards/margins": 1.4621927738189697,
      "rewards/rejected": -0.7361106872558594,
      "step": 660
    },
    {
      "epoch": 0.7173447537473233,
      "grad_norm": 3.8054449558258057,
      "learning_rate": 1.5887290167865707e-07,
      "logits/chosen": 1.7183074951171875,
      "logits/rejected": 1.8502633571624756,
      "logps/chosen": -119.29239654541016,
      "logps/rejected": -76.80537414550781,
      "loss": 0.22086820602416993,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6736306548118591,
      "rewards/margins": 1.432626724243164,
      "rewards/rejected": -0.7589960694313049,
      "step": 670
    },
    {
      "epoch": 0.728051391862955,
      "grad_norm": 3.4133331775665283,
      "learning_rate": 1.5287769784172662e-07,
      "logits/chosen": 1.7217051982879639,
      "logits/rejected": 1.7972755432128906,
      "logps/chosen": -120.1126937866211,
      "logps/rejected": -76.4248046875,
      "loss": 0.21661059856414794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7170795798301697,
      "rewards/margins": 1.4745031595230103,
      "rewards/rejected": -0.757423460483551,
      "step": 680
    },
    {
      "epoch": 0.7387580299785867,
      "grad_norm": 3.479074478149414,
      "learning_rate": 1.4688249400479616e-07,
      "logits/chosen": 1.716341257095337,
      "logits/rejected": 1.777489423751831,
      "logps/chosen": -116.86146545410156,
      "logps/rejected": -76.50260925292969,
      "loss": 0.22264389991760253,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6696044206619263,
      "rewards/margins": 1.4202334880828857,
      "rewards/rejected": -0.750629186630249,
      "step": 690
    },
    {
      "epoch": 0.7494646680942184,
      "grad_norm": 3.4742929935455322,
      "learning_rate": 1.408872901678657e-07,
      "logits/chosen": 1.7470571994781494,
      "logits/rejected": 1.817612886428833,
      "logps/chosen": -119.18412780761719,
      "logps/rejected": -76.01982116699219,
      "loss": 0.2156604528427124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.695346474647522,
      "rewards/margins": 1.4639503955841064,
      "rewards/rejected": -0.7686037421226501,
      "step": 700
    },
    {
      "epoch": 0.7601713062098501,
      "grad_norm": 3.9090747833251953,
      "learning_rate": 1.3489208633093525e-07,
      "logits/chosen": 1.7320079803466797,
      "logits/rejected": 1.7707141637802124,
      "logps/chosen": -116.19758605957031,
      "logps/rejected": -76.36009216308594,
      "loss": 0.2131185531616211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7081734538078308,
      "rewards/margins": 1.4952646493911743,
      "rewards/rejected": -0.7870911359786987,
      "step": 710
    },
    {
      "epoch": 0.7708779443254818,
      "grad_norm": 4.0122528076171875,
      "learning_rate": 1.288968824940048e-07,
      "logits/chosen": 1.7513492107391357,
      "logits/rejected": 1.7582435607910156,
      "logps/chosen": -117.08576965332031,
      "logps/rejected": -77.47846984863281,
      "loss": 0.21004898548126222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7127997875213623,
      "rewards/margins": 1.504163384437561,
      "rewards/rejected": -0.7913635969161987,
      "step": 720
    },
    {
      "epoch": 0.7815845824411135,
      "grad_norm": 3.9595959186553955,
      "learning_rate": 1.2290167865707434e-07,
      "logits/chosen": 1.7564512491226196,
      "logits/rejected": 1.855386734008789,
      "logps/chosen": -130.2552947998047,
      "logps/rejected": -76.67520904541016,
      "loss": 0.21384105682373047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6689995527267456,
      "rewards/margins": 1.468473196029663,
      "rewards/rejected": -0.7994736433029175,
      "step": 730
    },
    {
      "epoch": 0.7922912205567452,
      "grad_norm": 4.009642601013184,
      "learning_rate": 1.1690647482014387e-07,
      "logits/chosen": 1.6987855434417725,
      "logits/rejected": 1.757918357849121,
      "logps/chosen": -113.05946350097656,
      "logps/rejected": -76.42742919921875,
      "loss": 0.20565252304077147,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7351082563400269,
      "rewards/margins": 1.5292824506759644,
      "rewards/rejected": -0.7941741943359375,
      "step": 740
    },
    {
      "epoch": 0.8029978586723768,
      "grad_norm": 4.071012496948242,
      "learning_rate": 1.1091127098321343e-07,
      "logits/chosen": 1.7152960300445557,
      "logits/rejected": 1.8184406757354736,
      "logps/chosen": -131.46090698242188,
      "logps/rejected": -77.12591552734375,
      "loss": 0.2071972131729126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7284451723098755,
      "rewards/margins": 1.5258638858795166,
      "rewards/rejected": -0.7974187731742859,
      "step": 750
    },
    {
      "epoch": 0.8137044967880086,
      "grad_norm": 3.25290584564209,
      "learning_rate": 1.0491606714628296e-07,
      "logits/chosen": 1.683035135269165,
      "logits/rejected": 1.759441614151001,
      "logps/chosen": -121.61207580566406,
      "logps/rejected": -78.06277465820312,
      "loss": 0.20092666149139404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7316488027572632,
      "rewards/margins": 1.5594215393066406,
      "rewards/rejected": -0.8277727365493774,
      "step": 760
    },
    {
      "epoch": 0.8244111349036403,
      "grad_norm": 3.731701374053955,
      "learning_rate": 9.892086330935251e-08,
      "logits/chosen": 1.7974522113800049,
      "logits/rejected": 1.7646839618682861,
      "logps/chosen": -122.67618560791016,
      "logps/rejected": -78.10191345214844,
      "loss": 0.19378560781478882,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7723132967948914,
      "rewards/margins": 1.5898271799087524,
      "rewards/rejected": -0.8175140619277954,
      "step": 770
    },
    {
      "epoch": 0.8351177730192719,
      "grad_norm": 4.026064872741699,
      "learning_rate": 9.292565947242207e-08,
      "logits/chosen": 1.7079652547836304,
      "logits/rejected": 1.905870795249939,
      "logps/chosen": -116.39066314697266,
      "logps/rejected": -77.20503234863281,
      "loss": 0.1987370491027832,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7275263071060181,
      "rewards/margins": 1.5661500692367554,
      "rewards/rejected": -0.8386238217353821,
      "step": 780
    },
    {
      "epoch": 0.8458244111349036,
      "grad_norm": 3.428180456161499,
      "learning_rate": 8.69304556354916e-08,
      "logits/chosen": 1.6900584697723389,
      "logits/rejected": 1.8284670114517212,
      "logps/chosen": -129.3657684326172,
      "logps/rejected": -77.31852722167969,
      "loss": 0.19388551712036134,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7183624505996704,
      "rewards/margins": 1.5836632251739502,
      "rewards/rejected": -0.8653006553649902,
      "step": 790
    },
    {
      "epoch": 0.8565310492505354,
      "grad_norm": 3.657552719116211,
      "learning_rate": 8.093525179856114e-08,
      "logits/chosen": 1.7674888372421265,
      "logits/rejected": 1.7921667098999023,
      "logps/chosen": -140.70962524414062,
      "logps/rejected": -76.70339965820312,
      "loss": 0.202962064743042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6946288347244263,
      "rewards/margins": 1.5346542596817017,
      "rewards/rejected": -0.8400254249572754,
      "step": 800
    },
    {
      "epoch": 0.867237687366167,
      "grad_norm": 3.7927968502044678,
      "learning_rate": 7.49400479616307e-08,
      "logits/chosen": 1.7642707824707031,
      "logits/rejected": 1.7934859991073608,
      "logps/chosen": -129.78543090820312,
      "logps/rejected": -77.42664337158203,
      "loss": 0.2003854274749756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6987134218215942,
      "rewards/margins": 1.568512201309204,
      "rewards/rejected": -0.8697988390922546,
      "step": 810
    },
    {
      "epoch": 0.8779443254817987,
      "grad_norm": 3.202974557876587,
      "learning_rate": 6.894484412470023e-08,
      "logits/chosen": 1.6980527639389038,
      "logits/rejected": 1.7797905206680298,
      "logps/chosen": -113.62921142578125,
      "logps/rejected": -77.945556640625,
      "loss": 0.18985817432403565,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7432199716567993,
      "rewards/margins": 1.6170437335968018,
      "rewards/rejected": -0.8738237619400024,
      "step": 820
    },
    {
      "epoch": 0.8886509635974305,
      "grad_norm": 3.4337618350982666,
      "learning_rate": 6.294964028776978e-08,
      "logits/chosen": 1.7009226083755493,
      "logits/rejected": 1.8163020610809326,
      "logps/chosen": -122.6957778930664,
      "logps/rejected": -78.4272689819336,
      "loss": 0.19200797080993653,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7359816431999207,
      "rewards/margins": 1.6052898168563843,
      "rewards/rejected": -0.8693079948425293,
      "step": 830
    },
    {
      "epoch": 0.8993576017130621,
      "grad_norm": 3.8475685119628906,
      "learning_rate": 5.695443645083932e-08,
      "logits/chosen": 1.7791332006454468,
      "logits/rejected": 1.7971770763397217,
      "logps/chosen": -117.59135437011719,
      "logps/rejected": -77.06907653808594,
      "loss": 0.20112130641937256,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6921485662460327,
      "rewards/margins": 1.538746953010559,
      "rewards/rejected": -0.8465983271598816,
      "step": 840
    },
    {
      "epoch": 0.9100642398286938,
      "grad_norm": 3.2740283012390137,
      "learning_rate": 5.0959232613908875e-08,
      "logits/chosen": 1.7432806491851807,
      "logits/rejected": 1.8671436309814453,
      "logps/chosen": -128.58233642578125,
      "logps/rejected": -77.31321716308594,
      "loss": 0.1976061463356018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7055756449699402,
      "rewards/margins": 1.5641100406646729,
      "rewards/rejected": -0.8585343360900879,
      "step": 850
    },
    {
      "epoch": 0.9207708779443254,
      "grad_norm": 3.4766039848327637,
      "learning_rate": 4.496402877697841e-08,
      "logits/chosen": 1.6841541528701782,
      "logits/rejected": 1.8302109241485596,
      "logps/chosen": -119.52203369140625,
      "logps/rejected": -77.5684585571289,
      "loss": 0.2080080032348633,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6399325132369995,
      "rewards/margins": 1.5125091075897217,
      "rewards/rejected": -0.8725765943527222,
      "step": 860
    },
    {
      "epoch": 0.9314775160599572,
      "grad_norm": 3.8099541664123535,
      "learning_rate": 3.896882494004796e-08,
      "logits/chosen": 1.768943190574646,
      "logits/rejected": 1.7626721858978271,
      "logps/chosen": -130.25473022460938,
      "logps/rejected": -77.9406967163086,
      "loss": 0.19538891315460205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7161301374435425,
      "rewards/margins": 1.5790390968322754,
      "rewards/rejected": -0.8629088401794434,
      "step": 870
    },
    {
      "epoch": 0.9421841541755889,
      "grad_norm": 3.607870578765869,
      "learning_rate": 3.297362110311751e-08,
      "logits/chosen": 1.7420097589492798,
      "logits/rejected": 1.8043172359466553,
      "logps/chosen": -120.25474548339844,
      "logps/rejected": -77.6947250366211,
      "loss": 0.19807571172714233,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.692137598991394,
      "rewards/margins": 1.572641134262085,
      "rewards/rejected": -0.8805034756660461,
      "step": 880
    },
    {
      "epoch": 0.9528907922912205,
      "grad_norm": 3.5437443256378174,
      "learning_rate": 2.6978417266187048e-08,
      "logits/chosen": 1.675000786781311,
      "logits/rejected": 1.8182910680770874,
      "logps/chosen": -131.31155395507812,
      "logps/rejected": -79.33917236328125,
      "loss": 0.18579646348953247,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7399771213531494,
      "rewards/margins": 1.620177984237671,
      "rewards/rejected": -0.8802007436752319,
      "step": 890
    },
    {
      "epoch": 0.9635974304068522,
      "grad_norm": 3.428215265274048,
      "learning_rate": 2.0983213429256596e-08,
      "logits/chosen": 1.7265243530273438,
      "logits/rejected": 1.8221769332885742,
      "logps/chosen": -120.01765441894531,
      "logps/rejected": -76.72976684570312,
      "loss": 0.18787693977355957,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7546896934509277,
      "rewards/margins": 1.6170005798339844,
      "rewards/rejected": -0.8623110055923462,
      "step": 900
    },
    {
      "epoch": 0.974304068522484,
      "grad_norm": 3.505964756011963,
      "learning_rate": 1.4988009592326138e-08,
      "logits/chosen": 1.6655585765838623,
      "logits/rejected": 1.7391395568847656,
      "logps/chosen": -122.47709655761719,
      "logps/rejected": -77.54304504394531,
      "loss": 0.1832979440689087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7776598930358887,
      "rewards/margins": 1.6486005783081055,
      "rewards/rejected": -0.8709406852722168,
      "step": 910
    },
    {
      "epoch": 0.9850107066381156,
      "grad_norm": 3.390794038772583,
      "learning_rate": 8.992805755395683e-09,
      "logits/chosen": 1.7924108505249023,
      "logits/rejected": 1.7391090393066406,
      "logps/chosen": -132.4521026611328,
      "logps/rejected": -78.43919372558594,
      "loss": 0.19238874912261963,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7185256481170654,
      "rewards/margins": 1.6075845956802368,
      "rewards/rejected": -0.8890587687492371,
      "step": 920
    },
    {
      "epoch": 0.9957173447537473,
      "grad_norm": 3.282618522644043,
      "learning_rate": 2.9976019184652275e-09,
      "logits/chosen": 1.7754943370819092,
      "logits/rejected": 1.802117943763733,
      "logps/chosen": -124.4705810546875,
      "logps/rejected": -78.65437316894531,
      "loss": 0.20276501178741455,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6955665946006775,
      "rewards/margins": 1.5481624603271484,
      "rewards/rejected": -0.8525959253311157,
      "step": 930
    }
  ],
  "logging_steps": 10,
  "max_steps": 934,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
