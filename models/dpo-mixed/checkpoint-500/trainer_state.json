{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5353319057815846,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010706638115631691,
      "grad_norm": 7.741055011749268,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.6414082050323486,
      "logits/rejected": 1.6470849514007568,
      "logps/chosen": -137.65316772460938,
      "logps/rejected": -68.58262634277344,
      "loss": 0.6921837806701661,
      "rewards/accuracies": 0.3499999940395355,
      "rewards/chosen": 0.0018970727687701583,
      "rewards/margins": 0.002223605988547206,
      "rewards/rejected": -0.0003265332488808781,
      "step": 10
    },
    {
      "epoch": 0.021413276231263382,
      "grad_norm": 8.083742141723633,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.6303012371063232,
      "logits/rejected": 1.619828462600708,
      "logps/chosen": -127.005615234375,
      "logps/rejected": -69.37870025634766,
      "loss": 0.6981179237365722,
      "rewards/accuracies": 0.4000000059604645,
      "rewards/chosen": -0.007431450299918652,
      "rewards/margins": -0.009424667805433273,
      "rewards/rejected": 0.001993217272683978,
      "step": 20
    },
    {
      "epoch": 0.032119914346895075,
      "grad_norm": 8.292325019836426,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.6350021362304688,
      "logits/rejected": 1.6774721145629883,
      "logps/chosen": -132.09512329101562,
      "logps/rejected": -68.65172576904297,
      "loss": 0.6949917793273925,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.004879589658230543,
      "rewards/margins": -0.0032155707012861967,
      "rewards/rejected": -0.001664018607698381,
      "step": 30
    },
    {
      "epoch": 0.042826552462526764,
      "grad_norm": 8.421181678771973,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.5207608938217163,
      "logits/rejected": 1.6680008172988892,
      "logps/chosen": -123.42039489746094,
      "logps/rejected": -69.3780517578125,
      "loss": 0.6928003311157227,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -0.0022781279403716326,
      "rewards/margins": 0.001274451962672174,
      "rewards/rejected": -0.0035525797866284847,
      "step": 40
    },
    {
      "epoch": 0.05353319057815846,
      "grad_norm": 7.814224720001221,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.7590328454971313,
      "logits/rejected": 1.623600721359253,
      "logps/chosen": -146.6126251220703,
      "logps/rejected": -69.6846923828125,
      "loss": 0.6869121074676514,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.009453506208956242,
      "rewards/margins": 0.013024091720581055,
      "rewards/rejected": -0.0035705850459635258,
      "step": 50
    },
    {
      "epoch": 0.06423982869379015,
      "grad_norm": 7.7611212730407715,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.5742673873901367,
      "logits/rejected": 1.661669135093689,
      "logps/chosen": -128.58689880371094,
      "logps/rejected": -68.86058807373047,
      "loss": 0.6956583976745605,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -0.0024095436092466116,
      "rewards/margins": -0.004303164780139923,
      "rewards/rejected": 0.0018936205888167024,
      "step": 60
    },
    {
      "epoch": 0.07494646680942184,
      "grad_norm": 8.805891990661621,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.6264060735702515,
      "logits/rejected": 1.6312564611434937,
      "logps/chosen": -131.72048950195312,
      "logps/rejected": -68.80120849609375,
      "loss": 0.6938254833221436,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.0010343979811295867,
      "rewards/margins": -0.0007398080197162926,
      "rewards/rejected": 0.001774206175468862,
      "step": 70
    },
    {
      "epoch": 0.08565310492505353,
      "grad_norm": 8.418060302734375,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.6953182220458984,
      "logits/rejected": 1.7030633687973022,
      "logps/chosen": -133.45242309570312,
      "logps/rejected": -68.4122543334961,
      "loss": 0.6912439346313477,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -0.00254586199298501,
      "rewards/margins": 0.004318948369473219,
      "rewards/rejected": -0.006864809896796942,
      "step": 80
    },
    {
      "epoch": 0.09635974304068523,
      "grad_norm": 8.60579776763916,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.6077579259872437,
      "logits/rejected": 1.6657851934432983,
      "logps/chosen": -122.4295883178711,
      "logps/rejected": -69.25360870361328,
      "loss": 0.6869400978088379,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.009872857481241226,
      "rewards/margins": 0.013005204498767853,
      "rewards/rejected": -0.003132348181679845,
      "step": 90
    },
    {
      "epoch": 0.10706638115631692,
      "grad_norm": 8.464462280273438,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.6527435779571533,
      "logits/rejected": 1.61818528175354,
      "logps/chosen": -134.21189880371094,
      "logps/rejected": -68.3548812866211,
      "loss": 0.68349289894104,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.013684412464499474,
      "rewards/margins": 0.020024046301841736,
      "rewards/rejected": -0.006339636631309986,
      "step": 100
    },
    {
      "epoch": 0.11777301927194861,
      "grad_norm": 7.88031005859375,
      "learning_rate": 4.946043165467625e-07,
      "logits/chosen": 1.5999301671981812,
      "logits/rejected": 1.6902990341186523,
      "logps/chosen": -121.95326232910156,
      "logps/rejected": -68.95580291748047,
      "loss": 0.6762250900268555,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.02649036981165409,
      "rewards/margins": 0.03455853834748268,
      "rewards/rejected": -0.008068164810538292,
      "step": 110
    },
    {
      "epoch": 0.1284796573875803,
      "grad_norm": 8.902802467346191,
      "learning_rate": 4.886091127098321e-07,
      "logits/chosen": 1.5206339359283447,
      "logits/rejected": 1.7172397375106812,
      "logps/chosen": -111.86238861083984,
      "logps/rejected": -69.06817626953125,
      "loss": 0.6703062057495117,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": 0.028182417154312134,
      "rewards/margins": 0.04670344293117523,
      "rewards/rejected": -0.01852102391421795,
      "step": 120
    },
    {
      "epoch": 0.139186295503212,
      "grad_norm": 8.137377738952637,
      "learning_rate": 4.826139088729016e-07,
      "logits/chosen": 1.6242367029190063,
      "logits/rejected": 1.6543670892715454,
      "logps/chosen": -127.9379653930664,
      "logps/rejected": -68.19505310058594,
      "loss": 0.6634600639343262,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.03936268761754036,
      "rewards/margins": 0.060975514352321625,
      "rewards/rejected": -0.021612826734781265,
      "step": 130
    },
    {
      "epoch": 0.14989293361884368,
      "grad_norm": 8.199177742004395,
      "learning_rate": 4.7661870503597116e-07,
      "logits/chosen": 1.5829235315322876,
      "logits/rejected": 1.668872594833374,
      "logps/chosen": -130.53536987304688,
      "logps/rejected": -69.46643829345703,
      "loss": 0.6529661178588867,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": 0.052739500999450684,
      "rewards/margins": 0.0826331079006195,
      "rewards/rejected": -0.029893606901168823,
      "step": 140
    },
    {
      "epoch": 0.16059957173447537,
      "grad_norm": 8.568166732788086,
      "learning_rate": 4.706235011990408e-07,
      "logits/chosen": 1.6092227697372437,
      "logits/rejected": 1.6694523096084595,
      "logps/chosen": -135.5042266845703,
      "logps/rejected": -68.8786849975586,
      "loss": 0.6507787227630615,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.04855255037546158,
      "rewards/margins": 0.087519571185112,
      "rewards/rejected": -0.03896702826023102,
      "step": 150
    },
    {
      "epoch": 0.17130620985010706,
      "grad_norm": 7.989839553833008,
      "learning_rate": 4.646282973621103e-07,
      "logits/chosen": 1.5869275331497192,
      "logits/rejected": 1.6636018753051758,
      "logps/chosen": -121.2269515991211,
      "logps/rejected": -68.49610900878906,
      "loss": 0.6393714904785156,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.0738278329372406,
      "rewards/margins": 0.11129005998373032,
      "rewards/rejected": -0.03746223822236061,
      "step": 160
    },
    {
      "epoch": 0.18201284796573874,
      "grad_norm": 7.484827041625977,
      "learning_rate": 4.586330935251798e-07,
      "logits/chosen": 1.5921857357025146,
      "logits/rejected": 1.6428565979003906,
      "logps/chosen": -128.2965850830078,
      "logps/rejected": -70.21226501464844,
      "loss": 0.6311060428619385,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.0793221965432167,
      "rewards/margins": 0.12913191318511963,
      "rewards/rejected": -0.04980972781777382,
      "step": 170
    },
    {
      "epoch": 0.19271948608137046,
      "grad_norm": 7.462615489959717,
      "learning_rate": 4.526378896882494e-07,
      "logits/chosen": 1.5806759595870972,
      "logits/rejected": 1.6912168264389038,
      "logps/chosen": -124.4361801147461,
      "logps/rejected": -68.71379089355469,
      "loss": 0.6198153972625733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09824083745479584,
      "rewards/margins": 0.15375441312789917,
      "rewards/rejected": -0.055513571947813034,
      "step": 180
    },
    {
      "epoch": 0.20342612419700215,
      "grad_norm": 7.844651222229004,
      "learning_rate": 4.466426858513189e-07,
      "logits/chosen": 1.6462863683700562,
      "logits/rejected": 1.7085870504379272,
      "logps/chosen": -128.85494995117188,
      "logps/rejected": -70.08350372314453,
      "loss": 0.6158407211303711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0967750996351242,
      "rewards/margins": 0.16226157546043396,
      "rewards/rejected": -0.06548646837472916,
      "step": 190
    },
    {
      "epoch": 0.21413276231263384,
      "grad_norm": 7.200769901275635,
      "learning_rate": 4.4064748201438843e-07,
      "logits/chosen": 1.6285110712051392,
      "logits/rejected": 1.7047147750854492,
      "logps/chosen": -127.4510269165039,
      "logps/rejected": -70.01476287841797,
      "loss": 0.5973907947540283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11917439848184586,
      "rewards/margins": 0.20283634960651398,
      "rewards/rejected": -0.08366195112466812,
      "step": 200
    },
    {
      "epoch": 0.22483940042826553,
      "grad_norm": 8.171895027160645,
      "learning_rate": 4.3465227817745806e-07,
      "logits/chosen": 1.508737564086914,
      "logits/rejected": 1.6937510967254639,
      "logps/chosen": -115.48828125,
      "logps/rejected": -69.54158782958984,
      "loss": 0.5904012680053711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12961935997009277,
      "rewards/margins": 0.2190200537443161,
      "rewards/rejected": -0.08940066397190094,
      "step": 210
    },
    {
      "epoch": 0.23554603854389722,
      "grad_norm": 8.254551887512207,
      "learning_rate": 4.286570743405276e-07,
      "logits/chosen": 1.6269643306732178,
      "logits/rejected": 1.7915422916412354,
      "logps/chosen": -138.51356506347656,
      "logps/rejected": -70.59925842285156,
      "loss": 0.5724263668060303,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16693195700645447,
      "rewards/margins": 0.25981515645980835,
      "rewards/rejected": -0.09288317710161209,
      "step": 220
    },
    {
      "epoch": 0.2462526766595289,
      "grad_norm": 7.195977210998535,
      "learning_rate": 4.226618705035971e-07,
      "logits/chosen": 1.6350101232528687,
      "logits/rejected": 1.6930118799209595,
      "logps/chosen": -114.0125732421875,
      "logps/rejected": -69.8135986328125,
      "loss": 0.5691221714019775,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1704360544681549,
      "rewards/margins": 0.26742976903915405,
      "rewards/rejected": -0.09699370712041855,
      "step": 230
    },
    {
      "epoch": 0.2569593147751606,
      "grad_norm": 7.002618312835693,
      "learning_rate": 4.1666666666666667e-07,
      "logits/chosen": 1.6395642757415771,
      "logits/rejected": 1.6769828796386719,
      "logps/chosen": -132.30322265625,
      "logps/rejected": -70.18910217285156,
      "loss": 0.5501570701599121,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19723379611968994,
      "rewards/margins": 0.31206417083740234,
      "rewards/rejected": -0.11483035236597061,
      "step": 240
    },
    {
      "epoch": 0.2676659528907923,
      "grad_norm": 8.010068893432617,
      "learning_rate": 4.106714628297362e-07,
      "logits/chosen": 1.6982170343399048,
      "logits/rejected": 1.7445398569107056,
      "logps/chosen": -136.2633514404297,
      "logps/rejected": -70.20318603515625,
      "loss": 0.5497150897979737,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1870913803577423,
      "rewards/margins": 0.3127710819244385,
      "rewards/rejected": -0.12567973136901855,
      "step": 250
    },
    {
      "epoch": 0.278372591006424,
      "grad_norm": 8.242047309875488,
      "learning_rate": 4.046762589928057e-07,
      "logits/chosen": 1.6161391735076904,
      "logits/rejected": 1.7438112497329712,
      "logps/chosen": -124.64337158203125,
      "logps/rejected": -70.76585388183594,
      "loss": 0.531620454788208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22497472167015076,
      "rewards/margins": 0.3578566610813141,
      "rewards/rejected": -0.13288193941116333,
      "step": 260
    },
    {
      "epoch": 0.2890792291220557,
      "grad_norm": 6.686182498931885,
      "learning_rate": 3.9868105515587533e-07,
      "logits/chosen": 1.624447226524353,
      "logits/rejected": 1.7339435815811157,
      "logps/chosen": -128.43740844726562,
      "logps/rejected": -70.68250274658203,
      "loss": 0.5293261051177979,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21388402581214905,
      "rewards/margins": 0.36366376280784607,
      "rewards/rejected": -0.14977972209453583,
      "step": 270
    },
    {
      "epoch": 0.29978586723768735,
      "grad_norm": 6.167685031890869,
      "learning_rate": 3.9268585131894485e-07,
      "logits/chosen": 1.6475884914398193,
      "logits/rejected": 1.6943752765655518,
      "logps/chosen": -120.843505859375,
      "logps/rejected": -69.97770690917969,
      "loss": 0.5203248977661132,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.22276143729686737,
      "rewards/margins": 0.3866351544857025,
      "rewards/rejected": -0.16387371718883514,
      "step": 280
    },
    {
      "epoch": 0.31049250535331907,
      "grad_norm": 7.911632537841797,
      "learning_rate": 3.8669064748201436e-07,
      "logits/chosen": 1.6980562210083008,
      "logits/rejected": 1.7317081689834595,
      "logps/chosen": -138.04588317871094,
      "logps/rejected": -70.97135925292969,
      "loss": 0.4880954742431641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2969769537448883,
      "rewards/margins": 0.4678518772125244,
      "rewards/rejected": -0.17087490856647491,
      "step": 290
    },
    {
      "epoch": 0.32119914346895073,
      "grad_norm": 7.79892635345459,
      "learning_rate": 3.8069544364508394e-07,
      "logits/chosen": 1.7201478481292725,
      "logits/rejected": 1.764155387878418,
      "logps/chosen": -130.9140625,
      "logps/rejected": -70.36097717285156,
      "loss": 0.48144874572753904,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.28139516711235046,
      "rewards/margins": 0.48678502440452576,
      "rewards/rejected": -0.2053898572921753,
      "step": 300
    },
    {
      "epoch": 0.33190578158458245,
      "grad_norm": 7.8517231941223145,
      "learning_rate": 3.7470023980815345e-07,
      "logits/chosen": 1.7134841680526733,
      "logits/rejected": 1.722998857498169,
      "logps/chosen": -141.0425262451172,
      "logps/rejected": -70.40679168701172,
      "loss": 0.4679696083068848,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3205703794956207,
      "rewards/margins": 0.5223708152770996,
      "rewards/rejected": -0.20180043578147888,
      "step": 310
    },
    {
      "epoch": 0.3426124197002141,
      "grad_norm": 6.915214538574219,
      "learning_rate": 3.6870503597122297e-07,
      "logits/chosen": 1.6239919662475586,
      "logits/rejected": 1.774981141090393,
      "logps/chosen": -121.45024108886719,
      "logps/rejected": -71.14373779296875,
      "loss": 0.46284775733947753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31710928678512573,
      "rewards/margins": 0.5380560159683228,
      "rewards/rejected": -0.22094669938087463,
      "step": 320
    },
    {
      "epoch": 0.3533190578158458,
      "grad_norm": 7.145328044891357,
      "learning_rate": 3.627098321342926e-07,
      "logits/chosen": 1.7421276569366455,
      "logits/rejected": 1.775216817855835,
      "logps/chosen": -130.68710327148438,
      "logps/rejected": -70.46624755859375,
      "loss": 0.4475550174713135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3369230329990387,
      "rewards/margins": 0.5787224769592285,
      "rewards/rejected": -0.24179942905902863,
      "step": 330
    },
    {
      "epoch": 0.3640256959314775,
      "grad_norm": 6.632793426513672,
      "learning_rate": 3.567146282973621e-07,
      "logits/chosen": 1.7010889053344727,
      "logits/rejected": 1.776019811630249,
      "logps/chosen": -144.11822509765625,
      "logps/rejected": -71.8785400390625,
      "loss": 0.43529491424560546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34599921107292175,
      "rewards/margins": 0.6157651543617249,
      "rewards/rejected": -0.2697659432888031,
      "step": 340
    },
    {
      "epoch": 0.3747323340471092,
      "grad_norm": 6.380807876586914,
      "learning_rate": 3.5071942446043163e-07,
      "logits/chosen": 1.6991281509399414,
      "logits/rejected": 1.720046043395996,
      "logps/chosen": -128.89962768554688,
      "logps/rejected": -70.43315124511719,
      "loss": 0.42685937881469727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3807167410850525,
      "rewards/margins": 0.6443994641304016,
      "rewards/rejected": -0.26368266344070435,
      "step": 350
    },
    {
      "epoch": 0.3854389721627409,
      "grad_norm": 6.079395294189453,
      "learning_rate": 3.447242206235012e-07,
      "logits/chosen": 1.7227891683578491,
      "logits/rejected": 1.852887511253357,
      "logps/chosen": -123.9052734375,
      "logps/rejected": -72.29902648925781,
      "loss": 0.42282629013061523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3517988324165344,
      "rewards/margins": 0.6531723737716675,
      "rewards/rejected": -0.30137357115745544,
      "step": 360
    },
    {
      "epoch": 0.3961456102783726,
      "grad_norm": 6.3076910972595215,
      "learning_rate": 3.387290167865707e-07,
      "logits/chosen": 1.774964690208435,
      "logits/rejected": 1.7948055267333984,
      "logps/chosen": -127.28727722167969,
      "logps/rejected": -72.2643814086914,
      "loss": 0.4216721534729004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.35563454031944275,
      "rewards/margins": 0.6565887928009033,
      "rewards/rejected": -0.30095428228378296,
      "step": 370
    },
    {
      "epoch": 0.4068522483940043,
      "grad_norm": 6.376628398895264,
      "learning_rate": 3.3273381294964024e-07,
      "logits/chosen": 1.6560760736465454,
      "logits/rejected": 1.7717841863632202,
      "logps/chosen": -122.11065673828125,
      "logps/rejected": -72.16600799560547,
      "loss": 0.3968196392059326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4199541211128235,
      "rewards/margins": 0.7303374409675598,
      "rewards/rejected": -0.31038329005241394,
      "step": 380
    },
    {
      "epoch": 0.41755888650963596,
      "grad_norm": 6.101396083831787,
      "learning_rate": 3.2673860911270987e-07,
      "logits/chosen": 1.7897109985351562,
      "logits/rejected": 1.7782552242279053,
      "logps/chosen": -133.59283447265625,
      "logps/rejected": -71.7552490234375,
      "loss": 0.4028975009918213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.391545832157135,
      "rewards/margins": 0.7166863679885864,
      "rewards/rejected": -0.3251405358314514,
      "step": 390
    },
    {
      "epoch": 0.4282655246252677,
      "grad_norm": 5.62619686126709,
      "learning_rate": 3.207434052757794e-07,
      "logits/chosen": 1.7085297107696533,
      "logits/rejected": 1.768411636352539,
      "logps/chosen": -120.59797668457031,
      "logps/rejected": -72.63621520996094,
      "loss": 0.39118590354919436,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4118087887763977,
      "rewards/margins": 0.7474412322044373,
      "rewards/rejected": -0.3356325328350067,
      "step": 400
    },
    {
      "epoch": 0.43897216274089934,
      "grad_norm": 5.362334728240967,
      "learning_rate": 3.147482014388489e-07,
      "logits/chosen": 1.6492512226104736,
      "logits/rejected": 1.7654674053192139,
      "logps/chosen": -112.69343566894531,
      "logps/rejected": -72.82518005371094,
      "loss": 0.37764360904693606,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4518015384674072,
      "rewards/margins": 0.7963234186172485,
      "rewards/rejected": -0.34452182054519653,
      "step": 410
    },
    {
      "epoch": 0.44967880085653106,
      "grad_norm": 5.973454475402832,
      "learning_rate": 3.087529976019185e-07,
      "logits/chosen": 1.6632111072540283,
      "logits/rejected": 1.8019161224365234,
      "logps/chosen": -120.314697265625,
      "logps/rejected": -71.65013122558594,
      "loss": 0.35718631744384766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.47905999422073364,
      "rewards/margins": 0.8620496988296509,
      "rewards/rejected": -0.38298970460891724,
      "step": 420
    },
    {
      "epoch": 0.4603854389721627,
      "grad_norm": 5.460209846496582,
      "learning_rate": 3.02757793764988e-07,
      "logits/chosen": 1.773888349533081,
      "logits/rejected": 1.8037201166152954,
      "logps/chosen": -132.87957763671875,
      "logps/rejected": -73.58642578125,
      "loss": 0.3468312740325928,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4960877001285553,
      "rewards/margins": 0.8990741968154907,
      "rewards/rejected": -0.40298646688461304,
      "step": 430
    },
    {
      "epoch": 0.47109207708779444,
      "grad_norm": 5.701747417449951,
      "learning_rate": 2.967625899280575e-07,
      "logits/chosen": 1.669395089149475,
      "logits/rejected": 1.7530901432037354,
      "logps/chosen": -131.12820434570312,
      "logps/rejected": -72.90501403808594,
      "loss": 0.3360680103302002,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.512489914894104,
      "rewards/margins": 0.9309952855110168,
      "rewards/rejected": -0.4185052812099457,
      "step": 440
    },
    {
      "epoch": 0.4817987152034261,
      "grad_norm": 5.458523273468018,
      "learning_rate": 2.907673860911271e-07,
      "logits/chosen": 1.7761256694793701,
      "logits/rejected": 1.8283132314682007,
      "logps/chosen": -117.85076904296875,
      "logps/rejected": -72.65133666992188,
      "loss": 0.3489613771438599,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.46487587690353394,
      "rewards/margins": 0.8949135541915894,
      "rewards/rejected": -0.43003764748573303,
      "step": 450
    },
    {
      "epoch": 0.4925053533190578,
      "grad_norm": 5.306919097900391,
      "learning_rate": 2.8477218225419665e-07,
      "logits/chosen": 1.7203201055526733,
      "logits/rejected": 1.7541296482086182,
      "logps/chosen": -119.7204360961914,
      "logps/rejected": -73.51383972167969,
      "loss": 0.3401479721069336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49809685349464417,
      "rewards/margins": 0.9191838502883911,
      "rewards/rejected": -0.42108696699142456,
      "step": 460
    },
    {
      "epoch": 0.5032119914346895,
      "grad_norm": 5.2116875648498535,
      "learning_rate": 2.7877697841726617e-07,
      "logits/chosen": 1.652305245399475,
      "logits/rejected": 1.7981897592544556,
      "logps/chosen": -118.83565521240234,
      "logps/rejected": -74.01769256591797,
      "loss": 0.3251779556274414,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5207119584083557,
      "rewards/margins": 0.9744011163711548,
      "rewards/rejected": -0.4536890387535095,
      "step": 470
    },
    {
      "epoch": 0.5139186295503212,
      "grad_norm": 5.218020915985107,
      "learning_rate": 2.7278177458033574e-07,
      "logits/chosen": 1.689134955406189,
      "logits/rejected": 1.8135219812393188,
      "logps/chosen": -126.3836898803711,
      "logps/rejected": -74.37802124023438,
      "loss": 0.30874269008636473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5642669200897217,
      "rewards/margins": 1.040651559829712,
      "rewards/rejected": -0.4763847291469574,
      "step": 480
    },
    {
      "epoch": 0.5246252676659529,
      "grad_norm": 5.253102779388428,
      "learning_rate": 2.6678657074340526e-07,
      "logits/chosen": 1.6579649448394775,
      "logits/rejected": 1.7480230331420898,
      "logps/chosen": -120.4889907836914,
      "logps/rejected": -75.39362335205078,
      "loss": 0.30684971809387207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5676183104515076,
      "rewards/margins": 1.0471782684326172,
      "rewards/rejected": -0.479559987783432,
      "step": 490
    },
    {
      "epoch": 0.5353319057815846,
      "grad_norm": 4.98911190032959,
      "learning_rate": 2.607913669064748e-07,
      "logits/chosen": 1.7070884704589844,
      "logits/rejected": 1.7949190139770508,
      "logps/chosen": -126.05009460449219,
      "logps/rejected": -73.45948791503906,
      "loss": 0.3099621534347534,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5381681323051453,
      "rewards/margins": 1.0409502983093262,
      "rewards/rejected": -0.5027821660041809,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 934,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
