{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.6047631790206047,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010703773080010704,
      "grad_norm": 8.042835235595703,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.6620283126831055,
      "logits/rejected": 1.6317756175994873,
      "logps/chosen": -154.88954162597656,
      "logps/rejected": -68.91143798828125,
      "loss": 0.6929930686950684,
      "rewards/accuracies": 0.36250001192092896,
      "rewards/chosen": 0.0027783107943832874,
      "rewards/margins": 0.0006214429740794003,
      "rewards/rejected": 0.002156867878511548,
      "step": 10
    },
    {
      "epoch": 0.02140754616002141,
      "grad_norm": 7.908276557922363,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.6803842782974243,
      "logits/rejected": 1.6823651790618896,
      "logps/chosen": -172.01377868652344,
      "logps/rejected": -69.42620849609375,
      "loss": 0.6901248455047607,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.0032467462588101625,
      "rewards/margins": 0.006624302826821804,
      "rewards/rejected": -0.0033775572665035725,
      "step": 20
    },
    {
      "epoch": 0.03211131924003211,
      "grad_norm": 8.849369049072266,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.7294156551361084,
      "logits/rejected": 1.7146995067596436,
      "logps/chosen": -156.42025756835938,
      "logps/rejected": -68.60186004638672,
      "loss": 0.6883335113525391,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.0077818394638597965,
      "rewards/margins": 0.010242929682135582,
      "rewards/rejected": -0.0024610902182757854,
      "step": 30
    },
    {
      "epoch": 0.04281509232004282,
      "grad_norm": 7.736130714416504,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.6949303150177002,
      "logits/rejected": 1.6702102422714233,
      "logps/chosen": -163.21951293945312,
      "logps/rejected": -68.36978912353516,
      "loss": 0.6939249992370605,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004687915090471506,
      "rewards/margins": -0.000950565212406218,
      "rewards/rejected": 0.005638480186462402,
      "step": 40
    },
    {
      "epoch": 0.05351886540005352,
      "grad_norm": 7.328680992126465,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.6597477197647095,
      "logits/rejected": 1.6957956552505493,
      "logps/chosen": -164.46815490722656,
      "logps/rejected": -69.56840515136719,
      "loss": 0.6954107284545898,
      "rewards/accuracies": 0.38749998807907104,
      "rewards/chosen": -0.0025431732647120953,
      "rewards/margins": -0.003903585020452738,
      "rewards/rejected": 0.0013604119885712862,
      "step": 50
    },
    {
      "epoch": 0.06422263848006422,
      "grad_norm": 8.188251495361328,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.5828840732574463,
      "logits/rejected": 1.6658637523651123,
      "logps/chosen": -165.49407958984375,
      "logps/rejected": -69.3355484008789,
      "loss": 0.6892322063446045,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.007503075059503317,
      "rewards/margins": 0.008510095067322254,
      "rewards/rejected": -0.0010070180287584662,
      "step": 60
    },
    {
      "epoch": 0.07492641156007493,
      "grad_norm": 8.65149211883545,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.7149341106414795,
      "logits/rejected": 1.6704447269439697,
      "logps/chosen": -158.31288146972656,
      "logps/rejected": -69.85413360595703,
      "loss": 0.6899673461914062,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.004872560501098633,
      "rewards/margins": 0.00689715426415205,
      "rewards/rejected": -0.0020245935302227736,
      "step": 70
    },
    {
      "epoch": 0.08563018464008564,
      "grad_norm": 8.285731315612793,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.7061173915863037,
      "logits/rejected": 1.6593306064605713,
      "logps/chosen": -148.55221557617188,
      "logps/rejected": -68.52693939208984,
      "loss": 0.6900406360626221,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.0032034304458647966,
      "rewards/margins": 0.006800008472055197,
      "rewards/rejected": -0.0035965777933597565,
      "step": 80
    },
    {
      "epoch": 0.09633395772009633,
      "grad_norm": 8.954898834228516,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.6642587184906006,
      "logits/rejected": 1.6277955770492554,
      "logps/chosen": -158.2709197998047,
      "logps/rejected": -70.13672637939453,
      "loss": 0.6845562934875489,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.012011649087071419,
      "rewards/margins": 0.017708750441670418,
      "rewards/rejected": -0.005697102285921574,
      "step": 90
    },
    {
      "epoch": 0.10703773080010703,
      "grad_norm": 9.460087776184082,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.6440887451171875,
      "logits/rejected": 1.666945457458496,
      "logps/chosen": -157.4323272705078,
      "logps/rejected": -69.00125122070312,
      "loss": 0.6818899631500244,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.016707099974155426,
      "rewards/margins": 0.02356214076280594,
      "rewards/rejected": -0.006855040788650513,
      "step": 100
    },
    {
      "epoch": 0.11774150388011774,
      "grad_norm": 9.953648567199707,
      "learning_rate": 4.99016393442623e-07,
      "logits/chosen": 1.7171710729599,
      "logits/rejected": 1.6603634357452393,
      "logps/chosen": -174.9585418701172,
      "logps/rejected": -68.0926742553711,
      "loss": 0.6798484325408936,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.01922713965177536,
      "rewards/margins": 0.02738826908171177,
      "rewards/rejected": -0.008161130361258984,
      "step": 110
    },
    {
      "epoch": 0.12844527696012845,
      "grad_norm": 8.520073890686035,
      "learning_rate": 4.979234972677595e-07,
      "logits/chosen": 1.6902961730957031,
      "logits/rejected": 1.6549479961395264,
      "logps/chosen": -167.37828063964844,
      "logps/rejected": -69.44087982177734,
      "loss": 0.6729569435119629,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.031610604375600815,
      "rewards/margins": 0.04162018746137619,
      "rewards/rejected": -0.010009574703872204,
      "step": 120
    },
    {
      "epoch": 0.13914905004013914,
      "grad_norm": 9.898834228515625,
      "learning_rate": 4.968306010928961e-07,
      "logits/chosen": 1.6194766759872437,
      "logits/rejected": 1.6620088815689087,
      "logps/chosen": -152.73416137695312,
      "logps/rejected": -69.17903900146484,
      "loss": 0.6615282535552979,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.04378412291407585,
      "rewards/margins": 0.06479620933532715,
      "rewards/rejected": -0.021012086421251297,
      "step": 130
    },
    {
      "epoch": 0.14985282312014986,
      "grad_norm": 7.924726486206055,
      "learning_rate": 4.957377049180328e-07,
      "logits/chosen": 1.6532785892486572,
      "logits/rejected": 1.6689271926879883,
      "logps/chosen": -149.36196899414062,
      "logps/rejected": -68.09927368164062,
      "loss": 0.6616442680358887,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": 0.04494362697005272,
      "rewards/margins": 0.06471928209066391,
      "rewards/rejected": -0.01977565698325634,
      "step": 140
    },
    {
      "epoch": 0.16055659620016055,
      "grad_norm": 9.148638725280762,
      "learning_rate": 4.946448087431694e-07,
      "logits/chosen": 1.6315438747406006,
      "logits/rejected": 1.7217543125152588,
      "logps/chosen": -164.35971069335938,
      "logps/rejected": -69.40621185302734,
      "loss": 0.6517998218536377,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.055680327117443085,
      "rewards/margins": 0.08524040132761002,
      "rewards/rejected": -0.029560070484876633,
      "step": 150
    },
    {
      "epoch": 0.17126036928017127,
      "grad_norm": 10.011578559875488,
      "learning_rate": 4.935519125683059e-07,
      "logits/chosen": 1.730621337890625,
      "logits/rejected": 1.6951007843017578,
      "logps/chosen": -163.42745971679688,
      "logps/rejected": -69.35670471191406,
      "loss": 0.6403472900390625,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.07630730420351028,
      "rewards/margins": 0.10929622501134872,
      "rewards/rejected": -0.032988931983709335,
      "step": 160
    },
    {
      "epoch": 0.18196414236018196,
      "grad_norm": 8.293572425842285,
      "learning_rate": 4.924590163934426e-07,
      "logits/chosen": 1.7120643854141235,
      "logits/rejected": 1.6681219339370728,
      "logps/chosen": -160.22293090820312,
      "logps/rejected": -69.96358489990234,
      "loss": 0.6249523639678956,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09709646552801132,
      "rewards/margins": 0.14246416091918945,
      "rewards/rejected": -0.04536769166588783,
      "step": 170
    },
    {
      "epoch": 0.19266791544019266,
      "grad_norm": 8.27168083190918,
      "learning_rate": 4.913661202185792e-07,
      "logits/chosen": 1.6911976337432861,
      "logits/rejected": 1.638209342956543,
      "logps/chosen": -156.54566955566406,
      "logps/rejected": -69.0328140258789,
      "loss": 0.6169334411621094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10367057472467422,
      "rewards/margins": 0.15983103215694427,
      "rewards/rejected": -0.056160468608140945,
      "step": 180
    },
    {
      "epoch": 0.20337168852020338,
      "grad_norm": 8.73447322845459,
      "learning_rate": 4.902732240437159e-07,
      "logits/chosen": 1.7855793237686157,
      "logits/rejected": 1.6400638818740845,
      "logps/chosen": -158.33712768554688,
      "logps/rejected": -70.53496551513672,
      "loss": 0.6121816158294677,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.11388534307479858,
      "rewards/margins": 0.17062537372112274,
      "rewards/rejected": -0.05674004554748535,
      "step": 190
    },
    {
      "epoch": 0.21407546160021407,
      "grad_norm": 8.191123008728027,
      "learning_rate": 4.891803278688524e-07,
      "logits/chosen": 1.6980412006378174,
      "logits/rejected": 1.6481969356536865,
      "logps/chosen": -152.1992950439453,
      "logps/rejected": -68.19105529785156,
      "loss": 0.6061748027801513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1223047524690628,
      "rewards/margins": 0.18418067693710327,
      "rewards/rejected": -0.061875928193330765,
      "step": 200
    },
    {
      "epoch": 0.2247792346802248,
      "grad_norm": 10.072147369384766,
      "learning_rate": 4.88087431693989e-07,
      "logits/chosen": 1.6401643753051758,
      "logits/rejected": 1.7380163669586182,
      "logps/chosen": -157.94541931152344,
      "logps/rejected": -70.68669128417969,
      "loss": 0.5895828247070313,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.14281681180000305,
      "rewards/margins": 0.22147062420845032,
      "rewards/rejected": -0.07865382730960846,
      "step": 210
    },
    {
      "epoch": 0.23548300776023548,
      "grad_norm": 7.548822402954102,
      "learning_rate": 4.869945355191257e-07,
      "logits/chosen": 1.6622155904769897,
      "logits/rejected": 1.7017467021942139,
      "logps/chosen": -148.46351623535156,
      "logps/rejected": -69.21295928955078,
      "loss": 0.5830491065979004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14975541830062866,
      "rewards/margins": 0.235938161611557,
      "rewards/rejected": -0.08618275821208954,
      "step": 220
    },
    {
      "epoch": 0.2461867808402462,
      "grad_norm": 8.452560424804688,
      "learning_rate": 4.859016393442622e-07,
      "logits/chosen": 1.6331592798233032,
      "logits/rejected": 1.7276771068572998,
      "logps/chosen": -154.79164123535156,
      "logps/rejected": -70.20716857910156,
      "loss": 0.5672767639160157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17895743250846863,
      "rewards/margins": 0.27279460430145264,
      "rewards/rejected": -0.09383717179298401,
      "step": 230
    },
    {
      "epoch": 0.2568905539202569,
      "grad_norm": 7.775155544281006,
      "learning_rate": 4.848087431693989e-07,
      "logits/chosen": 1.697218894958496,
      "logits/rejected": 1.7532260417938232,
      "logps/chosen": -151.79420471191406,
      "logps/rejected": -70.38407897949219,
      "loss": 0.5580480098724365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18484637141227722,
      "rewards/margins": 0.2951138913631439,
      "rewards/rejected": -0.1102675050497055,
      "step": 240
    },
    {
      "epoch": 0.2675943270002676,
      "grad_norm": 7.7155351638793945,
      "learning_rate": 4.837158469945355e-07,
      "logits/chosen": 1.7367427349090576,
      "logits/rejected": 1.687816858291626,
      "logps/chosen": -156.65438842773438,
      "logps/rejected": -70.59455108642578,
      "loss": 0.538788890838623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21229608356952667,
      "rewards/margins": 0.34001052379608154,
      "rewards/rejected": -0.12771447002887726,
      "step": 250
    },
    {
      "epoch": 0.2782981000802783,
      "grad_norm": 7.714850902557373,
      "learning_rate": 4.826229508196722e-07,
      "logits/chosen": 1.7488590478897095,
      "logits/rejected": 1.7122571468353271,
      "logps/chosen": -159.88613891601562,
      "logps/rejected": -69.44705200195312,
      "loss": 0.531544303894043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2298315465450287,
      "rewards/margins": 0.35841742157936096,
      "rewards/rejected": -0.1285858452320099,
      "step": 260
    },
    {
      "epoch": 0.289001873160289,
      "grad_norm": 7.462470531463623,
      "learning_rate": 4.815300546448087e-07,
      "logits/chosen": 1.6619943380355835,
      "logits/rejected": 1.7232564687728882,
      "logps/chosen": -158.8004608154297,
      "logps/rejected": -70.70526885986328,
      "loss": 0.518095588684082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24078914523124695,
      "rewards/margins": 0.3924974799156189,
      "rewards/rejected": -0.15170833468437195,
      "step": 270
    },
    {
      "epoch": 0.2997056462402997,
      "grad_norm": 7.329143524169922,
      "learning_rate": 4.804371584699453e-07,
      "logits/chosen": 1.733319878578186,
      "logits/rejected": 1.7422233819961548,
      "logps/chosen": -156.47251892089844,
      "logps/rejected": -70.48951721191406,
      "loss": 0.5063504219055176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25117042660713196,
      "rewards/margins": 0.4227348268032074,
      "rewards/rejected": -0.17156442999839783,
      "step": 280
    },
    {
      "epoch": 0.3104094193203104,
      "grad_norm": 8.61311149597168,
      "learning_rate": 4.79344262295082e-07,
      "logits/chosen": 1.8045895099639893,
      "logits/rejected": 1.799299955368042,
      "logps/chosen": -163.0063934326172,
      "logps/rejected": -72.11375427246094,
      "loss": 0.4894240379333496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27973300218582153,
      "rewards/margins": 0.46572867035865784,
      "rewards/rejected": -0.1859956681728363,
      "step": 290
    },
    {
      "epoch": 0.3211131924003211,
      "grad_norm": 7.378121376037598,
      "learning_rate": 4.782513661202186e-07,
      "logits/chosen": 1.7040908336639404,
      "logits/rejected": 1.7486766576766968,
      "logps/chosen": -156.3368377685547,
      "logps/rejected": -69.96931457519531,
      "loss": 0.47478561401367186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31315600872039795,
      "rewards/margins": 0.5039626359939575,
      "rewards/rejected": -0.190806582570076,
      "step": 300
    },
    {
      "epoch": 0.3318169654803318,
      "grad_norm": 7.064162731170654,
      "learning_rate": 4.771584699453552e-07,
      "logits/chosen": 1.7980601787567139,
      "logits/rejected": 1.7381725311279297,
      "logps/chosen": -153.16200256347656,
      "logps/rejected": -71.08973693847656,
      "loss": 0.46725010871887207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31458261609077454,
      "rewards/margins": 0.525361180305481,
      "rewards/rejected": -0.21077856421470642,
      "step": 310
    },
    {
      "epoch": 0.34252073856034254,
      "grad_norm": 6.610952854156494,
      "learning_rate": 4.760655737704918e-07,
      "logits/chosen": 1.7534401416778564,
      "logits/rejected": 1.7501399517059326,
      "logps/chosen": -168.30015563964844,
      "logps/rejected": -71.00263977050781,
      "loss": 0.4474502086639404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3498777747154236,
      "rewards/margins": 0.5853263139724731,
      "rewards/rejected": -0.23544852435588837,
      "step": 320
    },
    {
      "epoch": 0.35322451164035323,
      "grad_norm": 6.845317840576172,
      "learning_rate": 4.749726775956284e-07,
      "logits/chosen": 1.8165700435638428,
      "logits/rejected": 1.750357985496521,
      "logps/chosen": -177.55010986328125,
      "logps/rejected": -71.16143798828125,
      "loss": 0.4265284061431885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3805598318576813,
      "rewards/margins": 0.6398438215255737,
      "rewards/rejected": -0.25928401947021484,
      "step": 330
    },
    {
      "epoch": 0.3639282847203639,
      "grad_norm": 6.692675590515137,
      "learning_rate": 4.73879781420765e-07,
      "logits/chosen": 1.7772655487060547,
      "logits/rejected": 1.8082275390625,
      "logps/chosen": -159.55142211914062,
      "logps/rejected": -71.16816711425781,
      "loss": 0.40757203102111816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4074929654598236,
      "rewards/margins": 0.6997970938682556,
      "rewards/rejected": -0.2923041582107544,
      "step": 340
    },
    {
      "epoch": 0.3746320578003746,
      "grad_norm": 5.849478721618652,
      "learning_rate": 4.727868852459016e-07,
      "logits/chosen": 1.7856992483139038,
      "logits/rejected": 1.774206519126892,
      "logps/chosen": -157.7308349609375,
      "logps/rejected": -70.65202331542969,
      "loss": 0.4171758651733398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3858453929424286,
      "rewards/margins": 0.6697971224784851,
      "rewards/rejected": -0.28395166993141174,
      "step": 350
    },
    {
      "epoch": 0.3853358308803853,
      "grad_norm": 6.871621608734131,
      "learning_rate": 4.7169398907103825e-07,
      "logits/chosen": 1.7737483978271484,
      "logits/rejected": 1.7897913455963135,
      "logps/chosen": -163.47891235351562,
      "logps/rejected": -71.0719985961914,
      "loss": 0.3919903039932251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4211021959781647,
      "rewards/margins": 0.745856523513794,
      "rewards/rejected": -0.3247542977333069,
      "step": 360
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 6.033052921295166,
      "learning_rate": 4.706010928961748e-07,
      "logits/chosen": 1.7575725317001343,
      "logits/rejected": 1.7525899410247803,
      "logps/chosen": -158.105712890625,
      "logps/rejected": -71.40069580078125,
      "loss": 0.38487725257873534,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4209696650505066,
      "rewards/margins": 0.7734045386314392,
      "rewards/rejected": -0.35243481397628784,
      "step": 370
    },
    {
      "epoch": 0.40674337704040675,
      "grad_norm": 5.977532863616943,
      "learning_rate": 4.695081967213115e-07,
      "logits/chosen": 1.738138198852539,
      "logits/rejected": 1.7429298162460327,
      "logps/chosen": -165.0994415283203,
      "logps/rejected": -72.59822082519531,
      "loss": 0.3554192543029785,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4993690848350525,
      "rewards/margins": 0.8690775036811829,
      "rewards/rejected": -0.3697083592414856,
      "step": 380
    },
    {
      "epoch": 0.41744715012041744,
      "grad_norm": 5.488399028778076,
      "learning_rate": 4.6841530054644806e-07,
      "logits/chosen": 1.6882820129394531,
      "logits/rejected": 1.784976601600647,
      "logps/chosen": -151.66372680664062,
      "logps/rejected": -73.06888580322266,
      "loss": 0.33793528079986573,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5386590361595154,
      "rewards/margins": 0.9236882328987122,
      "rewards/rejected": -0.3850291967391968,
      "step": 390
    },
    {
      "epoch": 0.42815092320042814,
      "grad_norm": 5.640366077423096,
      "learning_rate": 4.6732240437158464e-07,
      "logits/chosen": 1.770328164100647,
      "logits/rejected": 1.7905588150024414,
      "logps/chosen": -156.48995971679688,
      "logps/rejected": -72.52394104003906,
      "loss": 0.34104599952697756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5009521245956421,
      "rewards/margins": 0.9176923632621765,
      "rewards/rejected": -0.4167402386665344,
      "step": 400
    },
    {
      "epoch": 0.4388546962804388,
      "grad_norm": 5.513765811920166,
      "learning_rate": 4.662295081967213e-07,
      "logits/chosen": 1.7738593816757202,
      "logits/rejected": 1.7476686239242554,
      "logps/chosen": -160.97093200683594,
      "logps/rejected": -73.36878204345703,
      "loss": 0.3168286561965942,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5848418474197388,
      "rewards/margins": 1.0141011476516724,
      "rewards/rejected": -0.42925921082496643,
      "step": 410
    },
    {
      "epoch": 0.4495584693604496,
      "grad_norm": 5.140445709228516,
      "learning_rate": 4.651366120218579e-07,
      "logits/chosen": 1.8044955730438232,
      "logits/rejected": 1.8697763681411743,
      "logps/chosen": -160.54498291015625,
      "logps/rejected": -72.71686553955078,
      "loss": 0.3175292730331421,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5357639193534851,
      "rewards/margins": 0.998553454875946,
      "rewards/rejected": -0.46278953552246094,
      "step": 420
    },
    {
      "epoch": 0.46026224244046027,
      "grad_norm": 5.378852844238281,
      "learning_rate": 4.640437158469945e-07,
      "logits/chosen": 1.7668836116790771,
      "logits/rejected": 1.8253040313720703,
      "logps/chosen": -159.06869506835938,
      "logps/rejected": -73.11555480957031,
      "loss": 0.3142409324645996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5424200296401978,
      "rewards/margins": 1.0229847431182861,
      "rewards/rejected": -0.48056483268737793,
      "step": 430
    },
    {
      "epoch": 0.47096601552047096,
      "grad_norm": 4.926112651824951,
      "learning_rate": 4.6295081967213113e-07,
      "logits/chosen": 1.8253841400146484,
      "logits/rejected": 1.8405574560165405,
      "logps/chosen": -154.3362579345703,
      "logps/rejected": -73.98931884765625,
      "loss": 0.2918151617050171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5944596529006958,
      "rewards/margins": 1.11243736743927,
      "rewards/rejected": -0.5179777145385742,
      "step": 440
    },
    {
      "epoch": 0.48166978860048165,
      "grad_norm": 5.213535785675049,
      "learning_rate": 4.6185792349726776e-07,
      "logits/chosen": 1.7885091304779053,
      "logits/rejected": 1.8195703029632568,
      "logps/chosen": -159.6781768798828,
      "logps/rejected": -74.87156677246094,
      "loss": 0.2732362985610962,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6446535587310791,
      "rewards/margins": 1.1925660371780396,
      "rewards/rejected": -0.5479124188423157,
      "step": 450
    },
    {
      "epoch": 0.4923735616804924,
      "grad_norm": 4.465903282165527,
      "learning_rate": 4.607650273224044e-07,
      "logits/chosen": 1.8170499801635742,
      "logits/rejected": 1.7966291904449463,
      "logps/chosen": -154.4861297607422,
      "logps/rejected": -74.51118469238281,
      "loss": 0.26926634311676023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6413015723228455,
      "rewards/margins": 1.2055747509002686,
      "rewards/rejected": -0.5642733573913574,
      "step": 460
    },
    {
      "epoch": 0.5030773347605031,
      "grad_norm": 4.684820652008057,
      "learning_rate": 4.5967213114754095e-07,
      "logits/chosen": 1.8400636911392212,
      "logits/rejected": 1.8353493213653564,
      "logps/chosen": -162.42608642578125,
      "logps/rejected": -74.98222351074219,
      "loss": 0.2574610233306885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.652793288230896,
      "rewards/margins": 1.25051748752594,
      "rewards/rejected": -0.597724199295044,
      "step": 470
    },
    {
      "epoch": 0.5137811078405138,
      "grad_norm": 4.326503276824951,
      "learning_rate": 4.585792349726776e-07,
      "logits/chosen": 1.7971071004867554,
      "logits/rejected": 1.790305733680725,
      "logps/chosen": -159.56289672851562,
      "logps/rejected": -75.2584457397461,
      "loss": 0.23904845714569092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7037224769592285,
      "rewards/margins": 1.3411359786987305,
      "rewards/rejected": -0.6374134421348572,
      "step": 480
    },
    {
      "epoch": 0.5244848809205245,
      "grad_norm": 4.167069911956787,
      "learning_rate": 4.574863387978142e-07,
      "logits/chosen": 1.7841503620147705,
      "logits/rejected": 1.8653568029403687,
      "logps/chosen": -165.16070556640625,
      "logps/rejected": -76.31249237060547,
      "loss": 0.23473503589630126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7132250070571899,
      "rewards/margins": 1.3674430847167969,
      "rewards/rejected": -0.6542181968688965,
      "step": 490
    },
    {
      "epoch": 0.5351886540005352,
      "grad_norm": 4.156453609466553,
      "learning_rate": 4.563934426229508e-07,
      "logits/chosen": 1.8409897089004517,
      "logits/rejected": 1.8359819650650024,
      "logps/chosen": -142.95703125,
      "logps/rejected": -75.07670593261719,
      "loss": 0.23639342784881592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7014516592025757,
      "rewards/margins": 1.3671777248382568,
      "rewards/rejected": -0.6657260060310364,
      "step": 500
    },
    {
      "epoch": 0.5458924270805459,
      "grad_norm": 3.7900516986846924,
      "learning_rate": 4.553005464480874e-07,
      "logits/chosen": 1.812766671180725,
      "logits/rejected": 1.8012014627456665,
      "logps/chosen": -150.61380004882812,
      "logps/rejected": -75.01448822021484,
      "loss": 0.22986876964569092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7077286243438721,
      "rewards/margins": 1.4026319980621338,
      "rewards/rejected": -0.6949034333229065,
      "step": 510
    },
    {
      "epoch": 0.5565962001605566,
      "grad_norm": 3.4346323013305664,
      "learning_rate": 4.54207650273224e-07,
      "logits/chosen": 1.8092663288116455,
      "logits/rejected": 1.7893707752227783,
      "logps/chosen": -151.3472900390625,
      "logps/rejected": -75.72801208496094,
      "loss": 0.2132643222808838,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7562977075576782,
      "rewards/margins": 1.4790534973144531,
      "rewards/rejected": -0.7227557301521301,
      "step": 520
    },
    {
      "epoch": 0.5672999732405672,
      "grad_norm": 3.513603925704956,
      "learning_rate": 4.5311475409836064e-07,
      "logits/chosen": 1.7969367504119873,
      "logits/rejected": 1.824254035949707,
      "logps/chosen": -155.95095825195312,
      "logps/rejected": -75.7593765258789,
      "loss": 0.21915624141693116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.731634795665741,
      "rewards/margins": 1.4689702987670898,
      "rewards/rejected": -0.7373355627059937,
      "step": 530
    },
    {
      "epoch": 0.578003746320578,
      "grad_norm": 4.138045787811279,
      "learning_rate": 4.520218579234972e-07,
      "logits/chosen": 1.7642877101898193,
      "logits/rejected": 1.820688009262085,
      "logps/chosen": -145.81431579589844,
      "logps/rejected": -76.89228820800781,
      "loss": 0.20521259307861328,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7130760550498962,
      "rewards/margins": 1.5259830951690674,
      "rewards/rejected": -0.8129068613052368,
      "step": 540
    },
    {
      "epoch": 0.5887075194005887,
      "grad_norm": 2.9567062854766846,
      "learning_rate": 4.509289617486339e-07,
      "logits/chosen": 1.7720463275909424,
      "logits/rejected": 1.7897975444793701,
      "logps/chosen": -152.9249267578125,
      "logps/rejected": -76.35782623291016,
      "loss": 0.1861492395401001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7950961589813232,
      "rewards/margins": 1.630152940750122,
      "rewards/rejected": -0.8350567817687988,
      "step": 550
    },
    {
      "epoch": 0.5994112924805994,
      "grad_norm": 2.969787359237671,
      "learning_rate": 4.4983606557377046e-07,
      "logits/chosen": 1.791115403175354,
      "logits/rejected": 1.8092257976531982,
      "logps/chosen": -143.38133239746094,
      "logps/rejected": -77.51371765136719,
      "loss": 0.1971064567565918,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7465590238571167,
      "rewards/margins": 1.5867109298706055,
      "rewards/rejected": -0.8401519656181335,
      "step": 560
    },
    {
      "epoch": 0.6101150655606101,
      "grad_norm": 3.3995563983917236,
      "learning_rate": 4.487431693989071e-07,
      "logits/chosen": 1.8000361919403076,
      "logits/rejected": 1.8211749792099,
      "logps/chosen": -155.05215454101562,
      "logps/rejected": -79.23160552978516,
      "loss": 0.17334927320480348,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.785712480545044,
      "rewards/margins": 1.723633050918579,
      "rewards/rejected": -0.9379204511642456,
      "step": 570
    },
    {
      "epoch": 0.6208188386406208,
      "grad_norm": 3.103102922439575,
      "learning_rate": 4.476502732240437e-07,
      "logits/chosen": 1.739972710609436,
      "logits/rejected": 1.812269926071167,
      "logps/chosen": -146.7483673095703,
      "logps/rejected": -78.83075714111328,
      "loss": 0.1659580111503601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8500654101371765,
      "rewards/margins": 1.7748111486434937,
      "rewards/rejected": -0.9247457385063171,
      "step": 580
    },
    {
      "epoch": 0.6315226117206315,
      "grad_norm": 3.165898084640503,
      "learning_rate": 4.465573770491803e-07,
      "logits/chosen": 1.8384262323379517,
      "logits/rejected": 1.8030710220336914,
      "logps/chosen": -160.6950225830078,
      "logps/rejected": -78.15794372558594,
      "loss": 0.15289690494537353,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8729274868965149,
      "rewards/margins": 1.8413591384887695,
      "rewards/rejected": -0.9684314727783203,
      "step": 590
    },
    {
      "epoch": 0.6422263848006422,
      "grad_norm": 3.076017141342163,
      "learning_rate": 4.454644808743169e-07,
      "logits/chosen": 1.819422721862793,
      "logits/rejected": 1.8624855279922485,
      "logps/chosen": -150.9158477783203,
      "logps/rejected": -78.68762969970703,
      "loss": 0.15469962358474731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8495267629623413,
      "rewards/margins": 1.8539130687713623,
      "rewards/rejected": -1.0043861865997314,
      "step": 600
    },
    {
      "epoch": 0.6529301578806529,
      "grad_norm": 3.3542444705963135,
      "learning_rate": 4.4437158469945353e-07,
      "logits/chosen": 1.7931493520736694,
      "logits/rejected": 1.7662004232406616,
      "logps/chosen": -156.47067260742188,
      "logps/rejected": -78.69563293457031,
      "loss": 0.15708862543106078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8011693954467773,
      "rewards/margins": 1.8293449878692627,
      "rewards/rejected": -1.0281753540039062,
      "step": 610
    },
    {
      "epoch": 0.6636339309606636,
      "grad_norm": 3.179837226867676,
      "learning_rate": 4.4327868852459015e-07,
      "logits/chosen": 1.786595106124878,
      "logits/rejected": 1.820146918296814,
      "logps/chosen": -152.81436157226562,
      "logps/rejected": -79.03211975097656,
      "loss": 0.14858046770095826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8299798965454102,
      "rewards/margins": 1.9021879434585571,
      "rewards/rejected": -1.0722078084945679,
      "step": 620
    },
    {
      "epoch": 0.6743377040406744,
      "grad_norm": 2.931001901626587,
      "learning_rate": 4.421857923497268e-07,
      "logits/chosen": 1.7775561809539795,
      "logits/rejected": 1.7981802225112915,
      "logps/chosen": -155.6448211669922,
      "logps/rejected": -80.45366668701172,
      "loss": 0.15442954301834105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7538518905639648,
      "rewards/margins": 1.8623638153076172,
      "rewards/rejected": -1.1085119247436523,
      "step": 630
    },
    {
      "epoch": 0.6850414771206851,
      "grad_norm": 3.2971746921539307,
      "learning_rate": 4.410928961748634e-07,
      "logits/chosen": 1.7837142944335938,
      "logits/rejected": 1.7658417224884033,
      "logps/chosen": -151.1968231201172,
      "logps/rejected": -78.75161743164062,
      "loss": 0.14259451627731323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8242725133895874,
      "rewards/margins": 1.9472805261611938,
      "rewards/rejected": -1.1230080127716064,
      "step": 640
    },
    {
      "epoch": 0.6957452502006958,
      "grad_norm": 2.9427597522735596,
      "learning_rate": 4.3999999999999997e-07,
      "logits/chosen": 1.843504548072815,
      "logits/rejected": 1.7960821390151978,
      "logps/chosen": -150.39749145507812,
      "logps/rejected": -80.89216613769531,
      "loss": 0.12209330797195435,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9342406392097473,
      "rewards/margins": 2.117431402206421,
      "rewards/rejected": -1.183190941810608,
      "step": 650
    },
    {
      "epoch": 0.7064490232807065,
      "grad_norm": 2.174078941345215,
      "learning_rate": 4.389071038251366e-07,
      "logits/chosen": 1.763603925704956,
      "logits/rejected": 1.781469702720642,
      "logps/chosen": -143.51356506347656,
      "logps/rejected": -80.98930358886719,
      "loss": 0.12900182008743286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8648360371589661,
      "rewards/margins": 2.0690298080444336,
      "rewards/rejected": -1.2041938304901123,
      "step": 660
    },
    {
      "epoch": 0.7171527963607172,
      "grad_norm": 2.731015920639038,
      "learning_rate": 4.378142076502732e-07,
      "logits/chosen": 1.850423812866211,
      "logits/rejected": 1.8077869415283203,
      "logps/chosen": -159.25588989257812,
      "logps/rejected": -81.06141662597656,
      "loss": 0.1196125864982605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9192136526107788,
      "rewards/margins": 2.1484951972961426,
      "rewards/rejected": -1.2292816638946533,
      "step": 670
    },
    {
      "epoch": 0.7278565694407279,
      "grad_norm": 2.2992358207702637,
      "learning_rate": 4.367213114754098e-07,
      "logits/chosen": 1.8160632848739624,
      "logits/rejected": 1.8401365280151367,
      "logps/chosen": -140.0146026611328,
      "logps/rejected": -82.35936737060547,
      "loss": 0.11418379545211792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8760480880737305,
      "rewards/margins": 2.1694564819335938,
      "rewards/rejected": -1.2934086322784424,
      "step": 680
    },
    {
      "epoch": 0.7385603425207385,
      "grad_norm": 2.5261237621307373,
      "learning_rate": 4.3562841530054647e-07,
      "logits/chosen": 1.7846043109893799,
      "logits/rejected": 1.7177053689956665,
      "logps/chosen": -162.27255249023438,
      "logps/rejected": -82.38078308105469,
      "loss": 0.10433937311172485,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9660691022872925,
      "rewards/margins": 2.294405460357666,
      "rewards/rejected": -1.3283361196517944,
      "step": 690
    },
    {
      "epoch": 0.7492641156007492,
      "grad_norm": 2.0589141845703125,
      "learning_rate": 4.3453551912568304e-07,
      "logits/chosen": 1.776180624961853,
      "logits/rejected": 1.7863147258758545,
      "logps/chosen": -149.65113830566406,
      "logps/rejected": -82.73945617675781,
      "loss": 0.10204199552536011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9478128552436829,
      "rewards/margins": 2.3019299507141113,
      "rewards/rejected": -1.3541171550750732,
      "step": 700
    },
    {
      "epoch": 0.7599678886807599,
      "grad_norm": 1.904205083847046,
      "learning_rate": 4.334426229508196e-07,
      "logits/chosen": 1.8321046829223633,
      "logits/rejected": 1.7787792682647705,
      "logps/chosen": -169.90652465820312,
      "logps/rejected": -82.6867904663086,
      "loss": 0.09450395107269287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.998293399810791,
      "rewards/margins": 2.405311107635498,
      "rewards/rejected": -1.407017707824707,
      "step": 710
    },
    {
      "epoch": 0.7706716617607706,
      "grad_norm": 2.5522873401641846,
      "learning_rate": 4.323497267759563e-07,
      "logits/chosen": 1.7917639017105103,
      "logits/rejected": 1.7664276361465454,
      "logps/chosen": -149.2853240966797,
      "logps/rejected": -83.3419189453125,
      "loss": 0.09824571013450623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9395872354507446,
      "rewards/margins": 2.3770480155944824,
      "rewards/rejected": -1.4374607801437378,
      "step": 720
    },
    {
      "epoch": 0.7813754348407814,
      "grad_norm": 1.9055136442184448,
      "learning_rate": 4.3125683060109286e-07,
      "logits/chosen": 1.7494118213653564,
      "logits/rejected": 1.7055559158325195,
      "logps/chosen": -148.74447631835938,
      "logps/rejected": -85.08723449707031,
      "loss": 0.08772898316383362,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9730061292648315,
      "rewards/margins": 2.487753391265869,
      "rewards/rejected": -1.5147473812103271,
      "step": 730
    },
    {
      "epoch": 0.7920792079207921,
      "grad_norm": 1.6576265096664429,
      "learning_rate": 4.301639344262295e-07,
      "logits/chosen": 1.8033357858657837,
      "logits/rejected": 1.6875845193862915,
      "logps/chosen": -163.80084228515625,
      "logps/rejected": -84.67510986328125,
      "loss": 0.08052144050598145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0615533590316772,
      "rewards/margins": 2.60038423538208,
      "rewards/rejected": -1.5388309955596924,
      "step": 740
    },
    {
      "epoch": 0.8027829810008028,
      "grad_norm": 1.7653721570968628,
      "learning_rate": 4.290710382513661e-07,
      "logits/chosen": 1.8351141214370728,
      "logits/rejected": 1.65499746799469,
      "logps/chosen": -157.83262634277344,
      "logps/rejected": -84.69694519042969,
      "loss": 0.07486096620559693,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0277754068374634,
      "rewards/margins": 2.637855291366577,
      "rewards/rejected": -1.6100800037384033,
      "step": 750
    },
    {
      "epoch": 0.8134867540808135,
      "grad_norm": 1.6472928524017334,
      "learning_rate": 4.2797814207650273e-07,
      "logits/chosen": 1.6718753576278687,
      "logits/rejected": 1.6622778177261353,
      "logps/chosen": -146.2825469970703,
      "logps/rejected": -84.47618103027344,
      "loss": 0.07485225200653076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0219066143035889,
      "rewards/margins": 2.6572508811950684,
      "rewards/rejected": -1.6353442668914795,
      "step": 760
    },
    {
      "epoch": 0.8241905271608242,
      "grad_norm": 1.7153552770614624,
      "learning_rate": 4.268852459016393e-07,
      "logits/chosen": 1.7719131708145142,
      "logits/rejected": 1.681692361831665,
      "logps/chosen": -163.47219848632812,
      "logps/rejected": -86.72774505615234,
      "loss": 0.07162449955940246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0017569065093994,
      "rewards/margins": 2.702376365661621,
      "rewards/rejected": -1.7006194591522217,
      "step": 770
    },
    {
      "epoch": 0.8348943002408349,
      "grad_norm": 1.7915538549423218,
      "learning_rate": 4.257923497267759e-07,
      "logits/chosen": 1.7588112354278564,
      "logits/rejected": 1.761612892150879,
      "logps/chosen": -158.7922821044922,
      "logps/rejected": -85.04820251464844,
      "loss": 0.08087860941886901,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9474912881851196,
      "rewards/margins": 2.605459690093994,
      "rewards/rejected": -1.657968282699585,
      "step": 780
    },
    {
      "epoch": 0.8455980733208456,
      "grad_norm": 1.5435279607772827,
      "learning_rate": 4.2469945355191255e-07,
      "logits/chosen": 1.6815217733383179,
      "logits/rejected": 1.659170150756836,
      "logps/chosen": -141.67153930664062,
      "logps/rejected": -86.1138687133789,
      "loss": 0.07111806273460389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.959647536277771,
      "rewards/margins": 2.725346326828003,
      "rewards/rejected": -1.765699028968811,
      "step": 790
    },
    {
      "epoch": 0.8563018464008563,
      "grad_norm": 1.192418098449707,
      "learning_rate": 4.2360655737704917e-07,
      "logits/chosen": 1.7205194234848022,
      "logits/rejected": 1.5790023803710938,
      "logps/chosen": -140.65902709960938,
      "logps/rejected": -87.70341491699219,
      "loss": 0.06502756476402283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0407321453094482,
      "rewards/margins": 2.853187084197998,
      "rewards/rejected": -1.8124549388885498,
      "step": 800
    },
    {
      "epoch": 0.867005619480867,
      "grad_norm": 1.2954949140548706,
      "learning_rate": 4.225136612021858e-07,
      "logits/chosen": 1.7844030857086182,
      "logits/rejected": 1.6893689632415771,
      "logps/chosen": -155.53677368164062,
      "logps/rejected": -86.67449188232422,
      "loss": 0.06417385935783386,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0463283061981201,
      "rewards/margins": 2.8428380489349365,
      "rewards/rejected": -1.796510100364685,
      "step": 810
    },
    {
      "epoch": 0.8777093925608777,
      "grad_norm": 1.8784531354904175,
      "learning_rate": 4.2142076502732236e-07,
      "logits/chosen": 1.8235204219818115,
      "logits/rejected": 1.739553451538086,
      "logps/chosen": -149.76885986328125,
      "logps/rejected": -87.57658386230469,
      "loss": 0.06573216319084167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9877670407295227,
      "rewards/margins": 2.8412609100341797,
      "rewards/rejected": -1.8534940481185913,
      "step": 820
    },
    {
      "epoch": 0.8884131656408885,
      "grad_norm": 1.3906311988830566,
      "learning_rate": 4.2032786885245904e-07,
      "logits/chosen": 1.7170041799545288,
      "logits/rejected": 1.6727221012115479,
      "logps/chosen": -142.951904296875,
      "logps/rejected": -89.37434387207031,
      "loss": 0.05886092782020569,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.964301586151123,
      "rewards/margins": 2.9349441528320312,
      "rewards/rejected": -1.9706424474716187,
      "step": 830
    },
    {
      "epoch": 0.8991169387208992,
      "grad_norm": 0.9178356528282166,
      "learning_rate": 4.192349726775956e-07,
      "logits/chosen": 1.7838985919952393,
      "logits/rejected": 1.6357009410858154,
      "logps/chosen": -160.9322967529297,
      "logps/rejected": -87.64883422851562,
      "loss": 0.055837112665176394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0890274047851562,
      "rewards/margins": 3.0316686630249023,
      "rewards/rejected": -1.9426414966583252,
      "step": 840
    },
    {
      "epoch": 0.9098207118009098,
      "grad_norm": 1.0754969120025635,
      "learning_rate": 4.181420765027322e-07,
      "logits/chosen": 1.788027048110962,
      "logits/rejected": 1.5935801267623901,
      "logps/chosen": -162.02935791015625,
      "logps/rejected": -89.02740478515625,
      "loss": 0.04708324670791626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1095348596572876,
      "rewards/margins": 3.150054454803467,
      "rewards/rejected": -2.040519952774048,
      "step": 850
    },
    {
      "epoch": 0.9205244848809205,
      "grad_norm": 1.1452856063842773,
      "learning_rate": 4.1704918032786886e-07,
      "logits/chosen": 1.7593824863433838,
      "logits/rejected": 1.6450179815292358,
      "logps/chosen": -150.4923553466797,
      "logps/rejected": -89.09027862548828,
      "loss": 0.04953871369361877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0339109897613525,
      "rewards/margins": 3.0847699642181396,
      "rewards/rejected": -2.050858736038208,
      "step": 860
    },
    {
      "epoch": 0.9312282579609312,
      "grad_norm": 0.9945034384727478,
      "learning_rate": 4.1595628415300543e-07,
      "logits/chosen": 1.7284057140350342,
      "logits/rejected": 1.629233717918396,
      "logps/chosen": -161.48593139648438,
      "logps/rejected": -91.5926513671875,
      "loss": 0.04700658917427063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0734291076660156,
      "rewards/margins": 3.232520580291748,
      "rewards/rejected": -2.1590917110443115,
      "step": 870
    },
    {
      "epoch": 0.9419320310409419,
      "grad_norm": 1.6321930885314941,
      "learning_rate": 4.1486338797814206e-07,
      "logits/chosen": 1.7180430889129639,
      "logits/rejected": 1.6240301132202148,
      "logps/chosen": -146.04124450683594,
      "logps/rejected": -90.5680923461914,
      "loss": 0.04806958734989166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9799259305000305,
      "rewards/margins": 3.1595466136932373,
      "rewards/rejected": -2.1796205043792725,
      "step": 880
    },
    {
      "epoch": 0.9526358041209526,
      "grad_norm": 0.8668941259384155,
      "learning_rate": 4.137704918032787e-07,
      "logits/chosen": 1.7094818353652954,
      "logits/rejected": 1.5231965780258179,
      "logps/chosen": -156.80088806152344,
      "logps/rejected": -92.11121368408203,
      "loss": 0.046077588200569154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9766501188278198,
      "rewards/margins": 3.239579439163208,
      "rewards/rejected": -2.2629292011260986,
      "step": 890
    },
    {
      "epoch": 0.9633395772009633,
      "grad_norm": 1.4290539026260376,
      "learning_rate": 4.126775956284153e-07,
      "logits/chosen": 1.7265279293060303,
      "logits/rejected": 1.584498405456543,
      "logps/chosen": -142.72727966308594,
      "logps/rejected": -92.38348388671875,
      "loss": 0.03659718930721283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1476142406463623,
      "rewards/margins": 3.4494094848632812,
      "rewards/rejected": -2.301795244216919,
      "step": 900
    },
    {
      "epoch": 0.974043350280974,
      "grad_norm": 0.8241678476333618,
      "learning_rate": 4.115846994535519e-07,
      "logits/chosen": 1.7337844371795654,
      "logits/rejected": 1.58919358253479,
      "logps/chosen": -152.03326416015625,
      "logps/rejected": -92.68684387207031,
      "loss": 0.04033022522926331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0825837850570679,
      "rewards/margins": 3.392866611480713,
      "rewards/rejected": -2.3102829456329346,
      "step": 910
    },
    {
      "epoch": 0.9847471233609848,
      "grad_norm": 0.8369371891021729,
      "learning_rate": 4.104918032786885e-07,
      "logits/chosen": 1.8130000829696655,
      "logits/rejected": 1.5563679933547974,
      "logps/chosen": -177.03248596191406,
      "logps/rejected": -93.50448608398438,
      "loss": 0.032793253660202026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1613147258758545,
      "rewards/margins": 3.574037551879883,
      "rewards/rejected": -2.412722587585449,
      "step": 920
    },
    {
      "epoch": 0.9954508964409955,
      "grad_norm": 0.588119387626648,
      "learning_rate": 4.093989071038251e-07,
      "logits/chosen": 1.7225919961929321,
      "logits/rejected": 1.517499566078186,
      "logps/chosen": -145.09872436523438,
      "logps/rejected": -93.66281127929688,
      "loss": 0.03417066931724548,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0797823667526245,
      "rewards/margins": 3.5223441123962402,
      "rewards/rejected": -2.4425618648529053,
      "step": 930
    },
    {
      "epoch": 1.0053518865400053,
      "grad_norm": 0.8849689364433289,
      "learning_rate": 4.083060109289617e-07,
      "logits/chosen": 1.5755726099014282,
      "logits/rejected": 1.4725950956344604,
      "logps/chosen": -132.5122833251953,
      "logps/rejected": -95.16565704345703,
      "loss": 0.03245730400085449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0501840114593506,
      "rewards/margins": 3.6119842529296875,
      "rewards/rejected": -2.561800241470337,
      "step": 940
    },
    {
      "epoch": 1.016055659620016,
      "grad_norm": 0.8366124033927917,
      "learning_rate": 4.0721311475409837e-07,
      "logits/chosen": 1.8341636657714844,
      "logits/rejected": 1.4668307304382324,
      "logps/chosen": -165.87979125976562,
      "logps/rejected": -95.01008605957031,
      "loss": 0.031292271614074704,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0788172483444214,
      "rewards/margins": 3.6775989532470703,
      "rewards/rejected": -2.5987815856933594,
      "step": 950
    },
    {
      "epoch": 1.0267594327000267,
      "grad_norm": 0.6333491802215576,
      "learning_rate": 4.0612021857923494e-07,
      "logits/chosen": 1.7061717510223389,
      "logits/rejected": 1.4761234521865845,
      "logps/chosen": -154.01495361328125,
      "logps/rejected": -96.00778198242188,
      "loss": 0.03177412748336792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0302543640136719,
      "rewards/margins": 3.6437790393829346,
      "rewards/rejected": -2.6135246753692627,
      "step": 960
    },
    {
      "epoch": 1.0374632057800375,
      "grad_norm": 0.9965106844902039,
      "learning_rate": 4.0502732240437156e-07,
      "logits/chosen": 1.695291519165039,
      "logits/rejected": 1.5310051441192627,
      "logps/chosen": -151.8094940185547,
      "logps/rejected": -94.58476257324219,
      "loss": 0.028743746876716613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1636403799057007,
      "rewards/margins": 3.7653377056121826,
      "rewards/rejected": -2.6016972064971924,
      "step": 970
    },
    {
      "epoch": 1.048166978860048,
      "grad_norm": 0.7560970783233643,
      "learning_rate": 4.039344262295082e-07,
      "logits/chosen": 1.755011796951294,
      "logits/rejected": 1.3940136432647705,
      "logps/chosen": -167.62318420410156,
      "logps/rejected": -96.64051818847656,
      "loss": 0.023827163875102995,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1457898616790771,
      "rewards/margins": 3.9066014289855957,
      "rewards/rejected": -2.7608115673065186,
      "step": 980
    },
    {
      "epoch": 1.0588707519400589,
      "grad_norm": 0.8368943333625793,
      "learning_rate": 4.0284153005464476e-07,
      "logits/chosen": 1.7236073017120361,
      "logits/rejected": 1.471868872642517,
      "logps/chosen": -146.08102416992188,
      "logps/rejected": -95.93193054199219,
      "loss": 0.025808066129684448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1423739194869995,
      "rewards/margins": 3.8906846046447754,
      "rewards/rejected": -2.7483105659484863,
      "step": 990
    },
    {
      "epoch": 1.0695745250200697,
      "grad_norm": 0.5986548662185669,
      "learning_rate": 4.0174863387978144e-07,
      "logits/chosen": 1.644383192062378,
      "logits/rejected": 1.303471326828003,
      "logps/chosen": -149.46023559570312,
      "logps/rejected": -97.68709564208984,
      "loss": 0.022938047349452973,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1230791807174683,
      "rewards/margins": 3.9801979064941406,
      "rewards/rejected": -2.857118606567383,
      "step": 1000
    },
    {
      "epoch": 1.0802782981000802,
      "grad_norm": 0.6457048058509827,
      "learning_rate": 4.00655737704918e-07,
      "logits/chosen": 1.6980746984481812,
      "logits/rejected": 1.3307790756225586,
      "logps/chosen": -159.41468811035156,
      "logps/rejected": -99.05873107910156,
      "loss": 0.023854197561740877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0730946063995361,
      "rewards/margins": 3.969989776611328,
      "rewards/rejected": -2.896894931793213,
      "step": 1010
    },
    {
      "epoch": 1.090982071180091,
      "grad_norm": 0.9346348643302917,
      "learning_rate": 3.9956284153005463e-07,
      "logits/chosen": 1.746276617050171,
      "logits/rejected": 1.410571813583374,
      "logps/chosen": -157.96530151367188,
      "logps/rejected": -99.2369155883789,
      "loss": 0.024355484545230864,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9926129579544067,
      "rewards/margins": 3.9418463706970215,
      "rewards/rejected": -2.9492335319519043,
      "step": 1020
    },
    {
      "epoch": 1.1016858442601016,
      "grad_norm": 0.9981865286827087,
      "learning_rate": 3.9846994535519126e-07,
      "logits/chosen": 1.6944652795791626,
      "logits/rejected": 1.3456825017929077,
      "logps/chosen": -143.97689819335938,
      "logps/rejected": -97.63856506347656,
      "loss": 0.027583912014961243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0066230297088623,
      "rewards/margins": 3.950909376144409,
      "rewards/rejected": -2.944286823272705,
      "step": 1030
    },
    {
      "epoch": 1.1123896173401124,
      "grad_norm": 0.40167346596717834,
      "learning_rate": 3.973770491803278e-07,
      "logits/chosen": 1.7114397287368774,
      "logits/rejected": 1.293777346611023,
      "logps/chosen": -163.22914123535156,
      "logps/rejected": -99.56421661376953,
      "loss": 0.01984236389398575,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1040815114974976,
      "rewards/margins": 4.195456504821777,
      "rewards/rejected": -3.0913748741149902,
      "step": 1040
    },
    {
      "epoch": 1.123093390420123,
      "grad_norm": 0.46220362186431885,
      "learning_rate": 3.9628415300546445e-07,
      "logits/chosen": 1.7259594202041626,
      "logits/rejected": 1.3666250705718994,
      "logps/chosen": -154.5895233154297,
      "logps/rejected": -98.67662048339844,
      "loss": 0.018726345896720887,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1358704566955566,
      "rewards/margins": 4.176422595977783,
      "rewards/rejected": -3.0405516624450684,
      "step": 1050
    },
    {
      "epoch": 1.1337971635001338,
      "grad_norm": 0.9118120670318604,
      "learning_rate": 3.951912568306011e-07,
      "logits/chosen": 1.7006441354751587,
      "logits/rejected": 1.282173991203308,
      "logps/chosen": -157.17379760742188,
      "logps/rejected": -99.81719970703125,
      "loss": 0.020315879583358766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.035856008529663,
      "rewards/margins": 4.141615390777588,
      "rewards/rejected": -3.1057591438293457,
      "step": 1060
    },
    {
      "epoch": 1.1445009365801444,
      "grad_norm": 0.6183236241340637,
      "learning_rate": 3.940983606557377e-07,
      "logits/chosen": 1.7149302959442139,
      "logits/rejected": 1.2687909603118896,
      "logps/chosen": -154.16815185546875,
      "logps/rejected": -101.94291687011719,
      "loss": 0.019633619487285613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.071311593055725,
      "rewards/margins": 4.297905445098877,
      "rewards/rejected": -3.2265942096710205,
      "step": 1070
    },
    {
      "epoch": 1.1552047096601552,
      "grad_norm": 0.48427698016166687,
      "learning_rate": 3.9300546448087427e-07,
      "logits/chosen": 1.7651933431625366,
      "logits/rejected": 1.3281927108764648,
      "logps/chosen": -158.3819580078125,
      "logps/rejected": -100.43812561035156,
      "loss": 0.015394061803817749,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.169189691543579,
      "rewards/margins": 4.354580879211426,
      "rewards/rejected": -3.1853911876678467,
      "step": 1080
    },
    {
      "epoch": 1.165908482740166,
      "grad_norm": 0.8450509905815125,
      "learning_rate": 3.9191256830601095e-07,
      "logits/chosen": 1.658064603805542,
      "logits/rejected": 1.224921464920044,
      "logps/chosen": -136.96585083007812,
      "logps/rejected": -103.66092681884766,
      "loss": 0.016760839521884917,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.045638084411621,
      "rewards/margins": 4.36219596862793,
      "rewards/rejected": -3.3165574073791504,
      "step": 1090
    },
    {
      "epoch": 1.1766122558201766,
      "grad_norm": 0.4204149544239044,
      "learning_rate": 3.908196721311475e-07,
      "logits/chosen": 1.6076500415802002,
      "logits/rejected": 1.3003630638122559,
      "logps/chosen": -147.70803833007812,
      "logps/rejected": -101.76332092285156,
      "loss": 0.016228657960891724,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.186042070388794,
      "rewards/margins": 4.416829586029053,
      "rewards/rejected": -3.230787992477417,
      "step": 1100
    },
    {
      "epoch": 1.1873160289001874,
      "grad_norm": 0.41651085019111633,
      "learning_rate": 3.8972677595628414e-07,
      "logits/chosen": 1.6439168453216553,
      "logits/rejected": 1.3227794170379639,
      "logps/chosen": -151.53140258789062,
      "logps/rejected": -101.81876373291016,
      "loss": 0.016530880331993104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0728799104690552,
      "rewards/margins": 4.331194877624512,
      "rewards/rejected": -3.258314847946167,
      "step": 1110
    },
    {
      "epoch": 1.198019801980198,
      "grad_norm": 0.4798126220703125,
      "learning_rate": 3.8863387978142076e-07,
      "logits/chosen": 1.6710643768310547,
      "logits/rejected": 1.1560618877410889,
      "logps/chosen": -158.01406860351562,
      "logps/rejected": -104.6727066040039,
      "loss": 0.014420031011104584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1185719966888428,
      "rewards/margins": 4.616798400878906,
      "rewards/rejected": -3.4982261657714844,
      "step": 1120
    },
    {
      "epoch": 1.2087235750602088,
      "grad_norm": 0.4670336842536926,
      "learning_rate": 3.8754098360655734e-07,
      "logits/chosen": 1.7404367923736572,
      "logits/rejected": 1.2171227931976318,
      "logps/chosen": -157.28460693359375,
      "logps/rejected": -103.58821105957031,
      "loss": 0.014666354656219483,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1248199939727783,
      "rewards/margins": 4.555264472961426,
      "rewards/rejected": -3.4304442405700684,
      "step": 1130
    },
    {
      "epoch": 1.2194273481402194,
      "grad_norm": 0.40709778666496277,
      "learning_rate": 3.86448087431694e-07,
      "logits/chosen": 1.598455786705017,
      "logits/rejected": 1.151465654373169,
      "logps/chosen": -148.83920288085938,
      "logps/rejected": -103.59617614746094,
      "loss": 0.013742342591285706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1368348598480225,
      "rewards/margins": 4.581087112426758,
      "rewards/rejected": -3.4442524909973145,
      "step": 1140
    },
    {
      "epoch": 1.2301311212202302,
      "grad_norm": 0.23900964856147766,
      "learning_rate": 3.853551912568306e-07,
      "logits/chosen": 1.634079933166504,
      "logits/rejected": 1.2009283304214478,
      "logps/chosen": -153.06735229492188,
      "logps/rejected": -104.62846374511719,
      "loss": 0.013513228297233582,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0884206295013428,
      "rewards/margins": 4.588320732116699,
      "rewards/rejected": -3.4999003410339355,
      "step": 1150
    },
    {
      "epoch": 1.2408348943002407,
      "grad_norm": 0.3809467852115631,
      "learning_rate": 3.8426229508196715e-07,
      "logits/chosen": 1.6272766590118408,
      "logits/rejected": 1.198920488357544,
      "logps/chosen": -156.12417602539062,
      "logps/rejected": -104.25091552734375,
      "loss": 0.013800825178623199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0724321603775024,
      "rewards/margins": 4.614104270935059,
      "rewards/rejected": -3.541672468185425,
      "step": 1160
    },
    {
      "epoch": 1.2515386673802515,
      "grad_norm": 0.23170055449008942,
      "learning_rate": 3.8316939890710383e-07,
      "logits/chosen": 1.608130693435669,
      "logits/rejected": 1.1872681379318237,
      "logps/chosen": -140.0825958251953,
      "logps/rejected": -103.0272445678711,
      "loss": 0.015065607428550721,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0024986267089844,
      "rewards/margins": 4.543237209320068,
      "rewards/rejected": -3.540738582611084,
      "step": 1170
    },
    {
      "epoch": 1.2622424404602621,
      "grad_norm": 0.4358747899532318,
      "learning_rate": 3.820765027322404e-07,
      "logits/chosen": 1.6957542896270752,
      "logits/rejected": 1.1685556173324585,
      "logps/chosen": -169.14918518066406,
      "logps/rejected": -104.20523834228516,
      "loss": 0.014322775602340698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9869871139526367,
      "rewards/margins": 4.530843734741211,
      "rewards/rejected": -3.5438568592071533,
      "step": 1180
    },
    {
      "epoch": 1.272946213540273,
      "grad_norm": 0.4058906137943268,
      "learning_rate": 3.8098360655737703e-07,
      "logits/chosen": 1.6327699422836304,
      "logits/rejected": 1.1227926015853882,
      "logps/chosen": -150.0608673095703,
      "logps/rejected": -105.39753723144531,
      "loss": 0.012888216972351074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0483556985855103,
      "rewards/margins": 4.657876968383789,
      "rewards/rejected": -3.6095213890075684,
      "step": 1190
    },
    {
      "epoch": 1.2836499866202837,
      "grad_norm": 0.5216193795204163,
      "learning_rate": 3.7989071038251365e-07,
      "logits/chosen": 1.564469575881958,
      "logits/rejected": 1.1601684093475342,
      "logps/chosen": -147.4188690185547,
      "logps/rejected": -103.6126937866211,
      "loss": 0.013099354505538941,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1141846179962158,
      "rewards/margins": 4.68864107131958,
      "rewards/rejected": -3.5744564533233643,
      "step": 1200
    },
    {
      "epoch": 1.2943537597002943,
      "grad_norm": 0.3623017370700836,
      "learning_rate": 3.787978142076503e-07,
      "logits/chosen": 1.590881586074829,
      "logits/rejected": 1.1287685632705688,
      "logps/chosen": -144.04910278320312,
      "logps/rejected": -108.01960754394531,
      "loss": 0.010898669064044953,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0596532821655273,
      "rewards/margins": 4.857486724853516,
      "rewards/rejected": -3.7978336811065674,
      "step": 1210
    },
    {
      "epoch": 1.3050575327803051,
      "grad_norm": 0.643327534198761,
      "learning_rate": 3.7770491803278685e-07,
      "logits/chosen": 1.6923789978027344,
      "logits/rejected": 1.1569429636001587,
      "logps/chosen": -151.11279296875,
      "logps/rejected": -104.87245178222656,
      "loss": 0.012995848059654235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0897698402404785,
      "rewards/margins": 4.703740119934082,
      "rewards/rejected": -3.6139702796936035,
      "step": 1220
    },
    {
      "epoch": 1.3157613058603157,
      "grad_norm": 0.4268481135368347,
      "learning_rate": 3.7661202185792347e-07,
      "logits/chosen": 1.6177021265029907,
      "logits/rejected": 1.152500867843628,
      "logps/chosen": -149.55088806152344,
      "logps/rejected": -105.1697006225586,
      "loss": 0.013492313027381898,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0310444831848145,
      "rewards/margins": 4.722887992858887,
      "rewards/rejected": -3.691843032836914,
      "step": 1230
    },
    {
      "epoch": 1.3264650789403265,
      "grad_norm": 0.4189468324184418,
      "learning_rate": 3.755191256830601e-07,
      "logits/chosen": 1.5691771507263184,
      "logits/rejected": 1.0491870641708374,
      "logps/chosen": -147.62387084960938,
      "logps/rejected": -107.48197937011719,
      "loss": 0.009806272387504578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1246130466461182,
      "rewards/margins": 4.981541633605957,
      "rewards/rejected": -3.8569283485412598,
      "step": 1240
    },
    {
      "epoch": 1.337168852020337,
      "grad_norm": 0.4989025592803955,
      "learning_rate": 3.7442622950819666e-07,
      "logits/chosen": 1.5755879878997803,
      "logits/rejected": 1.1296265125274658,
      "logps/chosen": -145.77291870117188,
      "logps/rejected": -105.25823974609375,
      "loss": 0.013076119124889374,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0347206592559814,
      "rewards/margins": 4.753051280975342,
      "rewards/rejected": -3.7183303833007812,
      "step": 1250
    },
    {
      "epoch": 1.3478726251003479,
      "grad_norm": 0.5551984906196594,
      "learning_rate": 3.7333333333333334e-07,
      "logits/chosen": 1.6291338205337524,
      "logits/rejected": 1.0504906177520752,
      "logps/chosen": -144.68692016601562,
      "logps/rejected": -108.4250717163086,
      "loss": 0.010129830241203308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2097426652908325,
      "rewards/margins": 5.105389595031738,
      "rewards/rejected": -3.895646572113037,
      "step": 1260
    },
    {
      "epoch": 1.3585763981803587,
      "grad_norm": 0.5045070648193359,
      "learning_rate": 3.722404371584699e-07,
      "logits/chosen": 1.6289771795272827,
      "logits/rejected": 1.019251823425293,
      "logps/chosen": -155.4300079345703,
      "logps/rejected": -108.71073150634766,
      "loss": 0.01139356791973114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0658457279205322,
      "rewards/margins": 5.054738521575928,
      "rewards/rejected": -3.988893508911133,
      "step": 1270
    },
    {
      "epoch": 1.3692801712603693,
      "grad_norm": 0.2792329788208008,
      "learning_rate": 3.711475409836066e-07,
      "logits/chosen": 1.5823785066604614,
      "logits/rejected": 0.9874511957168579,
      "logps/chosen": -136.4674530029297,
      "logps/rejected": -108.90467834472656,
      "loss": 0.008782903105020523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0923821926116943,
      "rewards/margins": 5.126376628875732,
      "rewards/rejected": -4.033994197845459,
      "step": 1280
    },
    {
      "epoch": 1.3799839443403799,
      "grad_norm": 0.28426870703697205,
      "learning_rate": 3.7005464480874316e-07,
      "logits/chosen": 1.5859463214874268,
      "logits/rejected": 1.117956280708313,
      "logps/chosen": -152.60537719726562,
      "logps/rejected": -107.889404296875,
      "loss": 0.010051801055669784,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.067343831062317,
      "rewards/margins": 5.025265216827393,
      "rewards/rejected": -3.9579215049743652,
      "step": 1290
    },
    {
      "epoch": 1.3906877174203907,
      "grad_norm": 0.22787357866764069,
      "learning_rate": 3.6896174863387973e-07,
      "logits/chosen": 1.5156147480010986,
      "logits/rejected": 0.9835519790649414,
      "logps/chosen": -128.3076629638672,
      "logps/rejected": -108.5299072265625,
      "loss": 0.008618803322315216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0897668600082397,
      "rewards/margins": 5.150269985198975,
      "rewards/rejected": -4.060503005981445,
      "step": 1300
    },
    {
      "epoch": 1.4013914905004015,
      "grad_norm": 0.1400226354598999,
      "learning_rate": 3.678688524590164e-07,
      "logits/chosen": 1.6013435125350952,
      "logits/rejected": 1.0340789556503296,
      "logps/chosen": -149.16268920898438,
      "logps/rejected": -108.9002685546875,
      "loss": 0.00866018682718277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.120958924293518,
      "rewards/margins": 5.195265293121338,
      "rewards/rejected": -4.074306488037109,
      "step": 1310
    },
    {
      "epoch": 1.412095263580412,
      "grad_norm": 0.2601236402988434,
      "learning_rate": 3.66775956284153e-07,
      "logits/chosen": 1.6872774362564087,
      "logits/rejected": 1.0182682275772095,
      "logps/chosen": -157.99490356445312,
      "logps/rejected": -110.9283218383789,
      "loss": 0.009131181985139847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.010909080505371,
      "rewards/margins": 5.104722023010254,
      "rewards/rejected": -4.093812942504883,
      "step": 1320
    },
    {
      "epoch": 1.4227990366604228,
      "grad_norm": 0.2117798924446106,
      "learning_rate": 3.656830601092896e-07,
      "logits/chosen": 1.634985327720642,
      "logits/rejected": 1.1040092706680298,
      "logps/chosen": -151.16329956054688,
      "logps/rejected": -107.21158599853516,
      "loss": 0.0102551631629467,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0900437831878662,
      "rewards/margins": 5.004817008972168,
      "rewards/rejected": -3.914773464202881,
      "step": 1330
    },
    {
      "epoch": 1.4335028097404334,
      "grad_norm": 0.22261206805706024,
      "learning_rate": 3.6459016393442623e-07,
      "logits/chosen": 1.6284105777740479,
      "logits/rejected": 0.9671529531478882,
      "logps/chosen": -154.08065795898438,
      "logps/rejected": -111.91996002197266,
      "loss": 0.005895167216658592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.248009443283081,
      "rewards/margins": 5.459428310394287,
      "rewards/rejected": -4.211419105529785,
      "step": 1340
    },
    {
      "epoch": 1.4442065828204442,
      "grad_norm": 0.5116671323776245,
      "learning_rate": 3.634972677595628e-07,
      "logits/chosen": 1.5597525835037231,
      "logits/rejected": 0.9500673413276672,
      "logps/chosen": -154.83474731445312,
      "logps/rejected": -109.31138610839844,
      "loss": 0.008137129992246629,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1510223150253296,
      "rewards/margins": 5.236159324645996,
      "rewards/rejected": -4.085136890411377,
      "step": 1350
    },
    {
      "epoch": 1.4549103559004548,
      "grad_norm": 0.38766947388648987,
      "learning_rate": 3.624043715846994e-07,
      "logits/chosen": 1.5665686130523682,
      "logits/rejected": 0.9719702005386353,
      "logps/chosen": -149.33465576171875,
      "logps/rejected": -110.83180236816406,
      "loss": 0.007921382784843445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0418528318405151,
      "rewards/margins": 5.186440467834473,
      "rewards/rejected": -4.144588470458984,
      "step": 1360
    },
    {
      "epoch": 1.4656141289804656,
      "grad_norm": 0.227491557598114,
      "learning_rate": 3.6131147540983605e-07,
      "logits/chosen": 1.49527907371521,
      "logits/rejected": 0.9250208735466003,
      "logps/chosen": -140.29666137695312,
      "logps/rejected": -113.23548889160156,
      "loss": 0.006601744145154953,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0471017360687256,
      "rewards/margins": 5.429178714752197,
      "rewards/rejected": -4.382077217102051,
      "step": 1370
    },
    {
      "epoch": 1.4763179020604764,
      "grad_norm": 0.36765435338020325,
      "learning_rate": 3.6021857923497267e-07,
      "logits/chosen": 1.6231693029403687,
      "logits/rejected": 0.9676400423049927,
      "logps/chosen": -149.10072326660156,
      "logps/rejected": -112.33113098144531,
      "loss": 0.008004538714885712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0391027927398682,
      "rewards/margins": 5.326772212982178,
      "rewards/rejected": -4.2876691818237305,
      "step": 1380
    },
    {
      "epoch": 1.487021675140487,
      "grad_norm": 0.44688349962234497,
      "learning_rate": 3.5912568306010924e-07,
      "logits/chosen": 1.6091368198394775,
      "logits/rejected": 0.8703486323356628,
      "logps/chosen": -149.99563598632812,
      "logps/rejected": -111.2745590209961,
      "loss": 0.00832662507891655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0202630758285522,
      "rewards/margins": 5.358219623565674,
      "rewards/rejected": -4.337956428527832,
      "step": 1390
    },
    {
      "epoch": 1.4977254482204978,
      "grad_norm": 0.4907837510108948,
      "learning_rate": 3.580327868852459e-07,
      "logits/chosen": 1.6005843877792358,
      "logits/rejected": 0.976699709892273,
      "logps/chosen": -154.8329620361328,
      "logps/rejected": -111.04893493652344,
      "loss": 0.007755400985479355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0370457172393799,
      "rewards/margins": 5.337039470672607,
      "rewards/rejected": -4.299993991851807,
      "step": 1400
    },
    {
      "epoch": 1.5084292213005084,
      "grad_norm": 0.2778608798980713,
      "learning_rate": 3.569398907103825e-07,
      "logits/chosen": 1.505464792251587,
      "logits/rejected": 0.9065073728561401,
      "logps/chosen": -140.48153686523438,
      "logps/rejected": -113.8782730102539,
      "loss": 0.0067954003810882565,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.057477355003357,
      "rewards/margins": 5.480918884277344,
      "rewards/rejected": -4.423441410064697,
      "step": 1410
    },
    {
      "epoch": 1.5191329943805192,
      "grad_norm": 0.29754751920700073,
      "learning_rate": 3.5584699453551906e-07,
      "logits/chosen": 1.6160824298858643,
      "logits/rejected": 0.8865992426872253,
      "logps/chosen": -153.82394409179688,
      "logps/rejected": -114.8030776977539,
      "loss": 0.006381382048130035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1296651363372803,
      "rewards/margins": 5.615314960479736,
      "rewards/rejected": -4.485650062561035,
      "step": 1420
    },
    {
      "epoch": 1.5298367674605298,
      "grad_norm": 0.29483237862586975,
      "learning_rate": 3.5475409836065574e-07,
      "logits/chosen": 1.4864342212677002,
      "logits/rejected": 0.9742469787597656,
      "logps/chosen": -135.53465270996094,
      "logps/rejected": -112.5530014038086,
      "loss": 0.007720509916543961,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0009530782699585,
      "rewards/margins": 5.3963727951049805,
      "rewards/rejected": -4.395419120788574,
      "step": 1430
    },
    {
      "epoch": 1.5405405405405406,
      "grad_norm": 0.13553862273693085,
      "learning_rate": 3.536612021857923e-07,
      "logits/chosen": 1.6430332660675049,
      "logits/rejected": 0.9338138699531555,
      "logps/chosen": -159.31103515625,
      "logps/rejected": -114.3194351196289,
      "loss": 0.006980492174625397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0315312147140503,
      "rewards/margins": 5.470551490783691,
      "rewards/rejected": -4.439020156860352,
      "step": 1440
    },
    {
      "epoch": 1.5512443136205514,
      "grad_norm": 0.1543293297290802,
      "learning_rate": 3.52568306010929e-07,
      "logits/chosen": 1.6492382287979126,
      "logits/rejected": 0.943995475769043,
      "logps/chosen": -161.6962127685547,
      "logps/rejected": -111.55224609375,
      "loss": 0.007546412944793701,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0708017349243164,
      "rewards/margins": 5.4432783126831055,
      "rewards/rejected": -4.372476577758789,
      "step": 1450
    },
    {
      "epoch": 1.561948086700562,
      "grad_norm": 0.30082517862319946,
      "learning_rate": 3.5147540983606556e-07,
      "logits/chosen": 1.5662428140640259,
      "logits/rejected": 0.8768116235733032,
      "logps/chosen": -156.20567321777344,
      "logps/rejected": -113.18183898925781,
      "loss": 0.006614429503679275,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1105087995529175,
      "rewards/margins": 5.518448829650879,
      "rewards/rejected": -4.40794038772583,
      "step": 1460
    },
    {
      "epoch": 1.5726518597805725,
      "grad_norm": 0.09834881871938705,
      "learning_rate": 3.503825136612022e-07,
      "logits/chosen": 1.520167589187622,
      "logits/rejected": 0.8321606516838074,
      "logps/chosen": -154.56912231445312,
      "logps/rejected": -113.91378021240234,
      "loss": 0.005730107426643372,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1200811862945557,
      "rewards/margins": 5.664028167724609,
      "rewards/rejected": -4.543947219848633,
      "step": 1470
    },
    {
      "epoch": 1.5833556328605833,
      "grad_norm": 0.1452556699514389,
      "learning_rate": 3.492896174863388e-07,
      "logits/chosen": 1.520647406578064,
      "logits/rejected": 0.8309138417243958,
      "logps/chosen": -158.67025756835938,
      "logps/rejected": -115.37918853759766,
      "loss": 0.004996734485030174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0982542037963867,
      "rewards/margins": 5.752010822296143,
      "rewards/rejected": -4.653756618499756,
      "step": 1480
    },
    {
      "epoch": 1.5940594059405941,
      "grad_norm": 0.13051317632198334,
      "learning_rate": 3.481967213114754e-07,
      "logits/chosen": 1.5546388626098633,
      "logits/rejected": 0.842633068561554,
      "logps/chosen": -148.94448852539062,
      "logps/rejected": -116.4286117553711,
      "loss": 0.005139270424842834,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1452716588974,
      "rewards/margins": 5.829920291900635,
      "rewards/rejected": -4.684648513793945,
      "step": 1490
    },
    {
      "epoch": 1.6047631790206047,
      "grad_norm": 0.37510889768600464,
      "learning_rate": 3.47103825136612e-07,
      "logits/chosen": 1.576114296913147,
      "logits/rejected": 0.8640255928039551,
      "logps/chosen": -143.94467163085938,
      "logps/rejected": -115.34197998046875,
      "loss": 0.005869773030281067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0664522647857666,
      "rewards/margins": 5.6125407218933105,
      "rewards/rejected": -4.546088695526123,
      "step": 1500
    }
  ],
  "logging_steps": 10,
  "max_steps": 4675,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
