{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.813486754080813,
  "eval_steps": 500,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010703773080010704,
      "grad_norm": 8.042835235595703,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.6620283126831055,
      "logits/rejected": 1.6317756175994873,
      "logps/chosen": -154.88954162597656,
      "logps/rejected": -68.91143798828125,
      "loss": 0.6929930686950684,
      "rewards/accuracies": 0.36250001192092896,
      "rewards/chosen": 0.0027783107943832874,
      "rewards/margins": 0.0006214429740794003,
      "rewards/rejected": 0.002156867878511548,
      "step": 10
    },
    {
      "epoch": 0.02140754616002141,
      "grad_norm": 7.908276557922363,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.6803842782974243,
      "logits/rejected": 1.6823651790618896,
      "logps/chosen": -172.01377868652344,
      "logps/rejected": -69.42620849609375,
      "loss": 0.6901248455047607,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.0032467462588101625,
      "rewards/margins": 0.006624302826821804,
      "rewards/rejected": -0.0033775572665035725,
      "step": 20
    },
    {
      "epoch": 0.03211131924003211,
      "grad_norm": 8.849369049072266,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.7294156551361084,
      "logits/rejected": 1.7146995067596436,
      "logps/chosen": -156.42025756835938,
      "logps/rejected": -68.60186004638672,
      "loss": 0.6883335113525391,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.0077818394638597965,
      "rewards/margins": 0.010242929682135582,
      "rewards/rejected": -0.0024610902182757854,
      "step": 30
    },
    {
      "epoch": 0.04281509232004282,
      "grad_norm": 7.736130714416504,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.6949303150177002,
      "logits/rejected": 1.6702102422714233,
      "logps/chosen": -163.21951293945312,
      "logps/rejected": -68.36978912353516,
      "loss": 0.6939249992370605,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004687915090471506,
      "rewards/margins": -0.000950565212406218,
      "rewards/rejected": 0.005638480186462402,
      "step": 40
    },
    {
      "epoch": 0.05351886540005352,
      "grad_norm": 7.328680992126465,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.6597477197647095,
      "logits/rejected": 1.6957956552505493,
      "logps/chosen": -164.46815490722656,
      "logps/rejected": -69.56840515136719,
      "loss": 0.6954107284545898,
      "rewards/accuracies": 0.38749998807907104,
      "rewards/chosen": -0.0025431732647120953,
      "rewards/margins": -0.003903585020452738,
      "rewards/rejected": 0.0013604119885712862,
      "step": 50
    },
    {
      "epoch": 0.06422263848006422,
      "grad_norm": 8.188251495361328,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.5828840732574463,
      "logits/rejected": 1.6658637523651123,
      "logps/chosen": -165.49407958984375,
      "logps/rejected": -69.3355484008789,
      "loss": 0.6892322063446045,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.007503075059503317,
      "rewards/margins": 0.008510095067322254,
      "rewards/rejected": -0.0010070180287584662,
      "step": 60
    },
    {
      "epoch": 0.07492641156007493,
      "grad_norm": 8.65149211883545,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.7149341106414795,
      "logits/rejected": 1.6704447269439697,
      "logps/chosen": -158.31288146972656,
      "logps/rejected": -69.85413360595703,
      "loss": 0.6899673461914062,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.004872560501098633,
      "rewards/margins": 0.00689715426415205,
      "rewards/rejected": -0.0020245935302227736,
      "step": 70
    },
    {
      "epoch": 0.08563018464008564,
      "grad_norm": 8.285731315612793,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.7061173915863037,
      "logits/rejected": 1.6593306064605713,
      "logps/chosen": -148.55221557617188,
      "logps/rejected": -68.52693939208984,
      "loss": 0.6900406360626221,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.0032034304458647966,
      "rewards/margins": 0.006800008472055197,
      "rewards/rejected": -0.0035965777933597565,
      "step": 80
    },
    {
      "epoch": 0.09633395772009633,
      "grad_norm": 8.954898834228516,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.6642587184906006,
      "logits/rejected": 1.6277955770492554,
      "logps/chosen": -158.2709197998047,
      "logps/rejected": -70.13672637939453,
      "loss": 0.6845562934875489,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.012011649087071419,
      "rewards/margins": 0.017708750441670418,
      "rewards/rejected": -0.005697102285921574,
      "step": 90
    },
    {
      "epoch": 0.10703773080010703,
      "grad_norm": 9.460087776184082,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.6440887451171875,
      "logits/rejected": 1.666945457458496,
      "logps/chosen": -157.4323272705078,
      "logps/rejected": -69.00125122070312,
      "loss": 0.6818899631500244,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.016707099974155426,
      "rewards/margins": 0.02356214076280594,
      "rewards/rejected": -0.006855040788650513,
      "step": 100
    },
    {
      "epoch": 0.11774150388011774,
      "grad_norm": 9.953648567199707,
      "learning_rate": 4.99016393442623e-07,
      "logits/chosen": 1.7171710729599,
      "logits/rejected": 1.6603634357452393,
      "logps/chosen": -174.9585418701172,
      "logps/rejected": -68.0926742553711,
      "loss": 0.6798484325408936,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.01922713965177536,
      "rewards/margins": 0.02738826908171177,
      "rewards/rejected": -0.008161130361258984,
      "step": 110
    },
    {
      "epoch": 0.12844527696012845,
      "grad_norm": 8.520073890686035,
      "learning_rate": 4.979234972677595e-07,
      "logits/chosen": 1.6902961730957031,
      "logits/rejected": 1.6549479961395264,
      "logps/chosen": -167.37828063964844,
      "logps/rejected": -69.44087982177734,
      "loss": 0.6729569435119629,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.031610604375600815,
      "rewards/margins": 0.04162018746137619,
      "rewards/rejected": -0.010009574703872204,
      "step": 120
    },
    {
      "epoch": 0.13914905004013914,
      "grad_norm": 9.898834228515625,
      "learning_rate": 4.968306010928961e-07,
      "logits/chosen": 1.6194766759872437,
      "logits/rejected": 1.6620088815689087,
      "logps/chosen": -152.73416137695312,
      "logps/rejected": -69.17903900146484,
      "loss": 0.6615282535552979,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.04378412291407585,
      "rewards/margins": 0.06479620933532715,
      "rewards/rejected": -0.021012086421251297,
      "step": 130
    },
    {
      "epoch": 0.14985282312014986,
      "grad_norm": 7.924726486206055,
      "learning_rate": 4.957377049180328e-07,
      "logits/chosen": 1.6532785892486572,
      "logits/rejected": 1.6689271926879883,
      "logps/chosen": -149.36196899414062,
      "logps/rejected": -68.09927368164062,
      "loss": 0.6616442680358887,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": 0.04494362697005272,
      "rewards/margins": 0.06471928209066391,
      "rewards/rejected": -0.01977565698325634,
      "step": 140
    },
    {
      "epoch": 0.16055659620016055,
      "grad_norm": 9.148638725280762,
      "learning_rate": 4.946448087431694e-07,
      "logits/chosen": 1.6315438747406006,
      "logits/rejected": 1.7217543125152588,
      "logps/chosen": -164.35971069335938,
      "logps/rejected": -69.40621185302734,
      "loss": 0.6517998218536377,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.055680327117443085,
      "rewards/margins": 0.08524040132761002,
      "rewards/rejected": -0.029560070484876633,
      "step": 150
    },
    {
      "epoch": 0.17126036928017127,
      "grad_norm": 10.011578559875488,
      "learning_rate": 4.935519125683059e-07,
      "logits/chosen": 1.730621337890625,
      "logits/rejected": 1.6951007843017578,
      "logps/chosen": -163.42745971679688,
      "logps/rejected": -69.35670471191406,
      "loss": 0.6403472900390625,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.07630730420351028,
      "rewards/margins": 0.10929622501134872,
      "rewards/rejected": -0.032988931983709335,
      "step": 160
    },
    {
      "epoch": 0.18196414236018196,
      "grad_norm": 8.293572425842285,
      "learning_rate": 4.924590163934426e-07,
      "logits/chosen": 1.7120643854141235,
      "logits/rejected": 1.6681219339370728,
      "logps/chosen": -160.22293090820312,
      "logps/rejected": -69.96358489990234,
      "loss": 0.6249523639678956,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09709646552801132,
      "rewards/margins": 0.14246416091918945,
      "rewards/rejected": -0.04536769166588783,
      "step": 170
    },
    {
      "epoch": 0.19266791544019266,
      "grad_norm": 8.27168083190918,
      "learning_rate": 4.913661202185792e-07,
      "logits/chosen": 1.6911976337432861,
      "logits/rejected": 1.638209342956543,
      "logps/chosen": -156.54566955566406,
      "logps/rejected": -69.0328140258789,
      "loss": 0.6169334411621094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10367057472467422,
      "rewards/margins": 0.15983103215694427,
      "rewards/rejected": -0.056160468608140945,
      "step": 180
    },
    {
      "epoch": 0.20337168852020338,
      "grad_norm": 8.73447322845459,
      "learning_rate": 4.902732240437159e-07,
      "logits/chosen": 1.7855793237686157,
      "logits/rejected": 1.6400638818740845,
      "logps/chosen": -158.33712768554688,
      "logps/rejected": -70.53496551513672,
      "loss": 0.6121816158294677,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.11388534307479858,
      "rewards/margins": 0.17062537372112274,
      "rewards/rejected": -0.05674004554748535,
      "step": 190
    },
    {
      "epoch": 0.21407546160021407,
      "grad_norm": 8.191123008728027,
      "learning_rate": 4.891803278688524e-07,
      "logits/chosen": 1.6980412006378174,
      "logits/rejected": 1.6481969356536865,
      "logps/chosen": -152.1992950439453,
      "logps/rejected": -68.19105529785156,
      "loss": 0.6061748027801513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1223047524690628,
      "rewards/margins": 0.18418067693710327,
      "rewards/rejected": -0.061875928193330765,
      "step": 200
    },
    {
      "epoch": 0.2247792346802248,
      "grad_norm": 10.072147369384766,
      "learning_rate": 4.88087431693989e-07,
      "logits/chosen": 1.6401643753051758,
      "logits/rejected": 1.7380163669586182,
      "logps/chosen": -157.94541931152344,
      "logps/rejected": -70.68669128417969,
      "loss": 0.5895828247070313,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.14281681180000305,
      "rewards/margins": 0.22147062420845032,
      "rewards/rejected": -0.07865382730960846,
      "step": 210
    },
    {
      "epoch": 0.23548300776023548,
      "grad_norm": 7.548822402954102,
      "learning_rate": 4.869945355191257e-07,
      "logits/chosen": 1.6622155904769897,
      "logits/rejected": 1.7017467021942139,
      "logps/chosen": -148.46351623535156,
      "logps/rejected": -69.21295928955078,
      "loss": 0.5830491065979004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14975541830062866,
      "rewards/margins": 0.235938161611557,
      "rewards/rejected": -0.08618275821208954,
      "step": 220
    },
    {
      "epoch": 0.2461867808402462,
      "grad_norm": 8.452560424804688,
      "learning_rate": 4.859016393442622e-07,
      "logits/chosen": 1.6331592798233032,
      "logits/rejected": 1.7276771068572998,
      "logps/chosen": -154.79164123535156,
      "logps/rejected": -70.20716857910156,
      "loss": 0.5672767639160157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17895743250846863,
      "rewards/margins": 0.27279460430145264,
      "rewards/rejected": -0.09383717179298401,
      "step": 230
    },
    {
      "epoch": 0.2568905539202569,
      "grad_norm": 7.775155544281006,
      "learning_rate": 4.848087431693989e-07,
      "logits/chosen": 1.697218894958496,
      "logits/rejected": 1.7532260417938232,
      "logps/chosen": -151.79420471191406,
      "logps/rejected": -70.38407897949219,
      "loss": 0.5580480098724365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18484637141227722,
      "rewards/margins": 0.2951138913631439,
      "rewards/rejected": -0.1102675050497055,
      "step": 240
    },
    {
      "epoch": 0.2675943270002676,
      "grad_norm": 7.7155351638793945,
      "learning_rate": 4.837158469945355e-07,
      "logits/chosen": 1.7367427349090576,
      "logits/rejected": 1.687816858291626,
      "logps/chosen": -156.65438842773438,
      "logps/rejected": -70.59455108642578,
      "loss": 0.538788890838623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21229608356952667,
      "rewards/margins": 0.34001052379608154,
      "rewards/rejected": -0.12771447002887726,
      "step": 250
    },
    {
      "epoch": 0.2782981000802783,
      "grad_norm": 7.714850902557373,
      "learning_rate": 4.826229508196722e-07,
      "logits/chosen": 1.7488590478897095,
      "logits/rejected": 1.7122571468353271,
      "logps/chosen": -159.88613891601562,
      "logps/rejected": -69.44705200195312,
      "loss": 0.531544303894043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2298315465450287,
      "rewards/margins": 0.35841742157936096,
      "rewards/rejected": -0.1285858452320099,
      "step": 260
    },
    {
      "epoch": 0.289001873160289,
      "grad_norm": 7.462470531463623,
      "learning_rate": 4.815300546448087e-07,
      "logits/chosen": 1.6619943380355835,
      "logits/rejected": 1.7232564687728882,
      "logps/chosen": -158.8004608154297,
      "logps/rejected": -70.70526885986328,
      "loss": 0.518095588684082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24078914523124695,
      "rewards/margins": 0.3924974799156189,
      "rewards/rejected": -0.15170833468437195,
      "step": 270
    },
    {
      "epoch": 0.2997056462402997,
      "grad_norm": 7.329143524169922,
      "learning_rate": 4.804371584699453e-07,
      "logits/chosen": 1.733319878578186,
      "logits/rejected": 1.7422233819961548,
      "logps/chosen": -156.47251892089844,
      "logps/rejected": -70.48951721191406,
      "loss": 0.5063504219055176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25117042660713196,
      "rewards/margins": 0.4227348268032074,
      "rewards/rejected": -0.17156442999839783,
      "step": 280
    },
    {
      "epoch": 0.3104094193203104,
      "grad_norm": 8.61311149597168,
      "learning_rate": 4.79344262295082e-07,
      "logits/chosen": 1.8045895099639893,
      "logits/rejected": 1.799299955368042,
      "logps/chosen": -163.0063934326172,
      "logps/rejected": -72.11375427246094,
      "loss": 0.4894240379333496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27973300218582153,
      "rewards/margins": 0.46572867035865784,
      "rewards/rejected": -0.1859956681728363,
      "step": 290
    },
    {
      "epoch": 0.3211131924003211,
      "grad_norm": 7.378121376037598,
      "learning_rate": 4.782513661202186e-07,
      "logits/chosen": 1.7040908336639404,
      "logits/rejected": 1.7486766576766968,
      "logps/chosen": -156.3368377685547,
      "logps/rejected": -69.96931457519531,
      "loss": 0.47478561401367186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31315600872039795,
      "rewards/margins": 0.5039626359939575,
      "rewards/rejected": -0.190806582570076,
      "step": 300
    },
    {
      "epoch": 0.3318169654803318,
      "grad_norm": 7.064162731170654,
      "learning_rate": 4.771584699453552e-07,
      "logits/chosen": 1.7980601787567139,
      "logits/rejected": 1.7381725311279297,
      "logps/chosen": -153.16200256347656,
      "logps/rejected": -71.08973693847656,
      "loss": 0.46725010871887207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31458261609077454,
      "rewards/margins": 0.525361180305481,
      "rewards/rejected": -0.21077856421470642,
      "step": 310
    },
    {
      "epoch": 0.34252073856034254,
      "grad_norm": 6.610952854156494,
      "learning_rate": 4.760655737704918e-07,
      "logits/chosen": 1.7534401416778564,
      "logits/rejected": 1.7501399517059326,
      "logps/chosen": -168.30015563964844,
      "logps/rejected": -71.00263977050781,
      "loss": 0.4474502086639404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3498777747154236,
      "rewards/margins": 0.5853263139724731,
      "rewards/rejected": -0.23544852435588837,
      "step": 320
    },
    {
      "epoch": 0.35322451164035323,
      "grad_norm": 6.845317840576172,
      "learning_rate": 4.749726775956284e-07,
      "logits/chosen": 1.8165700435638428,
      "logits/rejected": 1.750357985496521,
      "logps/chosen": -177.55010986328125,
      "logps/rejected": -71.16143798828125,
      "loss": 0.4265284061431885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3805598318576813,
      "rewards/margins": 0.6398438215255737,
      "rewards/rejected": -0.25928401947021484,
      "step": 330
    },
    {
      "epoch": 0.3639282847203639,
      "grad_norm": 6.692675590515137,
      "learning_rate": 4.73879781420765e-07,
      "logits/chosen": 1.7772655487060547,
      "logits/rejected": 1.8082275390625,
      "logps/chosen": -159.55142211914062,
      "logps/rejected": -71.16816711425781,
      "loss": 0.40757203102111816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4074929654598236,
      "rewards/margins": 0.6997970938682556,
      "rewards/rejected": -0.2923041582107544,
      "step": 340
    },
    {
      "epoch": 0.3746320578003746,
      "grad_norm": 5.849478721618652,
      "learning_rate": 4.727868852459016e-07,
      "logits/chosen": 1.7856992483139038,
      "logits/rejected": 1.774206519126892,
      "logps/chosen": -157.7308349609375,
      "logps/rejected": -70.65202331542969,
      "loss": 0.4171758651733398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3858453929424286,
      "rewards/margins": 0.6697971224784851,
      "rewards/rejected": -0.28395166993141174,
      "step": 350
    },
    {
      "epoch": 0.3853358308803853,
      "grad_norm": 6.871621608734131,
      "learning_rate": 4.7169398907103825e-07,
      "logits/chosen": 1.7737483978271484,
      "logits/rejected": 1.7897913455963135,
      "logps/chosen": -163.47891235351562,
      "logps/rejected": -71.0719985961914,
      "loss": 0.3919903039932251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4211021959781647,
      "rewards/margins": 0.745856523513794,
      "rewards/rejected": -0.3247542977333069,
      "step": 360
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 6.033052921295166,
      "learning_rate": 4.706010928961748e-07,
      "logits/chosen": 1.7575725317001343,
      "logits/rejected": 1.7525899410247803,
      "logps/chosen": -158.105712890625,
      "logps/rejected": -71.40069580078125,
      "loss": 0.38487725257873534,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4209696650505066,
      "rewards/margins": 0.7734045386314392,
      "rewards/rejected": -0.35243481397628784,
      "step": 370
    },
    {
      "epoch": 0.40674337704040675,
      "grad_norm": 5.977532863616943,
      "learning_rate": 4.695081967213115e-07,
      "logits/chosen": 1.738138198852539,
      "logits/rejected": 1.7429298162460327,
      "logps/chosen": -165.0994415283203,
      "logps/rejected": -72.59822082519531,
      "loss": 0.3554192543029785,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4993690848350525,
      "rewards/margins": 0.8690775036811829,
      "rewards/rejected": -0.3697083592414856,
      "step": 380
    },
    {
      "epoch": 0.41744715012041744,
      "grad_norm": 5.488399028778076,
      "learning_rate": 4.6841530054644806e-07,
      "logits/chosen": 1.6882820129394531,
      "logits/rejected": 1.784976601600647,
      "logps/chosen": -151.66372680664062,
      "logps/rejected": -73.06888580322266,
      "loss": 0.33793528079986573,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5386590361595154,
      "rewards/margins": 0.9236882328987122,
      "rewards/rejected": -0.3850291967391968,
      "step": 390
    },
    {
      "epoch": 0.42815092320042814,
      "grad_norm": 5.640366077423096,
      "learning_rate": 4.6732240437158464e-07,
      "logits/chosen": 1.770328164100647,
      "logits/rejected": 1.7905588150024414,
      "logps/chosen": -156.48995971679688,
      "logps/rejected": -72.52394104003906,
      "loss": 0.34104599952697756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5009521245956421,
      "rewards/margins": 0.9176923632621765,
      "rewards/rejected": -0.4167402386665344,
      "step": 400
    },
    {
      "epoch": 0.4388546962804388,
      "grad_norm": 5.513765811920166,
      "learning_rate": 4.662295081967213e-07,
      "logits/chosen": 1.7738593816757202,
      "logits/rejected": 1.7476686239242554,
      "logps/chosen": -160.97093200683594,
      "logps/rejected": -73.36878204345703,
      "loss": 0.3168286561965942,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5848418474197388,
      "rewards/margins": 1.0141011476516724,
      "rewards/rejected": -0.42925921082496643,
      "step": 410
    },
    {
      "epoch": 0.4495584693604496,
      "grad_norm": 5.140445709228516,
      "learning_rate": 4.651366120218579e-07,
      "logits/chosen": 1.8044955730438232,
      "logits/rejected": 1.8697763681411743,
      "logps/chosen": -160.54498291015625,
      "logps/rejected": -72.71686553955078,
      "loss": 0.3175292730331421,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5357639193534851,
      "rewards/margins": 0.998553454875946,
      "rewards/rejected": -0.46278953552246094,
      "step": 420
    },
    {
      "epoch": 0.46026224244046027,
      "grad_norm": 5.378852844238281,
      "learning_rate": 4.640437158469945e-07,
      "logits/chosen": 1.7668836116790771,
      "logits/rejected": 1.8253040313720703,
      "logps/chosen": -159.06869506835938,
      "logps/rejected": -73.11555480957031,
      "loss": 0.3142409324645996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5424200296401978,
      "rewards/margins": 1.0229847431182861,
      "rewards/rejected": -0.48056483268737793,
      "step": 430
    },
    {
      "epoch": 0.47096601552047096,
      "grad_norm": 4.926112651824951,
      "learning_rate": 4.6295081967213113e-07,
      "logits/chosen": 1.8253841400146484,
      "logits/rejected": 1.8405574560165405,
      "logps/chosen": -154.3362579345703,
      "logps/rejected": -73.98931884765625,
      "loss": 0.2918151617050171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5944596529006958,
      "rewards/margins": 1.11243736743927,
      "rewards/rejected": -0.5179777145385742,
      "step": 440
    },
    {
      "epoch": 0.48166978860048165,
      "grad_norm": 5.213535785675049,
      "learning_rate": 4.6185792349726776e-07,
      "logits/chosen": 1.7885091304779053,
      "logits/rejected": 1.8195703029632568,
      "logps/chosen": -159.6781768798828,
      "logps/rejected": -74.87156677246094,
      "loss": 0.2732362985610962,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6446535587310791,
      "rewards/margins": 1.1925660371780396,
      "rewards/rejected": -0.5479124188423157,
      "step": 450
    },
    {
      "epoch": 0.4923735616804924,
      "grad_norm": 4.465903282165527,
      "learning_rate": 4.607650273224044e-07,
      "logits/chosen": 1.8170499801635742,
      "logits/rejected": 1.7966291904449463,
      "logps/chosen": -154.4861297607422,
      "logps/rejected": -74.51118469238281,
      "loss": 0.26926634311676023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6413015723228455,
      "rewards/margins": 1.2055747509002686,
      "rewards/rejected": -0.5642733573913574,
      "step": 460
    },
    {
      "epoch": 0.5030773347605031,
      "grad_norm": 4.684820652008057,
      "learning_rate": 4.5967213114754095e-07,
      "logits/chosen": 1.8400636911392212,
      "logits/rejected": 1.8353493213653564,
      "logps/chosen": -162.42608642578125,
      "logps/rejected": -74.98222351074219,
      "loss": 0.2574610233306885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.652793288230896,
      "rewards/margins": 1.25051748752594,
      "rewards/rejected": -0.597724199295044,
      "step": 470
    },
    {
      "epoch": 0.5137811078405138,
      "grad_norm": 4.326503276824951,
      "learning_rate": 4.585792349726776e-07,
      "logits/chosen": 1.7971071004867554,
      "logits/rejected": 1.790305733680725,
      "logps/chosen": -159.56289672851562,
      "logps/rejected": -75.2584457397461,
      "loss": 0.23904845714569092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7037224769592285,
      "rewards/margins": 1.3411359786987305,
      "rewards/rejected": -0.6374134421348572,
      "step": 480
    },
    {
      "epoch": 0.5244848809205245,
      "grad_norm": 4.167069911956787,
      "learning_rate": 4.574863387978142e-07,
      "logits/chosen": 1.7841503620147705,
      "logits/rejected": 1.8653568029403687,
      "logps/chosen": -165.16070556640625,
      "logps/rejected": -76.31249237060547,
      "loss": 0.23473503589630126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7132250070571899,
      "rewards/margins": 1.3674430847167969,
      "rewards/rejected": -0.6542181968688965,
      "step": 490
    },
    {
      "epoch": 0.5351886540005352,
      "grad_norm": 4.156453609466553,
      "learning_rate": 4.563934426229508e-07,
      "logits/chosen": 1.8409897089004517,
      "logits/rejected": 1.8359819650650024,
      "logps/chosen": -142.95703125,
      "logps/rejected": -75.07670593261719,
      "loss": 0.23639342784881592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7014516592025757,
      "rewards/margins": 1.3671777248382568,
      "rewards/rejected": -0.6657260060310364,
      "step": 500
    },
    {
      "epoch": 0.5458924270805459,
      "grad_norm": 3.7900516986846924,
      "learning_rate": 4.553005464480874e-07,
      "logits/chosen": 1.812766671180725,
      "logits/rejected": 1.8012014627456665,
      "logps/chosen": -150.61380004882812,
      "logps/rejected": -75.01448822021484,
      "loss": 0.22986876964569092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7077286243438721,
      "rewards/margins": 1.4026319980621338,
      "rewards/rejected": -0.6949034333229065,
      "step": 510
    },
    {
      "epoch": 0.5565962001605566,
      "grad_norm": 3.4346323013305664,
      "learning_rate": 4.54207650273224e-07,
      "logits/chosen": 1.8092663288116455,
      "logits/rejected": 1.7893707752227783,
      "logps/chosen": -151.3472900390625,
      "logps/rejected": -75.72801208496094,
      "loss": 0.2132643222808838,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7562977075576782,
      "rewards/margins": 1.4790534973144531,
      "rewards/rejected": -0.7227557301521301,
      "step": 520
    },
    {
      "epoch": 0.5672999732405672,
      "grad_norm": 3.513603925704956,
      "learning_rate": 4.5311475409836064e-07,
      "logits/chosen": 1.7969367504119873,
      "logits/rejected": 1.824254035949707,
      "logps/chosen": -155.95095825195312,
      "logps/rejected": -75.7593765258789,
      "loss": 0.21915624141693116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.731634795665741,
      "rewards/margins": 1.4689702987670898,
      "rewards/rejected": -0.7373355627059937,
      "step": 530
    },
    {
      "epoch": 0.578003746320578,
      "grad_norm": 4.138045787811279,
      "learning_rate": 4.520218579234972e-07,
      "logits/chosen": 1.7642877101898193,
      "logits/rejected": 1.820688009262085,
      "logps/chosen": -145.81431579589844,
      "logps/rejected": -76.89228820800781,
      "loss": 0.20521259307861328,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7130760550498962,
      "rewards/margins": 1.5259830951690674,
      "rewards/rejected": -0.8129068613052368,
      "step": 540
    },
    {
      "epoch": 0.5887075194005887,
      "grad_norm": 2.9567062854766846,
      "learning_rate": 4.509289617486339e-07,
      "logits/chosen": 1.7720463275909424,
      "logits/rejected": 1.7897975444793701,
      "logps/chosen": -152.9249267578125,
      "logps/rejected": -76.35782623291016,
      "loss": 0.1861492395401001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7950961589813232,
      "rewards/margins": 1.630152940750122,
      "rewards/rejected": -0.8350567817687988,
      "step": 550
    },
    {
      "epoch": 0.5994112924805994,
      "grad_norm": 2.969787359237671,
      "learning_rate": 4.4983606557377046e-07,
      "logits/chosen": 1.791115403175354,
      "logits/rejected": 1.8092257976531982,
      "logps/chosen": -143.38133239746094,
      "logps/rejected": -77.51371765136719,
      "loss": 0.1971064567565918,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7465590238571167,
      "rewards/margins": 1.5867109298706055,
      "rewards/rejected": -0.8401519656181335,
      "step": 560
    },
    {
      "epoch": 0.6101150655606101,
      "grad_norm": 3.3995563983917236,
      "learning_rate": 4.487431693989071e-07,
      "logits/chosen": 1.8000361919403076,
      "logits/rejected": 1.8211749792099,
      "logps/chosen": -155.05215454101562,
      "logps/rejected": -79.23160552978516,
      "loss": 0.17334927320480348,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.785712480545044,
      "rewards/margins": 1.723633050918579,
      "rewards/rejected": -0.9379204511642456,
      "step": 570
    },
    {
      "epoch": 0.6208188386406208,
      "grad_norm": 3.103102922439575,
      "learning_rate": 4.476502732240437e-07,
      "logits/chosen": 1.739972710609436,
      "logits/rejected": 1.812269926071167,
      "logps/chosen": -146.7483673095703,
      "logps/rejected": -78.83075714111328,
      "loss": 0.1659580111503601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8500654101371765,
      "rewards/margins": 1.7748111486434937,
      "rewards/rejected": -0.9247457385063171,
      "step": 580
    },
    {
      "epoch": 0.6315226117206315,
      "grad_norm": 3.165898084640503,
      "learning_rate": 4.465573770491803e-07,
      "logits/chosen": 1.8384262323379517,
      "logits/rejected": 1.8030710220336914,
      "logps/chosen": -160.6950225830078,
      "logps/rejected": -78.15794372558594,
      "loss": 0.15289690494537353,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8729274868965149,
      "rewards/margins": 1.8413591384887695,
      "rewards/rejected": -0.9684314727783203,
      "step": 590
    },
    {
      "epoch": 0.6422263848006422,
      "grad_norm": 3.076017141342163,
      "learning_rate": 4.454644808743169e-07,
      "logits/chosen": 1.819422721862793,
      "logits/rejected": 1.8624855279922485,
      "logps/chosen": -150.9158477783203,
      "logps/rejected": -78.68762969970703,
      "loss": 0.15469962358474731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8495267629623413,
      "rewards/margins": 1.8539130687713623,
      "rewards/rejected": -1.0043861865997314,
      "step": 600
    },
    {
      "epoch": 0.6529301578806529,
      "grad_norm": 3.3542444705963135,
      "learning_rate": 4.4437158469945353e-07,
      "logits/chosen": 1.7931493520736694,
      "logits/rejected": 1.7662004232406616,
      "logps/chosen": -156.47067260742188,
      "logps/rejected": -78.69563293457031,
      "loss": 0.15708862543106078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8011693954467773,
      "rewards/margins": 1.8293449878692627,
      "rewards/rejected": -1.0281753540039062,
      "step": 610
    },
    {
      "epoch": 0.6636339309606636,
      "grad_norm": 3.179837226867676,
      "learning_rate": 4.4327868852459015e-07,
      "logits/chosen": 1.786595106124878,
      "logits/rejected": 1.820146918296814,
      "logps/chosen": -152.81436157226562,
      "logps/rejected": -79.03211975097656,
      "loss": 0.14858046770095826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8299798965454102,
      "rewards/margins": 1.9021879434585571,
      "rewards/rejected": -1.0722078084945679,
      "step": 620
    },
    {
      "epoch": 0.6743377040406744,
      "grad_norm": 2.931001901626587,
      "learning_rate": 4.421857923497268e-07,
      "logits/chosen": 1.7775561809539795,
      "logits/rejected": 1.7981802225112915,
      "logps/chosen": -155.6448211669922,
      "logps/rejected": -80.45366668701172,
      "loss": 0.15442954301834105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7538518905639648,
      "rewards/margins": 1.8623638153076172,
      "rewards/rejected": -1.1085119247436523,
      "step": 630
    },
    {
      "epoch": 0.6850414771206851,
      "grad_norm": 3.2971746921539307,
      "learning_rate": 4.410928961748634e-07,
      "logits/chosen": 1.7837142944335938,
      "logits/rejected": 1.7658417224884033,
      "logps/chosen": -151.1968231201172,
      "logps/rejected": -78.75161743164062,
      "loss": 0.14259451627731323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8242725133895874,
      "rewards/margins": 1.9472805261611938,
      "rewards/rejected": -1.1230080127716064,
      "step": 640
    },
    {
      "epoch": 0.6957452502006958,
      "grad_norm": 2.9427597522735596,
      "learning_rate": 4.3999999999999997e-07,
      "logits/chosen": 1.843504548072815,
      "logits/rejected": 1.7960821390151978,
      "logps/chosen": -150.39749145507812,
      "logps/rejected": -80.89216613769531,
      "loss": 0.12209330797195435,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9342406392097473,
      "rewards/margins": 2.117431402206421,
      "rewards/rejected": -1.183190941810608,
      "step": 650
    },
    {
      "epoch": 0.7064490232807065,
      "grad_norm": 2.174078941345215,
      "learning_rate": 4.389071038251366e-07,
      "logits/chosen": 1.763603925704956,
      "logits/rejected": 1.781469702720642,
      "logps/chosen": -143.51356506347656,
      "logps/rejected": -80.98930358886719,
      "loss": 0.12900182008743286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8648360371589661,
      "rewards/margins": 2.0690298080444336,
      "rewards/rejected": -1.2041938304901123,
      "step": 660
    },
    {
      "epoch": 0.7171527963607172,
      "grad_norm": 2.731015920639038,
      "learning_rate": 4.378142076502732e-07,
      "logits/chosen": 1.850423812866211,
      "logits/rejected": 1.8077869415283203,
      "logps/chosen": -159.25588989257812,
      "logps/rejected": -81.06141662597656,
      "loss": 0.1196125864982605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9192136526107788,
      "rewards/margins": 2.1484951972961426,
      "rewards/rejected": -1.2292816638946533,
      "step": 670
    },
    {
      "epoch": 0.7278565694407279,
      "grad_norm": 2.2992358207702637,
      "learning_rate": 4.367213114754098e-07,
      "logits/chosen": 1.8160632848739624,
      "logits/rejected": 1.8401365280151367,
      "logps/chosen": -140.0146026611328,
      "logps/rejected": -82.35936737060547,
      "loss": 0.11418379545211792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8760480880737305,
      "rewards/margins": 2.1694564819335938,
      "rewards/rejected": -1.2934086322784424,
      "step": 680
    },
    {
      "epoch": 0.7385603425207385,
      "grad_norm": 2.5261237621307373,
      "learning_rate": 4.3562841530054647e-07,
      "logits/chosen": 1.7846043109893799,
      "logits/rejected": 1.7177053689956665,
      "logps/chosen": -162.27255249023438,
      "logps/rejected": -82.38078308105469,
      "loss": 0.10433937311172485,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9660691022872925,
      "rewards/margins": 2.294405460357666,
      "rewards/rejected": -1.3283361196517944,
      "step": 690
    },
    {
      "epoch": 0.7492641156007492,
      "grad_norm": 2.0589141845703125,
      "learning_rate": 4.3453551912568304e-07,
      "logits/chosen": 1.776180624961853,
      "logits/rejected": 1.7863147258758545,
      "logps/chosen": -149.65113830566406,
      "logps/rejected": -82.73945617675781,
      "loss": 0.10204199552536011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9478128552436829,
      "rewards/margins": 2.3019299507141113,
      "rewards/rejected": -1.3541171550750732,
      "step": 700
    },
    {
      "epoch": 0.7599678886807599,
      "grad_norm": 1.904205083847046,
      "learning_rate": 4.334426229508196e-07,
      "logits/chosen": 1.8321046829223633,
      "logits/rejected": 1.7787792682647705,
      "logps/chosen": -169.90652465820312,
      "logps/rejected": -82.6867904663086,
      "loss": 0.09450395107269287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.998293399810791,
      "rewards/margins": 2.405311107635498,
      "rewards/rejected": -1.407017707824707,
      "step": 710
    },
    {
      "epoch": 0.7706716617607706,
      "grad_norm": 2.5522873401641846,
      "learning_rate": 4.323497267759563e-07,
      "logits/chosen": 1.7917639017105103,
      "logits/rejected": 1.7664276361465454,
      "logps/chosen": -149.2853240966797,
      "logps/rejected": -83.3419189453125,
      "loss": 0.09824571013450623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9395872354507446,
      "rewards/margins": 2.3770480155944824,
      "rewards/rejected": -1.4374607801437378,
      "step": 720
    },
    {
      "epoch": 0.7813754348407814,
      "grad_norm": 1.9055136442184448,
      "learning_rate": 4.3125683060109286e-07,
      "logits/chosen": 1.7494118213653564,
      "logits/rejected": 1.7055559158325195,
      "logps/chosen": -148.74447631835938,
      "logps/rejected": -85.08723449707031,
      "loss": 0.08772898316383362,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9730061292648315,
      "rewards/margins": 2.487753391265869,
      "rewards/rejected": -1.5147473812103271,
      "step": 730
    },
    {
      "epoch": 0.7920792079207921,
      "grad_norm": 1.6576265096664429,
      "learning_rate": 4.301639344262295e-07,
      "logits/chosen": 1.8033357858657837,
      "logits/rejected": 1.6875845193862915,
      "logps/chosen": -163.80084228515625,
      "logps/rejected": -84.67510986328125,
      "loss": 0.08052144050598145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0615533590316772,
      "rewards/margins": 2.60038423538208,
      "rewards/rejected": -1.5388309955596924,
      "step": 740
    },
    {
      "epoch": 0.8027829810008028,
      "grad_norm": 1.7653721570968628,
      "learning_rate": 4.290710382513661e-07,
      "logits/chosen": 1.8351141214370728,
      "logits/rejected": 1.65499746799469,
      "logps/chosen": -157.83262634277344,
      "logps/rejected": -84.69694519042969,
      "loss": 0.07486096620559693,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0277754068374634,
      "rewards/margins": 2.637855291366577,
      "rewards/rejected": -1.6100800037384033,
      "step": 750
    },
    {
      "epoch": 0.8134867540808135,
      "grad_norm": 1.6472928524017334,
      "learning_rate": 4.2797814207650273e-07,
      "logits/chosen": 1.6718753576278687,
      "logits/rejected": 1.6622778177261353,
      "logps/chosen": -146.2825469970703,
      "logps/rejected": -84.47618103027344,
      "loss": 0.07485225200653076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0219066143035889,
      "rewards/margins": 2.6572508811950684,
      "rewards/rejected": -1.6353442668914795,
      "step": 760
    },
    {
      "epoch": 0.8241905271608242,
      "grad_norm": 1.7153552770614624,
      "learning_rate": 4.268852459016393e-07,
      "logits/chosen": 1.7719131708145142,
      "logits/rejected": 1.681692361831665,
      "logps/chosen": -163.47219848632812,
      "logps/rejected": -86.72774505615234,
      "loss": 0.07162449955940246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0017569065093994,
      "rewards/margins": 2.702376365661621,
      "rewards/rejected": -1.7006194591522217,
      "step": 770
    },
    {
      "epoch": 0.8348943002408349,
      "grad_norm": 1.7915538549423218,
      "learning_rate": 4.257923497267759e-07,
      "logits/chosen": 1.7588112354278564,
      "logits/rejected": 1.761612892150879,
      "logps/chosen": -158.7922821044922,
      "logps/rejected": -85.04820251464844,
      "loss": 0.08087860941886901,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9474912881851196,
      "rewards/margins": 2.605459690093994,
      "rewards/rejected": -1.657968282699585,
      "step": 780
    },
    {
      "epoch": 0.8455980733208456,
      "grad_norm": 1.5435279607772827,
      "learning_rate": 4.2469945355191255e-07,
      "logits/chosen": 1.6815217733383179,
      "logits/rejected": 1.659170150756836,
      "logps/chosen": -141.67153930664062,
      "logps/rejected": -86.1138687133789,
      "loss": 0.07111806273460389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.959647536277771,
      "rewards/margins": 2.725346326828003,
      "rewards/rejected": -1.765699028968811,
      "step": 790
    },
    {
      "epoch": 0.8563018464008563,
      "grad_norm": 1.192418098449707,
      "learning_rate": 4.2360655737704917e-07,
      "logits/chosen": 1.7205194234848022,
      "logits/rejected": 1.5790023803710938,
      "logps/chosen": -140.65902709960938,
      "logps/rejected": -87.70341491699219,
      "loss": 0.06502756476402283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0407321453094482,
      "rewards/margins": 2.853187084197998,
      "rewards/rejected": -1.8124549388885498,
      "step": 800
    },
    {
      "epoch": 0.867005619480867,
      "grad_norm": 1.2954949140548706,
      "learning_rate": 4.225136612021858e-07,
      "logits/chosen": 1.7844030857086182,
      "logits/rejected": 1.6893689632415771,
      "logps/chosen": -155.53677368164062,
      "logps/rejected": -86.67449188232422,
      "loss": 0.06417385935783386,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0463283061981201,
      "rewards/margins": 2.8428380489349365,
      "rewards/rejected": -1.796510100364685,
      "step": 810
    },
    {
      "epoch": 0.8777093925608777,
      "grad_norm": 1.8784531354904175,
      "learning_rate": 4.2142076502732236e-07,
      "logits/chosen": 1.8235204219818115,
      "logits/rejected": 1.739553451538086,
      "logps/chosen": -149.76885986328125,
      "logps/rejected": -87.57658386230469,
      "loss": 0.06573216319084167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9877670407295227,
      "rewards/margins": 2.8412609100341797,
      "rewards/rejected": -1.8534940481185913,
      "step": 820
    },
    {
      "epoch": 0.8884131656408885,
      "grad_norm": 1.3906311988830566,
      "learning_rate": 4.2032786885245904e-07,
      "logits/chosen": 1.7170041799545288,
      "logits/rejected": 1.6727221012115479,
      "logps/chosen": -142.951904296875,
      "logps/rejected": -89.37434387207031,
      "loss": 0.05886092782020569,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.964301586151123,
      "rewards/margins": 2.9349441528320312,
      "rewards/rejected": -1.9706424474716187,
      "step": 830
    },
    {
      "epoch": 0.8991169387208992,
      "grad_norm": 0.9178356528282166,
      "learning_rate": 4.192349726775956e-07,
      "logits/chosen": 1.7838985919952393,
      "logits/rejected": 1.6357009410858154,
      "logps/chosen": -160.9322967529297,
      "logps/rejected": -87.64883422851562,
      "loss": 0.055837112665176394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0890274047851562,
      "rewards/margins": 3.0316686630249023,
      "rewards/rejected": -1.9426414966583252,
      "step": 840
    },
    {
      "epoch": 0.9098207118009098,
      "grad_norm": 1.0754969120025635,
      "learning_rate": 4.181420765027322e-07,
      "logits/chosen": 1.788027048110962,
      "logits/rejected": 1.5935801267623901,
      "logps/chosen": -162.02935791015625,
      "logps/rejected": -89.02740478515625,
      "loss": 0.04708324670791626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1095348596572876,
      "rewards/margins": 3.150054454803467,
      "rewards/rejected": -2.040519952774048,
      "step": 850
    },
    {
      "epoch": 0.9205244848809205,
      "grad_norm": 1.1452856063842773,
      "learning_rate": 4.1704918032786886e-07,
      "logits/chosen": 1.7593824863433838,
      "logits/rejected": 1.6450179815292358,
      "logps/chosen": -150.4923553466797,
      "logps/rejected": -89.09027862548828,
      "loss": 0.04953871369361877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0339109897613525,
      "rewards/margins": 3.0847699642181396,
      "rewards/rejected": -2.050858736038208,
      "step": 860
    },
    {
      "epoch": 0.9312282579609312,
      "grad_norm": 0.9945034384727478,
      "learning_rate": 4.1595628415300543e-07,
      "logits/chosen": 1.7284057140350342,
      "logits/rejected": 1.629233717918396,
      "logps/chosen": -161.48593139648438,
      "logps/rejected": -91.5926513671875,
      "loss": 0.04700658917427063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0734291076660156,
      "rewards/margins": 3.232520580291748,
      "rewards/rejected": -2.1590917110443115,
      "step": 870
    },
    {
      "epoch": 0.9419320310409419,
      "grad_norm": 1.6321930885314941,
      "learning_rate": 4.1486338797814206e-07,
      "logits/chosen": 1.7180430889129639,
      "logits/rejected": 1.6240301132202148,
      "logps/chosen": -146.04124450683594,
      "logps/rejected": -90.5680923461914,
      "loss": 0.04806958734989166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9799259305000305,
      "rewards/margins": 3.1595466136932373,
      "rewards/rejected": -2.1796205043792725,
      "step": 880
    },
    {
      "epoch": 0.9526358041209526,
      "grad_norm": 0.8668941259384155,
      "learning_rate": 4.137704918032787e-07,
      "logits/chosen": 1.7094818353652954,
      "logits/rejected": 1.5231965780258179,
      "logps/chosen": -156.80088806152344,
      "logps/rejected": -92.11121368408203,
      "loss": 0.046077588200569154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9766501188278198,
      "rewards/margins": 3.239579439163208,
      "rewards/rejected": -2.2629292011260986,
      "step": 890
    },
    {
      "epoch": 0.9633395772009633,
      "grad_norm": 1.4290539026260376,
      "learning_rate": 4.126775956284153e-07,
      "logits/chosen": 1.7265279293060303,
      "logits/rejected": 1.584498405456543,
      "logps/chosen": -142.72727966308594,
      "logps/rejected": -92.38348388671875,
      "loss": 0.03659718930721283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1476142406463623,
      "rewards/margins": 3.4494094848632812,
      "rewards/rejected": -2.301795244216919,
      "step": 900
    },
    {
      "epoch": 0.974043350280974,
      "grad_norm": 0.8241678476333618,
      "learning_rate": 4.115846994535519e-07,
      "logits/chosen": 1.7337844371795654,
      "logits/rejected": 1.58919358253479,
      "logps/chosen": -152.03326416015625,
      "logps/rejected": -92.68684387207031,
      "loss": 0.04033022522926331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0825837850570679,
      "rewards/margins": 3.392866611480713,
      "rewards/rejected": -2.3102829456329346,
      "step": 910
    },
    {
      "epoch": 0.9847471233609848,
      "grad_norm": 0.8369371891021729,
      "learning_rate": 4.104918032786885e-07,
      "logits/chosen": 1.8130000829696655,
      "logits/rejected": 1.5563679933547974,
      "logps/chosen": -177.03248596191406,
      "logps/rejected": -93.50448608398438,
      "loss": 0.032793253660202026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1613147258758545,
      "rewards/margins": 3.574037551879883,
      "rewards/rejected": -2.412722587585449,
      "step": 920
    },
    {
      "epoch": 0.9954508964409955,
      "grad_norm": 0.588119387626648,
      "learning_rate": 4.093989071038251e-07,
      "logits/chosen": 1.7225919961929321,
      "logits/rejected": 1.517499566078186,
      "logps/chosen": -145.09872436523438,
      "logps/rejected": -93.66281127929688,
      "loss": 0.03417066931724548,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0797823667526245,
      "rewards/margins": 3.5223441123962402,
      "rewards/rejected": -2.4425618648529053,
      "step": 930
    },
    {
      "epoch": 1.0053518865400053,
      "grad_norm": 0.8849689364433289,
      "learning_rate": 4.083060109289617e-07,
      "logits/chosen": 1.5755726099014282,
      "logits/rejected": 1.4725950956344604,
      "logps/chosen": -132.5122833251953,
      "logps/rejected": -95.16565704345703,
      "loss": 0.03245730400085449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0501840114593506,
      "rewards/margins": 3.6119842529296875,
      "rewards/rejected": -2.561800241470337,
      "step": 940
    },
    {
      "epoch": 1.016055659620016,
      "grad_norm": 0.8366124033927917,
      "learning_rate": 4.0721311475409837e-07,
      "logits/chosen": 1.8341636657714844,
      "logits/rejected": 1.4668307304382324,
      "logps/chosen": -165.87979125976562,
      "logps/rejected": -95.01008605957031,
      "loss": 0.031292271614074704,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0788172483444214,
      "rewards/margins": 3.6775989532470703,
      "rewards/rejected": -2.5987815856933594,
      "step": 950
    },
    {
      "epoch": 1.0267594327000267,
      "grad_norm": 0.6333491802215576,
      "learning_rate": 4.0612021857923494e-07,
      "logits/chosen": 1.7061717510223389,
      "logits/rejected": 1.4761234521865845,
      "logps/chosen": -154.01495361328125,
      "logps/rejected": -96.00778198242188,
      "loss": 0.03177412748336792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0302543640136719,
      "rewards/margins": 3.6437790393829346,
      "rewards/rejected": -2.6135246753692627,
      "step": 960
    },
    {
      "epoch": 1.0374632057800375,
      "grad_norm": 0.9965106844902039,
      "learning_rate": 4.0502732240437156e-07,
      "logits/chosen": 1.695291519165039,
      "logits/rejected": 1.5310051441192627,
      "logps/chosen": -151.8094940185547,
      "logps/rejected": -94.58476257324219,
      "loss": 0.028743746876716613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1636403799057007,
      "rewards/margins": 3.7653377056121826,
      "rewards/rejected": -2.6016972064971924,
      "step": 970
    },
    {
      "epoch": 1.048166978860048,
      "grad_norm": 0.7560970783233643,
      "learning_rate": 4.039344262295082e-07,
      "logits/chosen": 1.755011796951294,
      "logits/rejected": 1.3940136432647705,
      "logps/chosen": -167.62318420410156,
      "logps/rejected": -96.64051818847656,
      "loss": 0.023827163875102995,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1457898616790771,
      "rewards/margins": 3.9066014289855957,
      "rewards/rejected": -2.7608115673065186,
      "step": 980
    },
    {
      "epoch": 1.0588707519400589,
      "grad_norm": 0.8368943333625793,
      "learning_rate": 4.0284153005464476e-07,
      "logits/chosen": 1.7236073017120361,
      "logits/rejected": 1.471868872642517,
      "logps/chosen": -146.08102416992188,
      "logps/rejected": -95.93193054199219,
      "loss": 0.025808066129684448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1423739194869995,
      "rewards/margins": 3.8906846046447754,
      "rewards/rejected": -2.7483105659484863,
      "step": 990
    },
    {
      "epoch": 1.0695745250200697,
      "grad_norm": 0.5986548662185669,
      "learning_rate": 4.0174863387978144e-07,
      "logits/chosen": 1.644383192062378,
      "logits/rejected": 1.303471326828003,
      "logps/chosen": -149.46023559570312,
      "logps/rejected": -97.68709564208984,
      "loss": 0.022938047349452973,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1230791807174683,
      "rewards/margins": 3.9801979064941406,
      "rewards/rejected": -2.857118606567383,
      "step": 1000
    },
    {
      "epoch": 1.0802782981000802,
      "grad_norm": 0.6457048058509827,
      "learning_rate": 4.00655737704918e-07,
      "logits/chosen": 1.6980746984481812,
      "logits/rejected": 1.3307790756225586,
      "logps/chosen": -159.41468811035156,
      "logps/rejected": -99.05873107910156,
      "loss": 0.023854197561740877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0730946063995361,
      "rewards/margins": 3.969989776611328,
      "rewards/rejected": -2.896894931793213,
      "step": 1010
    },
    {
      "epoch": 1.090982071180091,
      "grad_norm": 0.9346348643302917,
      "learning_rate": 3.9956284153005463e-07,
      "logits/chosen": 1.746276617050171,
      "logits/rejected": 1.410571813583374,
      "logps/chosen": -157.96530151367188,
      "logps/rejected": -99.2369155883789,
      "loss": 0.024355484545230864,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9926129579544067,
      "rewards/margins": 3.9418463706970215,
      "rewards/rejected": -2.9492335319519043,
      "step": 1020
    },
    {
      "epoch": 1.1016858442601016,
      "grad_norm": 0.9981865286827087,
      "learning_rate": 3.9846994535519126e-07,
      "logits/chosen": 1.6944652795791626,
      "logits/rejected": 1.3456825017929077,
      "logps/chosen": -143.97689819335938,
      "logps/rejected": -97.63856506347656,
      "loss": 0.027583912014961243,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0066230297088623,
      "rewards/margins": 3.950909376144409,
      "rewards/rejected": -2.944286823272705,
      "step": 1030
    },
    {
      "epoch": 1.1123896173401124,
      "grad_norm": 0.40167346596717834,
      "learning_rate": 3.973770491803278e-07,
      "logits/chosen": 1.7114397287368774,
      "logits/rejected": 1.293777346611023,
      "logps/chosen": -163.22914123535156,
      "logps/rejected": -99.56421661376953,
      "loss": 0.01984236389398575,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1040815114974976,
      "rewards/margins": 4.195456504821777,
      "rewards/rejected": -3.0913748741149902,
      "step": 1040
    },
    {
      "epoch": 1.123093390420123,
      "grad_norm": 0.46220362186431885,
      "learning_rate": 3.9628415300546445e-07,
      "logits/chosen": 1.7259594202041626,
      "logits/rejected": 1.3666250705718994,
      "logps/chosen": -154.5895233154297,
      "logps/rejected": -98.67662048339844,
      "loss": 0.018726345896720887,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1358704566955566,
      "rewards/margins": 4.176422595977783,
      "rewards/rejected": -3.0405516624450684,
      "step": 1050
    },
    {
      "epoch": 1.1337971635001338,
      "grad_norm": 0.9118120670318604,
      "learning_rate": 3.951912568306011e-07,
      "logits/chosen": 1.7006441354751587,
      "logits/rejected": 1.282173991203308,
      "logps/chosen": -157.17379760742188,
      "logps/rejected": -99.81719970703125,
      "loss": 0.020315879583358766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.035856008529663,
      "rewards/margins": 4.141615390777588,
      "rewards/rejected": -3.1057591438293457,
      "step": 1060
    },
    {
      "epoch": 1.1445009365801444,
      "grad_norm": 0.6183236241340637,
      "learning_rate": 3.940983606557377e-07,
      "logits/chosen": 1.7149302959442139,
      "logits/rejected": 1.2687909603118896,
      "logps/chosen": -154.16815185546875,
      "logps/rejected": -101.94291687011719,
      "loss": 0.019633619487285613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.071311593055725,
      "rewards/margins": 4.297905445098877,
      "rewards/rejected": -3.2265942096710205,
      "step": 1070
    },
    {
      "epoch": 1.1552047096601552,
      "grad_norm": 0.48427698016166687,
      "learning_rate": 3.9300546448087427e-07,
      "logits/chosen": 1.7651933431625366,
      "logits/rejected": 1.3281927108764648,
      "logps/chosen": -158.3819580078125,
      "logps/rejected": -100.43812561035156,
      "loss": 0.015394061803817749,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.169189691543579,
      "rewards/margins": 4.354580879211426,
      "rewards/rejected": -3.1853911876678467,
      "step": 1080
    },
    {
      "epoch": 1.165908482740166,
      "grad_norm": 0.8450509905815125,
      "learning_rate": 3.9191256830601095e-07,
      "logits/chosen": 1.658064603805542,
      "logits/rejected": 1.224921464920044,
      "logps/chosen": -136.96585083007812,
      "logps/rejected": -103.66092681884766,
      "loss": 0.016760839521884917,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.045638084411621,
      "rewards/margins": 4.36219596862793,
      "rewards/rejected": -3.3165574073791504,
      "step": 1090
    },
    {
      "epoch": 1.1766122558201766,
      "grad_norm": 0.4204149544239044,
      "learning_rate": 3.908196721311475e-07,
      "logits/chosen": 1.6076500415802002,
      "logits/rejected": 1.3003630638122559,
      "logps/chosen": -147.70803833007812,
      "logps/rejected": -101.76332092285156,
      "loss": 0.016228657960891724,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.186042070388794,
      "rewards/margins": 4.416829586029053,
      "rewards/rejected": -3.230787992477417,
      "step": 1100
    },
    {
      "epoch": 1.1873160289001874,
      "grad_norm": 0.41651085019111633,
      "learning_rate": 3.8972677595628414e-07,
      "logits/chosen": 1.6439168453216553,
      "logits/rejected": 1.3227794170379639,
      "logps/chosen": -151.53140258789062,
      "logps/rejected": -101.81876373291016,
      "loss": 0.016530880331993104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0728799104690552,
      "rewards/margins": 4.331194877624512,
      "rewards/rejected": -3.258314847946167,
      "step": 1110
    },
    {
      "epoch": 1.198019801980198,
      "grad_norm": 0.4798126220703125,
      "learning_rate": 3.8863387978142076e-07,
      "logits/chosen": 1.6710643768310547,
      "logits/rejected": 1.1560618877410889,
      "logps/chosen": -158.01406860351562,
      "logps/rejected": -104.6727066040039,
      "loss": 0.014420031011104584,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1185719966888428,
      "rewards/margins": 4.616798400878906,
      "rewards/rejected": -3.4982261657714844,
      "step": 1120
    },
    {
      "epoch": 1.2087235750602088,
      "grad_norm": 0.4670336842536926,
      "learning_rate": 3.8754098360655734e-07,
      "logits/chosen": 1.7404367923736572,
      "logits/rejected": 1.2171227931976318,
      "logps/chosen": -157.28460693359375,
      "logps/rejected": -103.58821105957031,
      "loss": 0.014666354656219483,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1248199939727783,
      "rewards/margins": 4.555264472961426,
      "rewards/rejected": -3.4304442405700684,
      "step": 1130
    },
    {
      "epoch": 1.2194273481402194,
      "grad_norm": 0.40709778666496277,
      "learning_rate": 3.86448087431694e-07,
      "logits/chosen": 1.598455786705017,
      "logits/rejected": 1.151465654373169,
      "logps/chosen": -148.83920288085938,
      "logps/rejected": -103.59617614746094,
      "loss": 0.013742342591285706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1368348598480225,
      "rewards/margins": 4.581087112426758,
      "rewards/rejected": -3.4442524909973145,
      "step": 1140
    },
    {
      "epoch": 1.2301311212202302,
      "grad_norm": 0.23900964856147766,
      "learning_rate": 3.853551912568306e-07,
      "logits/chosen": 1.634079933166504,
      "logits/rejected": 1.2009283304214478,
      "logps/chosen": -153.06735229492188,
      "logps/rejected": -104.62846374511719,
      "loss": 0.013513228297233582,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0884206295013428,
      "rewards/margins": 4.588320732116699,
      "rewards/rejected": -3.4999003410339355,
      "step": 1150
    },
    {
      "epoch": 1.2408348943002407,
      "grad_norm": 0.3809467852115631,
      "learning_rate": 3.8426229508196715e-07,
      "logits/chosen": 1.6272766590118408,
      "logits/rejected": 1.198920488357544,
      "logps/chosen": -156.12417602539062,
      "logps/rejected": -104.25091552734375,
      "loss": 0.013800825178623199,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0724321603775024,
      "rewards/margins": 4.614104270935059,
      "rewards/rejected": -3.541672468185425,
      "step": 1160
    },
    {
      "epoch": 1.2515386673802515,
      "grad_norm": 0.23170055449008942,
      "learning_rate": 3.8316939890710383e-07,
      "logits/chosen": 1.608130693435669,
      "logits/rejected": 1.1872681379318237,
      "logps/chosen": -140.0825958251953,
      "logps/rejected": -103.0272445678711,
      "loss": 0.015065607428550721,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0024986267089844,
      "rewards/margins": 4.543237209320068,
      "rewards/rejected": -3.540738582611084,
      "step": 1170
    },
    {
      "epoch": 1.2622424404602621,
      "grad_norm": 0.4358747899532318,
      "learning_rate": 3.820765027322404e-07,
      "logits/chosen": 1.6957542896270752,
      "logits/rejected": 1.1685556173324585,
      "logps/chosen": -169.14918518066406,
      "logps/rejected": -104.20523834228516,
      "loss": 0.014322775602340698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9869871139526367,
      "rewards/margins": 4.530843734741211,
      "rewards/rejected": -3.5438568592071533,
      "step": 1180
    },
    {
      "epoch": 1.272946213540273,
      "grad_norm": 0.4058906137943268,
      "learning_rate": 3.8098360655737703e-07,
      "logits/chosen": 1.6327699422836304,
      "logits/rejected": 1.1227926015853882,
      "logps/chosen": -150.0608673095703,
      "logps/rejected": -105.39753723144531,
      "loss": 0.012888216972351074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0483556985855103,
      "rewards/margins": 4.657876968383789,
      "rewards/rejected": -3.6095213890075684,
      "step": 1190
    },
    {
      "epoch": 1.2836499866202837,
      "grad_norm": 0.5216193795204163,
      "learning_rate": 3.7989071038251365e-07,
      "logits/chosen": 1.564469575881958,
      "logits/rejected": 1.1601684093475342,
      "logps/chosen": -147.4188690185547,
      "logps/rejected": -103.6126937866211,
      "loss": 0.013099354505538941,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1141846179962158,
      "rewards/margins": 4.68864107131958,
      "rewards/rejected": -3.5744564533233643,
      "step": 1200
    },
    {
      "epoch": 1.2943537597002943,
      "grad_norm": 0.3623017370700836,
      "learning_rate": 3.787978142076503e-07,
      "logits/chosen": 1.590881586074829,
      "logits/rejected": 1.1287685632705688,
      "logps/chosen": -144.04910278320312,
      "logps/rejected": -108.01960754394531,
      "loss": 0.010898669064044953,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0596532821655273,
      "rewards/margins": 4.857486724853516,
      "rewards/rejected": -3.7978336811065674,
      "step": 1210
    },
    {
      "epoch": 1.3050575327803051,
      "grad_norm": 0.643327534198761,
      "learning_rate": 3.7770491803278685e-07,
      "logits/chosen": 1.6923789978027344,
      "logits/rejected": 1.1569429636001587,
      "logps/chosen": -151.11279296875,
      "logps/rejected": -104.87245178222656,
      "loss": 0.012995848059654235,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0897698402404785,
      "rewards/margins": 4.703740119934082,
      "rewards/rejected": -3.6139702796936035,
      "step": 1220
    },
    {
      "epoch": 1.3157613058603157,
      "grad_norm": 0.4268481135368347,
      "learning_rate": 3.7661202185792347e-07,
      "logits/chosen": 1.6177021265029907,
      "logits/rejected": 1.152500867843628,
      "logps/chosen": -149.55088806152344,
      "logps/rejected": -105.1697006225586,
      "loss": 0.013492313027381898,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0310444831848145,
      "rewards/margins": 4.722887992858887,
      "rewards/rejected": -3.691843032836914,
      "step": 1230
    },
    {
      "epoch": 1.3264650789403265,
      "grad_norm": 0.4189468324184418,
      "learning_rate": 3.755191256830601e-07,
      "logits/chosen": 1.5691771507263184,
      "logits/rejected": 1.0491870641708374,
      "logps/chosen": -147.62387084960938,
      "logps/rejected": -107.48197937011719,
      "loss": 0.009806272387504578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1246130466461182,
      "rewards/margins": 4.981541633605957,
      "rewards/rejected": -3.8569283485412598,
      "step": 1240
    },
    {
      "epoch": 1.337168852020337,
      "grad_norm": 0.4989025592803955,
      "learning_rate": 3.7442622950819666e-07,
      "logits/chosen": 1.5755879878997803,
      "logits/rejected": 1.1296265125274658,
      "logps/chosen": -145.77291870117188,
      "logps/rejected": -105.25823974609375,
      "loss": 0.013076119124889374,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0347206592559814,
      "rewards/margins": 4.753051280975342,
      "rewards/rejected": -3.7183303833007812,
      "step": 1250
    },
    {
      "epoch": 1.3478726251003479,
      "grad_norm": 0.5551984906196594,
      "learning_rate": 3.7333333333333334e-07,
      "logits/chosen": 1.6291338205337524,
      "logits/rejected": 1.0504906177520752,
      "logps/chosen": -144.68692016601562,
      "logps/rejected": -108.4250717163086,
      "loss": 0.010129830241203308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2097426652908325,
      "rewards/margins": 5.105389595031738,
      "rewards/rejected": -3.895646572113037,
      "step": 1260
    },
    {
      "epoch": 1.3585763981803587,
      "grad_norm": 0.5045070648193359,
      "learning_rate": 3.722404371584699e-07,
      "logits/chosen": 1.6289771795272827,
      "logits/rejected": 1.019251823425293,
      "logps/chosen": -155.4300079345703,
      "logps/rejected": -108.71073150634766,
      "loss": 0.01139356791973114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0658457279205322,
      "rewards/margins": 5.054738521575928,
      "rewards/rejected": -3.988893508911133,
      "step": 1270
    },
    {
      "epoch": 1.3692801712603693,
      "grad_norm": 0.2792329788208008,
      "learning_rate": 3.711475409836066e-07,
      "logits/chosen": 1.5823785066604614,
      "logits/rejected": 0.9874511957168579,
      "logps/chosen": -136.4674530029297,
      "logps/rejected": -108.90467834472656,
      "loss": 0.008782903105020523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0923821926116943,
      "rewards/margins": 5.126376628875732,
      "rewards/rejected": -4.033994197845459,
      "step": 1280
    },
    {
      "epoch": 1.3799839443403799,
      "grad_norm": 0.28426870703697205,
      "learning_rate": 3.7005464480874316e-07,
      "logits/chosen": 1.5859463214874268,
      "logits/rejected": 1.117956280708313,
      "logps/chosen": -152.60537719726562,
      "logps/rejected": -107.889404296875,
      "loss": 0.010051801055669784,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.067343831062317,
      "rewards/margins": 5.025265216827393,
      "rewards/rejected": -3.9579215049743652,
      "step": 1290
    },
    {
      "epoch": 1.3906877174203907,
      "grad_norm": 0.22787357866764069,
      "learning_rate": 3.6896174863387973e-07,
      "logits/chosen": 1.5156147480010986,
      "logits/rejected": 0.9835519790649414,
      "logps/chosen": -128.3076629638672,
      "logps/rejected": -108.5299072265625,
      "loss": 0.008618803322315216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0897668600082397,
      "rewards/margins": 5.150269985198975,
      "rewards/rejected": -4.060503005981445,
      "step": 1300
    },
    {
      "epoch": 1.4013914905004015,
      "grad_norm": 0.1400226354598999,
      "learning_rate": 3.678688524590164e-07,
      "logits/chosen": 1.6013435125350952,
      "logits/rejected": 1.0340789556503296,
      "logps/chosen": -149.16268920898438,
      "logps/rejected": -108.9002685546875,
      "loss": 0.00866018682718277,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.120958924293518,
      "rewards/margins": 5.195265293121338,
      "rewards/rejected": -4.074306488037109,
      "step": 1310
    },
    {
      "epoch": 1.412095263580412,
      "grad_norm": 0.2601236402988434,
      "learning_rate": 3.66775956284153e-07,
      "logits/chosen": 1.6872774362564087,
      "logits/rejected": 1.0182682275772095,
      "logps/chosen": -157.99490356445312,
      "logps/rejected": -110.9283218383789,
      "loss": 0.009131181985139847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.010909080505371,
      "rewards/margins": 5.104722023010254,
      "rewards/rejected": -4.093812942504883,
      "step": 1320
    },
    {
      "epoch": 1.4227990366604228,
      "grad_norm": 0.2117798924446106,
      "learning_rate": 3.656830601092896e-07,
      "logits/chosen": 1.634985327720642,
      "logits/rejected": 1.1040092706680298,
      "logps/chosen": -151.16329956054688,
      "logps/rejected": -107.21158599853516,
      "loss": 0.0102551631629467,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0900437831878662,
      "rewards/margins": 5.004817008972168,
      "rewards/rejected": -3.914773464202881,
      "step": 1330
    },
    {
      "epoch": 1.4335028097404334,
      "grad_norm": 0.22261206805706024,
      "learning_rate": 3.6459016393442623e-07,
      "logits/chosen": 1.6284105777740479,
      "logits/rejected": 0.9671529531478882,
      "logps/chosen": -154.08065795898438,
      "logps/rejected": -111.91996002197266,
      "loss": 0.005895167216658592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.248009443283081,
      "rewards/margins": 5.459428310394287,
      "rewards/rejected": -4.211419105529785,
      "step": 1340
    },
    {
      "epoch": 1.4442065828204442,
      "grad_norm": 0.5116671323776245,
      "learning_rate": 3.634972677595628e-07,
      "logits/chosen": 1.5597525835037231,
      "logits/rejected": 0.9500673413276672,
      "logps/chosen": -154.83474731445312,
      "logps/rejected": -109.31138610839844,
      "loss": 0.008137129992246629,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1510223150253296,
      "rewards/margins": 5.236159324645996,
      "rewards/rejected": -4.085136890411377,
      "step": 1350
    },
    {
      "epoch": 1.4549103559004548,
      "grad_norm": 0.38766947388648987,
      "learning_rate": 3.624043715846994e-07,
      "logits/chosen": 1.5665686130523682,
      "logits/rejected": 0.9719702005386353,
      "logps/chosen": -149.33465576171875,
      "logps/rejected": -110.83180236816406,
      "loss": 0.007921382784843445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0418528318405151,
      "rewards/margins": 5.186440467834473,
      "rewards/rejected": -4.144588470458984,
      "step": 1360
    },
    {
      "epoch": 1.4656141289804656,
      "grad_norm": 0.227491557598114,
      "learning_rate": 3.6131147540983605e-07,
      "logits/chosen": 1.49527907371521,
      "logits/rejected": 0.9250208735466003,
      "logps/chosen": -140.29666137695312,
      "logps/rejected": -113.23548889160156,
      "loss": 0.006601744145154953,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0471017360687256,
      "rewards/margins": 5.429178714752197,
      "rewards/rejected": -4.382077217102051,
      "step": 1370
    },
    {
      "epoch": 1.4763179020604764,
      "grad_norm": 0.36765435338020325,
      "learning_rate": 3.6021857923497267e-07,
      "logits/chosen": 1.6231693029403687,
      "logits/rejected": 0.9676400423049927,
      "logps/chosen": -149.10072326660156,
      "logps/rejected": -112.33113098144531,
      "loss": 0.008004538714885712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0391027927398682,
      "rewards/margins": 5.326772212982178,
      "rewards/rejected": -4.2876691818237305,
      "step": 1380
    },
    {
      "epoch": 1.487021675140487,
      "grad_norm": 0.44688349962234497,
      "learning_rate": 3.5912568306010924e-07,
      "logits/chosen": 1.6091368198394775,
      "logits/rejected": 0.8703486323356628,
      "logps/chosen": -149.99563598632812,
      "logps/rejected": -111.2745590209961,
      "loss": 0.00832662507891655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0202630758285522,
      "rewards/margins": 5.358219623565674,
      "rewards/rejected": -4.337956428527832,
      "step": 1390
    },
    {
      "epoch": 1.4977254482204978,
      "grad_norm": 0.4907837510108948,
      "learning_rate": 3.580327868852459e-07,
      "logits/chosen": 1.6005843877792358,
      "logits/rejected": 0.976699709892273,
      "logps/chosen": -154.8329620361328,
      "logps/rejected": -111.04893493652344,
      "loss": 0.007755400985479355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0370457172393799,
      "rewards/margins": 5.337039470672607,
      "rewards/rejected": -4.299993991851807,
      "step": 1400
    },
    {
      "epoch": 1.5084292213005084,
      "grad_norm": 0.2778608798980713,
      "learning_rate": 3.569398907103825e-07,
      "logits/chosen": 1.505464792251587,
      "logits/rejected": 0.9065073728561401,
      "logps/chosen": -140.48153686523438,
      "logps/rejected": -113.8782730102539,
      "loss": 0.0067954003810882565,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.057477355003357,
      "rewards/margins": 5.480918884277344,
      "rewards/rejected": -4.423441410064697,
      "step": 1410
    },
    {
      "epoch": 1.5191329943805192,
      "grad_norm": 0.29754751920700073,
      "learning_rate": 3.5584699453551906e-07,
      "logits/chosen": 1.6160824298858643,
      "logits/rejected": 0.8865992426872253,
      "logps/chosen": -153.82394409179688,
      "logps/rejected": -114.8030776977539,
      "loss": 0.006381382048130035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1296651363372803,
      "rewards/margins": 5.615314960479736,
      "rewards/rejected": -4.485650062561035,
      "step": 1420
    },
    {
      "epoch": 1.5298367674605298,
      "grad_norm": 0.29483237862586975,
      "learning_rate": 3.5475409836065574e-07,
      "logits/chosen": 1.4864342212677002,
      "logits/rejected": 0.9742469787597656,
      "logps/chosen": -135.53465270996094,
      "logps/rejected": -112.5530014038086,
      "loss": 0.007720509916543961,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0009530782699585,
      "rewards/margins": 5.3963727951049805,
      "rewards/rejected": -4.395419120788574,
      "step": 1430
    },
    {
      "epoch": 1.5405405405405406,
      "grad_norm": 0.13553862273693085,
      "learning_rate": 3.536612021857923e-07,
      "logits/chosen": 1.6430332660675049,
      "logits/rejected": 0.9338138699531555,
      "logps/chosen": -159.31103515625,
      "logps/rejected": -114.3194351196289,
      "loss": 0.006980492174625397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0315312147140503,
      "rewards/margins": 5.470551490783691,
      "rewards/rejected": -4.439020156860352,
      "step": 1440
    },
    {
      "epoch": 1.5512443136205514,
      "grad_norm": 0.1543293297290802,
      "learning_rate": 3.52568306010929e-07,
      "logits/chosen": 1.6492382287979126,
      "logits/rejected": 0.943995475769043,
      "logps/chosen": -161.6962127685547,
      "logps/rejected": -111.55224609375,
      "loss": 0.007546412944793701,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0708017349243164,
      "rewards/margins": 5.4432783126831055,
      "rewards/rejected": -4.372476577758789,
      "step": 1450
    },
    {
      "epoch": 1.561948086700562,
      "grad_norm": 0.30082517862319946,
      "learning_rate": 3.5147540983606556e-07,
      "logits/chosen": 1.5662428140640259,
      "logits/rejected": 0.8768116235733032,
      "logps/chosen": -156.20567321777344,
      "logps/rejected": -113.18183898925781,
      "loss": 0.006614429503679275,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1105087995529175,
      "rewards/margins": 5.518448829650879,
      "rewards/rejected": -4.40794038772583,
      "step": 1460
    },
    {
      "epoch": 1.5726518597805725,
      "grad_norm": 0.09834881871938705,
      "learning_rate": 3.503825136612022e-07,
      "logits/chosen": 1.520167589187622,
      "logits/rejected": 0.8321606516838074,
      "logps/chosen": -154.56912231445312,
      "logps/rejected": -113.91378021240234,
      "loss": 0.005730107426643372,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1200811862945557,
      "rewards/margins": 5.664028167724609,
      "rewards/rejected": -4.543947219848633,
      "step": 1470
    },
    {
      "epoch": 1.5833556328605833,
      "grad_norm": 0.1452556699514389,
      "learning_rate": 3.492896174863388e-07,
      "logits/chosen": 1.520647406578064,
      "logits/rejected": 0.8309138417243958,
      "logps/chosen": -158.67025756835938,
      "logps/rejected": -115.37918853759766,
      "loss": 0.004996734485030174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0982542037963867,
      "rewards/margins": 5.752010822296143,
      "rewards/rejected": -4.653756618499756,
      "step": 1480
    },
    {
      "epoch": 1.5940594059405941,
      "grad_norm": 0.13051317632198334,
      "learning_rate": 3.481967213114754e-07,
      "logits/chosen": 1.5546388626098633,
      "logits/rejected": 0.842633068561554,
      "logps/chosen": -148.94448852539062,
      "logps/rejected": -116.4286117553711,
      "loss": 0.005139270424842834,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1452716588974,
      "rewards/margins": 5.829920291900635,
      "rewards/rejected": -4.684648513793945,
      "step": 1490
    },
    {
      "epoch": 1.6047631790206047,
      "grad_norm": 0.37510889768600464,
      "learning_rate": 3.47103825136612e-07,
      "logits/chosen": 1.576114296913147,
      "logits/rejected": 0.8640255928039551,
      "logps/chosen": -143.94467163085938,
      "logps/rejected": -115.34197998046875,
      "loss": 0.005869773030281067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0664522647857666,
      "rewards/margins": 5.6125407218933105,
      "rewards/rejected": -4.546088695526123,
      "step": 1500
    },
    {
      "epoch": 1.6154669521006153,
      "grad_norm": 0.21947038173675537,
      "learning_rate": 3.460109289617486e-07,
      "logits/chosen": 1.5982948541641235,
      "logits/rejected": 0.7766784429550171,
      "logps/chosen": -160.6962127685547,
      "logps/rejected": -114.58097076416016,
      "loss": 0.004470524564385414,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2018193006515503,
      "rewards/margins": 5.929062843322754,
      "rewards/rejected": -4.7272443771362305,
      "step": 1510
    },
    {
      "epoch": 1.6261707251806263,
      "grad_norm": 0.3414771258831024,
      "learning_rate": 3.4491803278688525e-07,
      "logits/chosen": 1.5552353858947754,
      "logits/rejected": 0.8312241435050964,
      "logps/chosen": -142.63339233398438,
      "logps/rejected": -113.5979232788086,
      "loss": 0.007761211693286895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9642106294631958,
      "rewards/margins": 5.466727256774902,
      "rewards/rejected": -4.50251579284668,
      "step": 1520
    },
    {
      "epoch": 1.636874498260637,
      "grad_norm": 0.2057974487543106,
      "learning_rate": 3.438251366120218e-07,
      "logits/chosen": 1.5897290706634521,
      "logits/rejected": 0.8295162320137024,
      "logps/chosen": -158.56973266601562,
      "logps/rejected": -114.5390625,
      "loss": 0.005641439184546471,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1414116621017456,
      "rewards/margins": 5.733644008636475,
      "rewards/rejected": -4.592232704162598,
      "step": 1530
    },
    {
      "epoch": 1.6475782713406475,
      "grad_norm": 0.09673157334327698,
      "learning_rate": 3.427322404371585e-07,
      "logits/chosen": 1.561664342880249,
      "logits/rejected": 0.7923893332481384,
      "logps/chosen": -155.33538818359375,
      "logps/rejected": -117.66542053222656,
      "loss": 0.004797248914837837,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0865919589996338,
      "rewards/margins": 5.9017229080200195,
      "rewards/rejected": -4.815130710601807,
      "step": 1540
    },
    {
      "epoch": 1.6582820444206583,
      "grad_norm": 0.3050020635128021,
      "learning_rate": 3.4163934426229506e-07,
      "logits/chosen": 1.4754148721694946,
      "logits/rejected": 0.738257110118866,
      "logps/chosen": -145.35238647460938,
      "logps/rejected": -116.49507141113281,
      "loss": 0.004570607841014862,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.105678915977478,
      "rewards/margins": 5.93576717376709,
      "rewards/rejected": -4.8300886154174805,
      "step": 1550
    },
    {
      "epoch": 1.668985817500669,
      "grad_norm": 0.34366393089294434,
      "learning_rate": 3.4054644808743164e-07,
      "logits/chosen": 1.5283586978912354,
      "logits/rejected": 0.8173551559448242,
      "logps/chosen": -147.7656707763672,
      "logps/rejected": -115.8546371459961,
      "loss": 0.004871172085404396,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.170554757118225,
      "rewards/margins": 5.855053901672363,
      "rewards/rejected": -4.6844987869262695,
      "step": 1560
    },
    {
      "epoch": 1.6796895905806797,
      "grad_norm": 0.10381560772657394,
      "learning_rate": 3.394535519125683e-07,
      "logits/chosen": 1.5279792547225952,
      "logits/rejected": 0.6934303045272827,
      "logps/chosen": -147.7467498779297,
      "logps/rejected": -118.15338134765625,
      "loss": 0.0036460526287555696,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1898711919784546,
      "rewards/margins": 6.120260238647461,
      "rewards/rejected": -4.930388450622559,
      "step": 1570
    },
    {
      "epoch": 1.6903933636606903,
      "grad_norm": 0.12060429155826569,
      "learning_rate": 3.383606557377049e-07,
      "logits/chosen": 1.5354530811309814,
      "logits/rejected": 0.6736940145492554,
      "logps/chosen": -148.82626342773438,
      "logps/rejected": -118.85604095458984,
      "loss": 0.004589807987213135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0626282691955566,
      "rewards/margins": 6.101828098297119,
      "rewards/rejected": -5.039199352264404,
      "step": 1580
    },
    {
      "epoch": 1.701097136740701,
      "grad_norm": 0.17309878766536713,
      "learning_rate": 3.3726775956284156e-07,
      "logits/chosen": 1.5679031610488892,
      "logits/rejected": 0.7518701553344727,
      "logps/chosen": -150.51217651367188,
      "logps/rejected": -116.42933654785156,
      "loss": 0.0051846526563167575,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.023505687713623,
      "rewards/margins": 5.837379455566406,
      "rewards/rejected": -4.813873767852783,
      "step": 1590
    },
    {
      "epoch": 1.7118009098207119,
      "grad_norm": 0.15225806832313538,
      "learning_rate": 3.3617486338797813e-07,
      "logits/chosen": 1.4664636850357056,
      "logits/rejected": 0.7018603086471558,
      "logps/chosen": -156.6265869140625,
      "logps/rejected": -116.9256362915039,
      "loss": 0.005242917314171791,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0311905145645142,
      "rewards/margins": 5.945704936981201,
      "rewards/rejected": -4.914514541625977,
      "step": 1600
    },
    {
      "epoch": 1.7225046829007225,
      "grad_norm": 0.08973901718854904,
      "learning_rate": 3.350819672131147e-07,
      "logits/chosen": 1.6009800434112549,
      "logits/rejected": 0.759947657585144,
      "logps/chosen": -160.56739807128906,
      "logps/rejected": -117.06459045410156,
      "loss": 0.004900451377034187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0900142192840576,
      "rewards/margins": 5.888967990875244,
      "rewards/rejected": -4.798953533172607,
      "step": 1610
    },
    {
      "epoch": 1.7332084559807333,
      "grad_norm": 0.17320911586284637,
      "learning_rate": 3.339890710382514e-07,
      "logits/chosen": 1.538717269897461,
      "logits/rejected": 0.731531023979187,
      "logps/chosen": -154.9336700439453,
      "logps/rejected": -118.90708923339844,
      "loss": 0.004155159741640091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0016013383865356,
      "rewards/margins": 5.920406341552734,
      "rewards/rejected": -4.918805122375488,
      "step": 1620
    },
    {
      "epoch": 1.743912229060744,
      "grad_norm": 0.2725568115711212,
      "learning_rate": 3.3289617486338795e-07,
      "logits/chosen": 1.4485523700714111,
      "logits/rejected": 0.7882407903671265,
      "logps/chosen": -149.05307006835938,
      "logps/rejected": -117.5820541381836,
      "loss": 0.005129667744040489,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0061070919036865,
      "rewards/margins": 5.891724109649658,
      "rewards/rejected": -4.885617256164551,
      "step": 1630
    },
    {
      "epoch": 1.7546160021407546,
      "grad_norm": 0.13122014701366425,
      "learning_rate": 3.318032786885246e-07,
      "logits/chosen": 1.487694501876831,
      "logits/rejected": 0.7943651676177979,
      "logps/chosen": -149.83709716796875,
      "logps/rejected": -117.58642578125,
      "loss": 0.004466667026281357,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1434080600738525,
      "rewards/margins": 6.017514228820801,
      "rewards/rejected": -4.874105930328369,
      "step": 1640
    },
    {
      "epoch": 1.7653197752207652,
      "grad_norm": 0.29374581575393677,
      "learning_rate": 3.307103825136612e-07,
      "logits/chosen": 1.509742021560669,
      "logits/rejected": 0.6940016746520996,
      "logps/chosen": -135.9411163330078,
      "logps/rejected": -118.92497253417969,
      "loss": 0.0039986010640859606,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1365573406219482,
      "rewards/margins": 6.124014854431152,
      "rewards/rejected": -4.987457275390625,
      "step": 1650
    },
    {
      "epoch": 1.776023548300776,
      "grad_norm": 0.2135181874036789,
      "learning_rate": 3.296174863387978e-07,
      "logits/chosen": 1.473055362701416,
      "logits/rejected": 0.7567785978317261,
      "logps/chosen": -142.8508758544922,
      "logps/rejected": -117.3902816772461,
      "loss": 0.0053837127983570095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0836849212646484,
      "rewards/margins": 5.973540306091309,
      "rewards/rejected": -4.88985538482666,
      "step": 1660
    },
    {
      "epoch": 1.7867273213807868,
      "grad_norm": 0.2548823654651642,
      "learning_rate": 3.285245901639344e-07,
      "logits/chosen": 1.4688224792480469,
      "logits/rejected": 0.7919714450836182,
      "logps/chosen": -150.28024291992188,
      "logps/rejected": -117.79609680175781,
      "loss": 0.004047109186649323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.141546368598938,
      "rewards/margins": 6.00596284866333,
      "rewards/rejected": -4.864416599273682,
      "step": 1670
    },
    {
      "epoch": 1.7974310944607974,
      "grad_norm": 0.11140570789575577,
      "learning_rate": 3.27431693989071e-07,
      "logits/chosen": 1.5517245531082153,
      "logits/rejected": 0.6706668734550476,
      "logps/chosen": -154.6449432373047,
      "logps/rejected": -121.26871490478516,
      "loss": 0.004351936653256417,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0217194557189941,
      "rewards/margins": 6.218635559082031,
      "rewards/rejected": -5.196916103363037,
      "step": 1680
    },
    {
      "epoch": 1.808134867540808,
      "grad_norm": 0.3311346769332886,
      "learning_rate": 3.2633879781420764e-07,
      "logits/chosen": 1.4776819944381714,
      "logits/rejected": 0.6457537412643433,
      "logps/chosen": -148.58578491210938,
      "logps/rejected": -120.37003326416016,
      "loss": 0.004631736502051354,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9618233442306519,
      "rewards/margins": 6.118097305297852,
      "rewards/rejected": -5.15627384185791,
      "step": 1690
    },
    {
      "epoch": 1.8188386406208188,
      "grad_norm": 0.1448356807231903,
      "learning_rate": 3.252459016393442e-07,
      "logits/chosen": 1.4546148777008057,
      "logits/rejected": 0.6552863717079163,
      "logps/chosen": -141.8134307861328,
      "logps/rejected": -120.81675720214844,
      "loss": 0.0033345628529787064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0453417301177979,
      "rewards/margins": 6.187654495239258,
      "rewards/rejected": -5.142313003540039,
      "step": 1700
    },
    {
      "epoch": 1.8295424137008296,
      "grad_norm": 0.1776205450296402,
      "learning_rate": 3.241530054644809e-07,
      "logits/chosen": 1.4313377141952515,
      "logits/rejected": 0.7617113590240479,
      "logps/chosen": -143.47396850585938,
      "logps/rejected": -117.89241027832031,
      "loss": 0.003885149583220482,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0821517705917358,
      "rewards/margins": 6.052678108215332,
      "rewards/rejected": -4.97052526473999,
      "step": 1710
    },
    {
      "epoch": 1.8402461867808402,
      "grad_norm": 0.11620660871267319,
      "learning_rate": 3.2306010928961746e-07,
      "logits/chosen": 1.5745112895965576,
      "logits/rejected": 0.7286126017570496,
      "logps/chosen": -158.12232971191406,
      "logps/rejected": -118.83625793457031,
      "loss": 0.003610484302043915,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.096605658531189,
      "rewards/margins": 6.130742073059082,
      "rewards/rejected": -5.034135818481445,
      "step": 1720
    },
    {
      "epoch": 1.850949959860851,
      "grad_norm": 0.12171466648578644,
      "learning_rate": 3.2196721311475414e-07,
      "logits/chosen": 1.446814775466919,
      "logits/rejected": 0.5939318537712097,
      "logps/chosen": -146.15087890625,
      "logps/rejected": -120.45649719238281,
      "loss": 0.0036291051656007767,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0129451751708984,
      "rewards/margins": 6.250824928283691,
      "rewards/rejected": -5.237879753112793,
      "step": 1730
    },
    {
      "epoch": 1.8616537329408618,
      "grad_norm": 0.13180969655513763,
      "learning_rate": 3.208743169398907e-07,
      "logits/chosen": 1.5000293254852295,
      "logits/rejected": 0.741145133972168,
      "logps/chosen": -150.6980438232422,
      "logps/rejected": -118.4443588256836,
      "loss": 0.004610740765929222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0184650421142578,
      "rewards/margins": 6.023463249206543,
      "rewards/rejected": -5.004998683929443,
      "step": 1740
    },
    {
      "epoch": 1.8723575060208724,
      "grad_norm": 0.2998705506324768,
      "learning_rate": 3.197814207650273e-07,
      "logits/chosen": 1.5602998733520508,
      "logits/rejected": 0.6853562593460083,
      "logps/chosen": -151.74093627929688,
      "logps/rejected": -120.72383117675781,
      "loss": 0.003917388245463371,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0297659635543823,
      "rewards/margins": 6.210249423980713,
      "rewards/rejected": -5.180482864379883,
      "step": 1750
    },
    {
      "epoch": 1.883061279100883,
      "grad_norm": 0.1871148943901062,
      "learning_rate": 3.1868852459016396e-07,
      "logits/chosen": 1.4845420122146606,
      "logits/rejected": 0.7029028534889221,
      "logps/chosen": -149.55581665039062,
      "logps/rejected": -120.7500991821289,
      "loss": 0.004722888395190239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9828691482543945,
      "rewards/margins": 6.127322196960449,
      "rewards/rejected": -5.1444525718688965,
      "step": 1760
    },
    {
      "epoch": 1.8937650521808937,
      "grad_norm": 0.17614050209522247,
      "learning_rate": 3.175956284153005e-07,
      "logits/chosen": 1.5553237199783325,
      "logits/rejected": 0.673250675201416,
      "logps/chosen": -150.4746856689453,
      "logps/rejected": -121.5872573852539,
      "loss": 0.0036264151334762574,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0615551471710205,
      "rewards/margins": 6.34146785736084,
      "rewards/rejected": -5.27991247177124,
      "step": 1770
    },
    {
      "epoch": 1.9044688252609046,
      "grad_norm": 0.11600381135940552,
      "learning_rate": 3.1650273224043715e-07,
      "logits/chosen": 1.5750457048416138,
      "logits/rejected": 0.6924819946289062,
      "logps/chosen": -155.31430053710938,
      "logps/rejected": -120.5289306640625,
      "loss": 0.0034931376576423645,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.129502773284912,
      "rewards/margins": 6.2902069091796875,
      "rewards/rejected": -5.160703659057617,
      "step": 1780
    },
    {
      "epoch": 1.9151725983409151,
      "grad_norm": 0.06815683096647263,
      "learning_rate": 3.154098360655738e-07,
      "logits/chosen": 1.4999120235443115,
      "logits/rejected": 0.5357456207275391,
      "logps/chosen": -161.388671875,
      "logps/rejected": -122.76789855957031,
      "loss": 0.004669053107500076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9903985857963562,
      "rewards/margins": 6.400639533996582,
      "rewards/rejected": -5.41024112701416,
      "step": 1790
    },
    {
      "epoch": 1.9258763714209257,
      "grad_norm": 0.16505491733551025,
      "learning_rate": 3.1431693989071035e-07,
      "logits/chosen": 1.4875143766403198,
      "logits/rejected": 0.5980480909347534,
      "logps/chosen": -153.0215301513672,
      "logps/rejected": -121.37568664550781,
      "loss": 0.0036387357860803602,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0354816913604736,
      "rewards/margins": 6.301854610443115,
      "rewards/rejected": -5.266373157501221,
      "step": 1800
    },
    {
      "epoch": 1.9365801445009367,
      "grad_norm": 0.18932977318763733,
      "learning_rate": 3.1322404371584697e-07,
      "logits/chosen": 1.585418701171875,
      "logits/rejected": 0.6047422289848328,
      "logps/chosen": -161.19082641601562,
      "logps/rejected": -123.39202880859375,
      "loss": 0.0032647706568241118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.082875370979309,
      "rewards/margins": 6.522629737854004,
      "rewards/rejected": -5.439754486083984,
      "step": 1810
    },
    {
      "epoch": 1.9472839175809473,
      "grad_norm": 0.16728149354457855,
      "learning_rate": 3.121311475409836e-07,
      "logits/chosen": 1.454008936882019,
      "logits/rejected": 0.6763039231300354,
      "logps/chosen": -156.9350128173828,
      "logps/rejected": -121.14158630371094,
      "loss": 0.004012018814682961,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.977035403251648,
      "rewards/margins": 6.184750080108643,
      "rewards/rejected": -5.207714080810547,
      "step": 1820
    },
    {
      "epoch": 1.957987690660958,
      "grad_norm": 0.13100945949554443,
      "learning_rate": 3.110382513661202e-07,
      "logits/chosen": 1.5030378103256226,
      "logits/rejected": 0.7571598887443542,
      "logps/chosen": -156.68594360351562,
      "logps/rejected": -119.37747955322266,
      "loss": 0.0034644857048988344,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0761038064956665,
      "rewards/margins": 6.198269367218018,
      "rewards/rejected": -5.122165679931641,
      "step": 1830
    },
    {
      "epoch": 1.9686914637409687,
      "grad_norm": 0.2701702117919922,
      "learning_rate": 3.099453551912568e-07,
      "logits/chosen": 1.5564534664154053,
      "logits/rejected": 0.6061638593673706,
      "logps/chosen": -153.29306030273438,
      "logps/rejected": -121.18260192871094,
      "loss": 0.003254232183098793,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0310449600219727,
      "rewards/margins": 6.342109680175781,
      "rewards/rejected": -5.311064720153809,
      "step": 1840
    },
    {
      "epoch": 1.9793952368209795,
      "grad_norm": 0.0800785943865776,
      "learning_rate": 3.0885245901639346e-07,
      "logits/chosen": 1.4291141033172607,
      "logits/rejected": 0.5587162971496582,
      "logps/chosen": -157.511962890625,
      "logps/rejected": -125.8763198852539,
      "loss": 0.0026865921914577483,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0286327600479126,
      "rewards/margins": 6.54119873046875,
      "rewards/rejected": -5.512565612792969,
      "step": 1850
    },
    {
      "epoch": 1.99009900990099,
      "grad_norm": 0.13709595799446106,
      "learning_rate": 3.0775956284153004e-07,
      "logits/chosen": 1.5321934223175049,
      "logits/rejected": 0.5205730199813843,
      "logps/chosen": -151.20352172851562,
      "logps/rejected": -124.80009460449219,
      "loss": 0.0030743153765797615,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9063335657119751,
      "rewards/margins": 6.491813659667969,
      "rewards/rejected": -5.585480690002441,
      "step": 1860
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.039750535041093826,
      "learning_rate": 3.066666666666666e-07,
      "logits/chosen": 1.4341245889663696,
      "logits/rejected": 0.5502797961235046,
      "logps/chosen": -139.96157836914062,
      "logps/rejected": -123.59080505371094,
      "loss": 0.003058922477066517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9688056707382202,
      "rewards/margins": 6.436350345611572,
      "rewards/rejected": -5.4675445556640625,
      "step": 1870
    },
    {
      "epoch": 2.0107037730800106,
      "grad_norm": 0.2896607220172882,
      "learning_rate": 3.055737704918033e-07,
      "logits/chosen": 1.5526959896087646,
      "logits/rejected": 0.49284929037094116,
      "logps/chosen": -157.7774200439453,
      "logps/rejected": -125.71964263916016,
      "loss": 0.002377932146191597,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1131511926651,
      "rewards/margins": 6.729103088378906,
      "rewards/rejected": -5.615951061248779,
      "step": 1880
    },
    {
      "epoch": 2.0214075461600216,
      "grad_norm": 0.11361595243215561,
      "learning_rate": 3.0448087431693985e-07,
      "logits/chosen": 1.5065425634384155,
      "logits/rejected": 0.5010890364646912,
      "logps/chosen": -158.81350708007812,
      "logps/rejected": -125.4672622680664,
      "loss": 0.0032584350556135178,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0083916187286377,
      "rewards/margins": 6.572033882141113,
      "rewards/rejected": -5.5636420249938965,
      "step": 1890
    },
    {
      "epoch": 2.032111319240032,
      "grad_norm": 0.08013357222080231,
      "learning_rate": 3.0338797814207653e-07,
      "logits/chosen": 1.5213844776153564,
      "logits/rejected": 0.5598002672195435,
      "logps/chosen": -155.23435974121094,
      "logps/rejected": -124.33781433105469,
      "loss": 0.0026266008615493776,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0709435939788818,
      "rewards/margins": 6.597651481628418,
      "rewards/rejected": -5.526707649230957,
      "step": 1900
    },
    {
      "epoch": 2.0428150923200428,
      "grad_norm": 0.13544459640979767,
      "learning_rate": 3.022950819672131e-07,
      "logits/chosen": 1.5368785858154297,
      "logits/rejected": 0.6037379503250122,
      "logps/chosen": -155.91127014160156,
      "logps/rejected": -123.21177673339844,
      "loss": 0.003547479584813118,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0077269077301025,
      "rewards/margins": 6.410433769226074,
      "rewards/rejected": -5.402707099914551,
      "step": 1910
    },
    {
      "epoch": 2.0535188654000534,
      "grad_norm": 0.15746408700942993,
      "learning_rate": 3.0120218579234973e-07,
      "logits/chosen": 1.495409369468689,
      "logits/rejected": 0.5773187875747681,
      "logps/chosen": -143.88424682617188,
      "logps/rejected": -123.3151626586914,
      "loss": 0.0027977321296930313,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.985864520072937,
      "rewards/margins": 6.451733589172363,
      "rewards/rejected": -5.465868949890137,
      "step": 1920
    },
    {
      "epoch": 2.0642226384800644,
      "grad_norm": 0.037635937333106995,
      "learning_rate": 3.0010928961748635e-07,
      "logits/chosen": 1.4387686252593994,
      "logits/rejected": 0.5170767307281494,
      "logps/chosen": -149.09535217285156,
      "logps/rejected": -125.88270568847656,
      "loss": 0.0028556127101182936,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0774955749511719,
      "rewards/margins": 6.715664863586426,
      "rewards/rejected": -5.638168811798096,
      "step": 1930
    },
    {
      "epoch": 2.074926411560075,
      "grad_norm": 0.135502427816391,
      "learning_rate": 2.990163934426229e-07,
      "logits/chosen": 1.4657282829284668,
      "logits/rejected": 0.5527217984199524,
      "logps/chosen": -143.11090087890625,
      "logps/rejected": -124.92436218261719,
      "loss": 0.0024582564830780028,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0214240550994873,
      "rewards/margins": 6.661993980407715,
      "rewards/rejected": -5.640570640563965,
      "step": 1940
    },
    {
      "epoch": 2.0856301846400855,
      "grad_norm": 0.13684280216693878,
      "learning_rate": 2.9792349726775955e-07,
      "logits/chosen": 1.4837524890899658,
      "logits/rejected": 0.48822221159935,
      "logps/chosen": -160.49282836914062,
      "logps/rejected": -124.57093811035156,
      "loss": 0.003776436671614647,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8681160807609558,
      "rewards/margins": 6.427125453948975,
      "rewards/rejected": -5.559009075164795,
      "step": 1950
    },
    {
      "epoch": 2.096333957720096,
      "grad_norm": 0.20886236429214478,
      "learning_rate": 2.9683060109289617e-07,
      "logits/chosen": 1.390901803970337,
      "logits/rejected": 0.5154417753219604,
      "logps/chosen": -141.78076171875,
      "logps/rejected": -126.1515121459961,
      "loss": 0.0029472578316926956,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9024735689163208,
      "rewards/margins": 6.534306526184082,
      "rewards/rejected": -5.631832599639893,
      "step": 1960
    },
    {
      "epoch": 2.107037730800107,
      "grad_norm": 0.27550193667411804,
      "learning_rate": 2.957377049180328e-07,
      "logits/chosen": 1.4491732120513916,
      "logits/rejected": 0.5530385971069336,
      "logps/chosen": -145.9943084716797,
      "logps/rejected": -126.9167709350586,
      "loss": 0.0033412162214517594,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8219404220581055,
      "rewards/margins": 6.441891670227051,
      "rewards/rejected": -5.619950771331787,
      "step": 1970
    },
    {
      "epoch": 2.1177415038801177,
      "grad_norm": 0.3880891501903534,
      "learning_rate": 2.9464480874316936e-07,
      "logits/chosen": 1.4399993419647217,
      "logits/rejected": 0.44511955976486206,
      "logps/chosen": -142.97689819335938,
      "logps/rejected": -126.92683410644531,
      "loss": 0.0030293824151158334,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9471173286437988,
      "rewards/margins": 6.721013069152832,
      "rewards/rejected": -5.773895740509033,
      "step": 1980
    },
    {
      "epoch": 2.1284452769601283,
      "grad_norm": 0.16601799428462982,
      "learning_rate": 2.93551912568306e-07,
      "logits/chosen": 1.4633824825286865,
      "logits/rejected": 0.6225780248641968,
      "logps/chosen": -151.4712371826172,
      "logps/rejected": -121.749267578125,
      "loss": 0.003313889726996422,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0608705282211304,
      "rewards/margins": 6.397374153137207,
      "rewards/rejected": -5.336503505706787,
      "step": 1990
    },
    {
      "epoch": 2.1391490500401393,
      "grad_norm": 0.21143002808094025,
      "learning_rate": 2.924590163934426e-07,
      "logits/chosen": 1.4197763204574585,
      "logits/rejected": 0.6153291463851929,
      "logps/chosen": -142.1334991455078,
      "logps/rejected": -124.11045837402344,
      "loss": 0.002791861444711685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1265590190887451,
      "rewards/margins": 6.675694465637207,
      "rewards/rejected": -5.549135684967041,
      "step": 2000
    },
    {
      "epoch": 2.14985282312015,
      "grad_norm": 0.07040438055992126,
      "learning_rate": 2.913661202185792e-07,
      "logits/chosen": 1.4166676998138428,
      "logits/rejected": 0.5284075736999512,
      "logps/chosen": -147.5186767578125,
      "logps/rejected": -125.57430267333984,
      "loss": 0.002738739177584648,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.936847984790802,
      "rewards/margins": 6.624791622161865,
      "rewards/rejected": -5.6879448890686035,
      "step": 2010
    },
    {
      "epoch": 2.1605565962001605,
      "grad_norm": 0.08093404024839401,
      "learning_rate": 2.9027322404371586e-07,
      "logits/chosen": 1.4649369716644287,
      "logits/rejected": 0.4823905825614929,
      "logps/chosen": -140.3905029296875,
      "logps/rejected": -124.73069763183594,
      "loss": 0.003003150038421154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9881485104560852,
      "rewards/margins": 6.671755790710449,
      "rewards/rejected": -5.68360710144043,
      "step": 2020
    },
    {
      "epoch": 2.171260369280171,
      "grad_norm": 0.10110314935445786,
      "learning_rate": 2.8918032786885243e-07,
      "logits/chosen": 1.510565996170044,
      "logits/rejected": 0.49249815940856934,
      "logps/chosen": -155.85792541503906,
      "logps/rejected": -126.1528549194336,
      "loss": 0.0026595955714583397,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0028131008148193,
      "rewards/margins": 6.74930477142334,
      "rewards/rejected": -5.746491432189941,
      "step": 2030
    },
    {
      "epoch": 2.181964142360182,
      "grad_norm": 0.06718752533197403,
      "learning_rate": 2.8808743169398905e-07,
      "logits/chosen": 1.477243185043335,
      "logits/rejected": 0.5398080348968506,
      "logps/chosen": -152.25387573242188,
      "logps/rejected": -126.39277648925781,
      "loss": 0.0021829646080732345,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.038659930229187,
      "rewards/margins": 6.777960777282715,
      "rewards/rejected": -5.7393012046813965,
      "step": 2040
    },
    {
      "epoch": 2.1926679154401927,
      "grad_norm": 0.11089986562728882,
      "learning_rate": 2.869945355191257e-07,
      "logits/chosen": 1.4871399402618408,
      "logits/rejected": 0.44859498739242554,
      "logps/chosen": -158.52932739257812,
      "logps/rejected": -125.17234802246094,
      "loss": 0.0022577768191695212,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0103648900985718,
      "rewards/margins": 6.760044097900391,
      "rewards/rejected": -5.749679088592529,
      "step": 2050
    },
    {
      "epoch": 2.2033716885202033,
      "grad_norm": 0.049009233713150024,
      "learning_rate": 2.8590163934426225e-07,
      "logits/chosen": 1.5319316387176514,
      "logits/rejected": 0.49656611680984497,
      "logps/chosen": -164.24388122558594,
      "logps/rejected": -127.47721862792969,
      "loss": 0.0025159860029816627,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0272547006607056,
      "rewards/margins": 6.791390419006348,
      "rewards/rejected": -5.764134883880615,
      "step": 2060
    },
    {
      "epoch": 2.2140754616002143,
      "grad_norm": 0.09687826037406921,
      "learning_rate": 2.8480874316939893e-07,
      "logits/chosen": 1.4794296026229858,
      "logits/rejected": 0.41713768243789673,
      "logps/chosen": -151.49893188476562,
      "logps/rejected": -128.28469848632812,
      "loss": 0.0026547050103545187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0665849447250366,
      "rewards/margins": 6.987290382385254,
      "rewards/rejected": -5.9207048416137695,
      "step": 2070
    },
    {
      "epoch": 2.224779234680225,
      "grad_norm": 0.07388327270746231,
      "learning_rate": 2.837158469945355e-07,
      "logits/chosen": 1.4490654468536377,
      "logits/rejected": 0.513068437576294,
      "logps/chosen": -158.13973999023438,
      "logps/rejected": -125.3230972290039,
      "loss": 0.0031191401183605196,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9513936042785645,
      "rewards/margins": 6.710287570953369,
      "rewards/rejected": -5.758893013000488,
      "step": 2080
    },
    {
      "epoch": 2.2354830077602355,
      "grad_norm": 0.07235264778137207,
      "learning_rate": 2.826229508196721e-07,
      "logits/chosen": 1.4318058490753174,
      "logits/rejected": 0.47284388542175293,
      "logps/chosen": -150.46060180664062,
      "logps/rejected": -127.51896667480469,
      "loss": 0.0023971237242221832,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9404087066650391,
      "rewards/margins": 6.729447364807129,
      "rewards/rejected": -5.789038181304932,
      "step": 2090
    },
    {
      "epoch": 2.246186780840246,
      "grad_norm": 0.056111324578523636,
      "learning_rate": 2.8153005464480875e-07,
      "logits/chosen": 1.3455901145935059,
      "logits/rejected": 0.4570145010948181,
      "logps/chosen": -127.69837951660156,
      "logps/rejected": -127.53276062011719,
      "loss": 0.0017177291214466096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0936658382415771,
      "rewards/margins": 6.991428375244141,
      "rewards/rejected": -5.897762298583984,
      "step": 2100
    },
    {
      "epoch": 2.256890553920257,
      "grad_norm": 0.058155834674835205,
      "learning_rate": 2.8043715846994537e-07,
      "logits/chosen": 1.3641340732574463,
      "logits/rejected": 0.47660723328590393,
      "logps/chosen": -149.432373046875,
      "logps/rejected": -126.8008804321289,
      "loss": 0.0023802699521183967,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.996921718120575,
      "rewards/margins": 6.9117913246154785,
      "rewards/rejected": -5.914869785308838,
      "step": 2110
    },
    {
      "epoch": 2.2675943270002676,
      "grad_norm": 0.041802674531936646,
      "learning_rate": 2.7934426229508194e-07,
      "logits/chosen": 1.4396504163742065,
      "logits/rejected": 0.4081820547580719,
      "logps/chosen": -140.4492950439453,
      "logps/rejected": -128.08779907226562,
      "loss": 0.002135193347930908,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0022952556610107,
      "rewards/margins": 6.959442138671875,
      "rewards/rejected": -5.957146644592285,
      "step": 2120
    },
    {
      "epoch": 2.278298100080278,
      "grad_norm": 0.11650945246219635,
      "learning_rate": 2.7825136612021856e-07,
      "logits/chosen": 1.4290540218353271,
      "logits/rejected": 0.42820820212364197,
      "logps/chosen": -141.7557373046875,
      "logps/rejected": -127.47901916503906,
      "loss": 0.0018946273252367974,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.06272292137146,
      "rewards/margins": 6.987894535064697,
      "rewards/rejected": -5.925171852111816,
      "step": 2130
    },
    {
      "epoch": 2.289001873160289,
      "grad_norm": 0.21665813028812408,
      "learning_rate": 2.771584699453552e-07,
      "logits/chosen": 1.3861935138702393,
      "logits/rejected": 0.47547632455825806,
      "logps/chosen": -152.62921142578125,
      "logps/rejected": -128.26779174804688,
      "loss": 0.0023826055228710176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9964858889579773,
      "rewards/margins": 6.916149139404297,
      "rewards/rejected": -5.919662952423096,
      "step": 2140
    },
    {
      "epoch": 2.2997056462403,
      "grad_norm": 0.08501067012548447,
      "learning_rate": 2.7606557377049176e-07,
      "logits/chosen": 1.4678852558135986,
      "logits/rejected": 0.4599221348762512,
      "logps/chosen": -144.94857788085938,
      "logps/rejected": -127.33686828613281,
      "loss": 0.0019201496616005898,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2182505130767822,
      "rewards/margins": 7.0583696365356445,
      "rewards/rejected": -5.840117931365967,
      "step": 2150
    },
    {
      "epoch": 2.3104094193203104,
      "grad_norm": 0.1243026852607727,
      "learning_rate": 2.7497267759562844e-07,
      "logits/chosen": 1.5593727827072144,
      "logits/rejected": 0.4475012421607971,
      "logps/chosen": -160.63546752929688,
      "logps/rejected": -129.02183532714844,
      "loss": 0.0026995129883289337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9929611086845398,
      "rewards/margins": 6.942579746246338,
      "rewards/rejected": -5.949618816375732,
      "step": 2160
    },
    {
      "epoch": 2.321113192400321,
      "grad_norm": 0.19596584141254425,
      "learning_rate": 2.73879781420765e-07,
      "logits/chosen": 1.459525465965271,
      "logits/rejected": 0.46629229187965393,
      "logps/chosen": -147.43222045898438,
      "logps/rejected": -129.1011199951172,
      "loss": 0.0019960260018706323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9468680620193481,
      "rewards/margins": 6.955275058746338,
      "rewards/rejected": -6.008406639099121,
      "step": 2170
    },
    {
      "epoch": 2.331816965480332,
      "grad_norm": 0.05201566591858864,
      "learning_rate": 2.7278688524590163e-07,
      "logits/chosen": 1.4876327514648438,
      "logits/rejected": 0.42444276809692383,
      "logps/chosen": -166.91929626464844,
      "logps/rejected": -126.92205810546875,
      "loss": 0.001682017557322979,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.110100507736206,
      "rewards/margins": 7.034442901611328,
      "rewards/rejected": -5.924341678619385,
      "step": 2180
    },
    {
      "epoch": 2.3425207385603426,
      "grad_norm": 0.08689054101705551,
      "learning_rate": 2.7169398907103826e-07,
      "logits/chosen": 1.5085949897766113,
      "logits/rejected": 0.5743601322174072,
      "logps/chosen": -161.57017517089844,
      "logps/rejected": -126.31526184082031,
      "loss": 0.0018067264929413796,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1180436611175537,
      "rewards/margins": 6.976956367492676,
      "rewards/rejected": -5.858912467956543,
      "step": 2190
    },
    {
      "epoch": 2.353224511640353,
      "grad_norm": 0.27131569385528564,
      "learning_rate": 2.706010928961748e-07,
      "logits/chosen": 1.3843132257461548,
      "logits/rejected": 0.3701043128967285,
      "logps/chosen": -146.19863891601562,
      "logps/rejected": -130.16421508789062,
      "loss": 0.0019759593531489374,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9553070068359375,
      "rewards/margins": 7.051602840423584,
      "rewards/rejected": -6.0962958335876465,
      "step": 2200
    },
    {
      "epoch": 2.3639282847203638,
      "grad_norm": 0.07385018467903137,
      "learning_rate": 2.6950819672131145e-07,
      "logits/chosen": 1.398378610610962,
      "logits/rejected": 0.3482743203639984,
      "logps/chosen": -150.7294464111328,
      "logps/rejected": -132.52610778808594,
      "loss": 0.0011304203420877458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1248881816864014,
      "rewards/margins": 7.332140922546387,
      "rewards/rejected": -6.2072529792785645,
      "step": 2210
    },
    {
      "epoch": 2.374632057800375,
      "grad_norm": 0.07405788451433182,
      "learning_rate": 2.684153005464481e-07,
      "logits/chosen": 1.4767652750015259,
      "logits/rejected": 0.4632749557495117,
      "logps/chosen": -156.75209045410156,
      "logps/rejected": -128.8383026123047,
      "loss": 0.0019316378980875014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0455223321914673,
      "rewards/margins": 6.968251705169678,
      "rewards/rejected": -5.9227294921875,
      "step": 2220
    },
    {
      "epoch": 2.3853358308803854,
      "grad_norm": 0.1349841058254242,
      "learning_rate": 2.673224043715847e-07,
      "logits/chosen": 1.497788667678833,
      "logits/rejected": 0.2270340621471405,
      "logps/chosen": -153.27999877929688,
      "logps/rejected": -134.10458374023438,
      "loss": 0.0010972190648317337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0169684886932373,
      "rewards/margins": 7.435845851898193,
      "rewards/rejected": -6.418877601623535,
      "step": 2230
    },
    {
      "epoch": 2.396039603960396,
      "grad_norm": 0.1437610685825348,
      "learning_rate": 2.662295081967213e-07,
      "logits/chosen": 1.4196970462799072,
      "logits/rejected": 0.3630598783493042,
      "logps/chosen": -147.0176239013672,
      "logps/rejected": -128.65184020996094,
      "loss": 0.002136230655014515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0789644718170166,
      "rewards/margins": 7.117372989654541,
      "rewards/rejected": -6.0384087562561035,
      "step": 2240
    },
    {
      "epoch": 2.4067433770404065,
      "grad_norm": 0.14910036325454712,
      "learning_rate": 2.651366120218579e-07,
      "logits/chosen": 1.4415029287338257,
      "logits/rejected": 0.31818294525146484,
      "logps/chosen": -163.88323974609375,
      "logps/rejected": -130.3768768310547,
      "loss": 0.001702420599758625,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0522578954696655,
      "rewards/margins": 7.214852333068848,
      "rewards/rejected": -6.162593364715576,
      "step": 2250
    },
    {
      "epoch": 2.4174471501204176,
      "grad_norm": 0.22311794757843018,
      "learning_rate": 2.640437158469945e-07,
      "logits/chosen": 1.4360666275024414,
      "logits/rejected": 0.43349188566207886,
      "logps/chosen": -156.05809020996094,
      "logps/rejected": -129.51904296875,
      "loss": 0.0017682841047644616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1817402839660645,
      "rewards/margins": 7.188438415527344,
      "rewards/rejected": -6.006698131561279,
      "step": 2260
    },
    {
      "epoch": 2.428150923200428,
      "grad_norm": 0.0731428787112236,
      "learning_rate": 2.6295081967213114e-07,
      "logits/chosen": 1.4055671691894531,
      "logits/rejected": 0.31137576699256897,
      "logps/chosen": -157.39752197265625,
      "logps/rejected": -132.04556274414062,
      "loss": 0.0015590913593769074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9897921681404114,
      "rewards/margins": 7.276482582092285,
      "rewards/rejected": -6.2866902351379395,
      "step": 2270
    },
    {
      "epoch": 2.4388546962804387,
      "grad_norm": 0.09740659594535828,
      "learning_rate": 2.6185792349726776e-07,
      "logits/chosen": 1.4719464778900146,
      "logits/rejected": 0.4116246700286865,
      "logps/chosen": -163.41323852539062,
      "logps/rejected": -130.07293701171875,
      "loss": 0.002096044272184372,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1566044092178345,
      "rewards/margins": 7.231528282165527,
      "rewards/rejected": -6.074924468994141,
      "step": 2280
    },
    {
      "epoch": 2.4495584693604497,
      "grad_norm": 0.06392665207386017,
      "learning_rate": 2.6076502732240434e-07,
      "logits/chosen": 1.4168246984481812,
      "logits/rejected": 0.3817104399204254,
      "logps/chosen": -148.68722534179688,
      "logps/rejected": -131.76925659179688,
      "loss": 0.0014338122680783271,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0217177867889404,
      "rewards/margins": 7.228528022766113,
      "rewards/rejected": -6.206809997558594,
      "step": 2290
    },
    {
      "epoch": 2.4602622424404603,
      "grad_norm": 0.061757639050483704,
      "learning_rate": 2.59672131147541e-07,
      "logits/chosen": 1.5457544326782227,
      "logits/rejected": 0.4157276749610901,
      "logps/chosen": -160.30531311035156,
      "logps/rejected": -129.63919067382812,
      "loss": 0.00187107902020216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0347309112548828,
      "rewards/margins": 7.101038455963135,
      "rewards/rejected": -6.066307544708252,
      "step": 2300
    },
    {
      "epoch": 2.470966015520471,
      "grad_norm": 0.11825161427259445,
      "learning_rate": 2.585792349726776e-07,
      "logits/chosen": 1.5184224843978882,
      "logits/rejected": 0.47224554419517517,
      "logps/chosen": -164.9349365234375,
      "logps/rejected": -128.02761840820312,
      "loss": 0.002177867479622364,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0453784465789795,
      "rewards/margins": 7.058290004730225,
      "rewards/rejected": -6.012911796569824,
      "step": 2310
    },
    {
      "epoch": 2.4816697886004815,
      "grad_norm": 0.20463116466999054,
      "learning_rate": 2.5748633879781415e-07,
      "logits/chosen": 1.3264789581298828,
      "logits/rejected": 0.35910770297050476,
      "logps/chosen": -137.09979248046875,
      "logps/rejected": -130.822998046875,
      "loss": 0.0017122482880949975,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9176434278488159,
      "rewards/margins": 7.107410430908203,
      "rewards/rejected": -6.189766883850098,
      "step": 2320
    },
    {
      "epoch": 2.4923735616804925,
      "grad_norm": 0.073807492852211,
      "learning_rate": 2.5639344262295083e-07,
      "logits/chosen": 1.352338433265686,
      "logits/rejected": 0.4261421263217926,
      "logps/chosen": -144.44699096679688,
      "logps/rejected": -128.46444702148438,
      "loss": 0.001733328215777874,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0358043909072876,
      "rewards/margins": 7.075602054595947,
      "rewards/rejected": -6.039797782897949,
      "step": 2330
    },
    {
      "epoch": 2.503077334760503,
      "grad_norm": 0.0395825020968914,
      "learning_rate": 2.553005464480874e-07,
      "logits/chosen": 1.2864570617675781,
      "logits/rejected": 0.35723286867141724,
      "logps/chosen": -144.6337127685547,
      "logps/rejected": -132.1907958984375,
      "loss": 0.0016006894409656524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0642096996307373,
      "rewards/margins": 7.341715335845947,
      "rewards/rejected": -6.277505874633789,
      "step": 2340
    },
    {
      "epoch": 2.5137811078405137,
      "grad_norm": 0.08190079778432846,
      "learning_rate": 2.54207650273224e-07,
      "logits/chosen": 1.3776023387908936,
      "logits/rejected": 0.43447309732437134,
      "logps/chosen": -149.21067810058594,
      "logps/rejected": -130.66683959960938,
      "loss": 0.0015737174078822135,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9272316098213196,
      "rewards/margins": 7.07187032699585,
      "rewards/rejected": -6.144639015197754,
      "step": 2350
    },
    {
      "epoch": 2.5244848809205243,
      "grad_norm": 0.10082387924194336,
      "learning_rate": 2.5311475409836065e-07,
      "logits/chosen": 1.4553072452545166,
      "logits/rejected": 0.3338549733161926,
      "logps/chosen": -154.40956115722656,
      "logps/rejected": -131.1110382080078,
      "loss": 0.001677238941192627,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.043515920639038,
      "rewards/margins": 7.279405117034912,
      "rewards/rejected": -6.235888481140137,
      "step": 2360
    },
    {
      "epoch": 2.5351886540005353,
      "grad_norm": 0.06132872402667999,
      "learning_rate": 2.520218579234973e-07,
      "logits/chosen": 1.3557984828948975,
      "logits/rejected": 0.2701389491558075,
      "logps/chosen": -157.4830780029297,
      "logps/rejected": -132.72909545898438,
      "loss": 0.0011805147863924504,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.087921142578125,
      "rewards/margins": 7.455875396728516,
      "rewards/rejected": -6.367955207824707,
      "step": 2370
    },
    {
      "epoch": 2.545892427080546,
      "grad_norm": 0.18252217769622803,
      "learning_rate": 2.509289617486339e-07,
      "logits/chosen": 1.4372844696044922,
      "logits/rejected": 0.37789681553840637,
      "logps/chosen": -150.11648559570312,
      "logps/rejected": -131.24008178710938,
      "loss": 0.0017593327909708023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0821843147277832,
      "rewards/margins": 7.282479286193848,
      "rewards/rejected": -6.200294494628906,
      "step": 2380
    },
    {
      "epoch": 2.5565962001605564,
      "grad_norm": 0.02553616277873516,
      "learning_rate": 2.4983606557377047e-07,
      "logits/chosen": 1.3674862384796143,
      "logits/rejected": 0.3069154620170593,
      "logps/chosen": -147.93479919433594,
      "logps/rejected": -132.1847686767578,
      "loss": 0.0013555509969592095,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0621570348739624,
      "rewards/margins": 7.465563774108887,
      "rewards/rejected": -6.403406620025635,
      "step": 2390
    },
    {
      "epoch": 2.5672999732405675,
      "grad_norm": 0.08190543204545975,
      "learning_rate": 2.487431693989071e-07,
      "logits/chosen": 1.4202816486358643,
      "logits/rejected": 0.2469005584716797,
      "logps/chosen": -152.03492736816406,
      "logps/rejected": -134.2154083251953,
      "loss": 0.0013185416348278523,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9964098930358887,
      "rewards/margins": 7.4769744873046875,
      "rewards/rejected": -6.480564117431641,
      "step": 2400
    },
    {
      "epoch": 2.578003746320578,
      "grad_norm": 0.05092169716954231,
      "learning_rate": 2.476502732240437e-07,
      "logits/chosen": 1.4432039260864258,
      "logits/rejected": 0.35985127091407776,
      "logps/chosen": -157.9288330078125,
      "logps/rejected": -129.38653564453125,
      "loss": 0.0017556754872202873,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9383500218391418,
      "rewards/margins": 7.075870513916016,
      "rewards/rejected": -6.137520790100098,
      "step": 2410
    },
    {
      "epoch": 2.5887075194005886,
      "grad_norm": 0.18996931612491608,
      "learning_rate": 2.465573770491803e-07,
      "logits/chosen": 1.3961677551269531,
      "logits/rejected": 0.39505141973495483,
      "logps/chosen": -143.53919982910156,
      "logps/rejected": -131.26437377929688,
      "loss": 0.001837942749261856,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0440036058425903,
      "rewards/margins": 7.2558441162109375,
      "rewards/rejected": -6.211840629577637,
      "step": 2420
    },
    {
      "epoch": 2.5994112924805997,
      "grad_norm": 0.217439204454422,
      "learning_rate": 2.454644808743169e-07,
      "logits/chosen": 1.3865880966186523,
      "logits/rejected": 0.3276696801185608,
      "logps/chosen": -159.03355407714844,
      "logps/rejected": -130.02320861816406,
      "loss": 0.0015603953041136264,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.004675030708313,
      "rewards/margins": 7.26254415512085,
      "rewards/rejected": -6.257868766784668,
      "step": 2430
    },
    {
      "epoch": 2.6101150655606102,
      "grad_norm": 0.07252683490514755,
      "learning_rate": 2.4437158469945354e-07,
      "logits/chosen": 1.4700813293457031,
      "logits/rejected": 0.3398721516132355,
      "logps/chosen": -160.94483947753906,
      "logps/rejected": -132.1984100341797,
      "loss": 0.0014938943088054657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.116411566734314,
      "rewards/margins": 7.519791603088379,
      "rewards/rejected": -6.403380393981934,
      "step": 2440
    },
    {
      "epoch": 2.620818838640621,
      "grad_norm": 0.8521761894226074,
      "learning_rate": 2.4327868852459016e-07,
      "logits/chosen": 1.4683873653411865,
      "logits/rejected": 0.44725799560546875,
      "logps/chosen": -154.01055908203125,
      "logps/rejected": -129.57501220703125,
      "loss": 0.0024119336158037186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9759869575500488,
      "rewards/margins": 7.129585266113281,
      "rewards/rejected": -6.153597831726074,
      "step": 2450
    },
    {
      "epoch": 2.6315226117206314,
      "grad_norm": 0.04723334312438965,
      "learning_rate": 2.421857923497268e-07,
      "logits/chosen": 1.4687845706939697,
      "logits/rejected": 0.3482603132724762,
      "logps/chosen": -145.33413696289062,
      "logps/rejected": -131.9952850341797,
      "loss": 0.001712034083902836,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0652588605880737,
      "rewards/margins": 7.3961029052734375,
      "rewards/rejected": -6.330843925476074,
      "step": 2460
    },
    {
      "epoch": 2.642226384800642,
      "grad_norm": 0.09542732685804367,
      "learning_rate": 2.4109289617486335e-07,
      "logits/chosen": 1.4773021936416626,
      "logits/rejected": 0.3987479507923126,
      "logps/chosen": -162.78179931640625,
      "logps/rejected": -129.91183471679688,
      "loss": 0.0017813317477703094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.056641697883606,
      "rewards/margins": 7.277483940124512,
      "rewards/rejected": -6.2208428382873535,
      "step": 2470
    },
    {
      "epoch": 2.652930157880653,
      "grad_norm": 0.10328639298677444,
      "learning_rate": 2.4e-07,
      "logits/chosen": 1.460559606552124,
      "logits/rejected": 0.44715040922164917,
      "logps/chosen": -158.87786865234375,
      "logps/rejected": -131.51150512695312,
      "loss": 0.0015994226559996605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0872597694396973,
      "rewards/margins": 7.363691806793213,
      "rewards/rejected": -6.276432514190674,
      "step": 2480
    },
    {
      "epoch": 2.6636339309606636,
      "grad_norm": 0.045674122869968414,
      "learning_rate": 2.389071038251366e-07,
      "logits/chosen": 1.3594434261322021,
      "logits/rejected": 0.3776792287826538,
      "logps/chosen": -158.58352661132812,
      "logps/rejected": -131.0664825439453,
      "loss": 0.0013723330572247504,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9762717485427856,
      "rewards/margins": 7.2126641273498535,
      "rewards/rejected": -6.236393451690674,
      "step": 2490
    },
    {
      "epoch": 2.674337704040674,
      "grad_norm": 0.08663913607597351,
      "learning_rate": 2.378142076502732e-07,
      "logits/chosen": 1.4392590522766113,
      "logits/rejected": 0.21909573674201965,
      "logps/chosen": -161.03451538085938,
      "logps/rejected": -136.25338745117188,
      "loss": 0.0011911553330719471,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0264298915863037,
      "rewards/margins": 7.5975341796875,
      "rewards/rejected": -6.571104526519775,
      "step": 2500
    },
    {
      "epoch": 2.685041477120685,
      "grad_norm": 0.08220118284225464,
      "learning_rate": 2.3672131147540982e-07,
      "logits/chosen": 1.3998324871063232,
      "logits/rejected": 0.43823617696762085,
      "logps/chosen": -146.97451782226562,
      "logps/rejected": -130.1543731689453,
      "loss": 0.001526074856519699,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0659743547439575,
      "rewards/margins": 7.2809929847717285,
      "rewards/rejected": -6.215018272399902,
      "step": 2510
    },
    {
      "epoch": 2.6957452502006958,
      "grad_norm": 0.11399703472852707,
      "learning_rate": 2.3562841530054645e-07,
      "logits/chosen": 1.4145904779434204,
      "logits/rejected": 0.3096591532230377,
      "logps/chosen": -148.1929931640625,
      "logps/rejected": -133.46054077148438,
      "loss": 0.0012124990113079547,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0607208013534546,
      "rewards/margins": 7.491607666015625,
      "rewards/rejected": -6.430886745452881,
      "step": 2520
    },
    {
      "epoch": 2.7064490232807064,
      "grad_norm": 0.041627250611782074,
      "learning_rate": 2.3453551912568307e-07,
      "logits/chosen": 1.4849954843521118,
      "logits/rejected": 0.38977915048599243,
      "logps/chosen": -163.3440399169922,
      "logps/rejected": -131.143798828125,
      "loss": 0.0015512733720242978,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.050400972366333,
      "rewards/margins": 7.33310079574585,
      "rewards/rejected": -6.2826995849609375,
      "step": 2530
    },
    {
      "epoch": 2.7171527963607174,
      "grad_norm": 0.061605487018823624,
      "learning_rate": 2.3344262295081964e-07,
      "logits/chosen": 1.3838915824890137,
      "logits/rejected": 0.2962495982646942,
      "logps/chosen": -149.92138671875,
      "logps/rejected": -132.9580841064453,
      "loss": 0.0011889436282217503,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0692601203918457,
      "rewards/margins": 7.561139106750488,
      "rewards/rejected": -6.491879463195801,
      "step": 2540
    },
    {
      "epoch": 2.727856569440728,
      "grad_norm": 0.024882197380065918,
      "learning_rate": 2.3234972677595627e-07,
      "logits/chosen": 1.4283766746520996,
      "logits/rejected": 0.31500881910324097,
      "logps/chosen": -139.15676879882812,
      "logps/rejected": -136.13038635253906,
      "loss": 0.001385917142033577,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0060489177703857,
      "rewards/margins": 7.575831413269043,
      "rewards/rejected": -6.5697832107543945,
      "step": 2550
    },
    {
      "epoch": 2.7385603425207385,
      "grad_norm": 0.03216307982802391,
      "learning_rate": 2.312568306010929e-07,
      "logits/chosen": 1.384592890739441,
      "logits/rejected": 0.19787277281284332,
      "logps/chosen": -155.83551025390625,
      "logps/rejected": -136.05982971191406,
      "loss": 0.0009172103367745876,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9675631523132324,
      "rewards/margins": 7.643060207366943,
      "rewards/rejected": -6.675496578216553,
      "step": 2560
    },
    {
      "epoch": 2.749264115600749,
      "grad_norm": 0.1358180046081543,
      "learning_rate": 2.301639344262295e-07,
      "logits/chosen": 1.3461244106292725,
      "logits/rejected": 0.2986530661582947,
      "logps/chosen": -149.1336212158203,
      "logps/rejected": -131.82815551757812,
      "loss": 0.001626046560704708,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.955544650554657,
      "rewards/margins": 7.353311061859131,
      "rewards/rejected": -6.397767543792725,
      "step": 2570
    },
    {
      "epoch": 2.7599678886807597,
      "grad_norm": 0.059655699878931046,
      "learning_rate": 2.290710382513661e-07,
      "logits/chosen": 1.4769699573516846,
      "logits/rejected": 0.25667768716812134,
      "logps/chosen": -150.21739196777344,
      "logps/rejected": -135.5801239013672,
      "loss": 0.0010894158855080604,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1298859119415283,
      "rewards/margins": 7.703250885009766,
      "rewards/rejected": -6.573365211486816,
      "step": 2580
    },
    {
      "epoch": 2.7706716617607707,
      "grad_norm": 0.053861938416957855,
      "learning_rate": 2.2797814207650274e-07,
      "logits/chosen": 1.4233338832855225,
      "logits/rejected": 0.27503737807273865,
      "logps/chosen": -161.35455322265625,
      "logps/rejected": -135.04647827148438,
      "loss": 0.0015503817237913608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.878516674041748,
      "rewards/margins": 7.406491756439209,
      "rewards/rejected": -6.527974605560303,
      "step": 2590
    },
    {
      "epoch": 2.7813754348407813,
      "grad_norm": 0.03149458393454552,
      "learning_rate": 2.2688524590163933e-07,
      "logits/chosen": 1.3263460397720337,
      "logits/rejected": 0.34402936697006226,
      "logps/chosen": -143.95736694335938,
      "logps/rejected": -133.1340789794922,
      "loss": 0.0012823313474655152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1012637615203857,
      "rewards/margins": 7.517685890197754,
      "rewards/rejected": -6.416421413421631,
      "step": 2600
    },
    {
      "epoch": 2.792079207920792,
      "grad_norm": 0.03977327421307564,
      "learning_rate": 2.2579234972677593e-07,
      "logits/chosen": 1.3519132137298584,
      "logits/rejected": 0.2674644887447357,
      "logps/chosen": -150.5478973388672,
      "logps/rejected": -133.7169189453125,
      "loss": 0.001420989166945219,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9341778755187988,
      "rewards/margins": 7.445925712585449,
      "rewards/rejected": -6.51174783706665,
      "step": 2610
    },
    {
      "epoch": 2.802782981000803,
      "grad_norm": 0.11827335506677628,
      "learning_rate": 2.2469945355191255e-07,
      "logits/chosen": 1.4485546350479126,
      "logits/rejected": 0.22729626297950745,
      "logps/chosen": -156.72422790527344,
      "logps/rejected": -135.46841430664062,
      "loss": 0.0011503518559038638,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9866806268692017,
      "rewards/margins": 7.597064971923828,
      "rewards/rejected": -6.6103835105896,
      "step": 2620
    },
    {
      "epoch": 2.8134867540808135,
      "grad_norm": 0.05551517754793167,
      "learning_rate": 2.2360655737704918e-07,
      "logits/chosen": 1.402062177658081,
      "logits/rejected": 0.3137304186820984,
      "logps/chosen": -147.85623168945312,
      "logps/rejected": -134.7406005859375,
      "loss": 0.0014031649567186832,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0305252075195312,
      "rewards/margins": 7.5493879318237305,
      "rewards/rejected": -6.518862724304199,
      "step": 2630
    },
    {
      "epoch": 2.824190527160824,
      "grad_norm": 0.04605426639318466,
      "learning_rate": 2.2251366120218578e-07,
      "logits/chosen": 1.263906717300415,
      "logits/rejected": 0.2715092897415161,
      "logps/chosen": -140.29129028320312,
      "logps/rejected": -133.44009399414062,
      "loss": 0.0010702157393097877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.042933464050293,
      "rewards/margins": 7.543398380279541,
      "rewards/rejected": -6.50046443939209,
      "step": 2640
    },
    {
      "epoch": 2.834894300240835,
      "grad_norm": 0.08103284984827042,
      "learning_rate": 2.214207650273224e-07,
      "logits/chosen": 1.5036649703979492,
      "logits/rejected": 0.3892868161201477,
      "logps/chosen": -145.29022216796875,
      "logps/rejected": -132.0996551513672,
      "loss": 0.001267877034842968,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1107561588287354,
      "rewards/margins": 7.506967067718506,
      "rewards/rejected": -6.39621114730835,
      "step": 2650
    },
    {
      "epoch": 2.8455980733208457,
      "grad_norm": 0.04292810335755348,
      "learning_rate": 2.2032786885245902e-07,
      "logits/chosen": 1.4266360998153687,
      "logits/rejected": 0.3878295421600342,
      "logps/chosen": -156.16177368164062,
      "logps/rejected": -132.0513458251953,
      "loss": 0.001585768535733223,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9789655804634094,
      "rewards/margins": 7.360363006591797,
      "rewards/rejected": -6.381397247314453,
      "step": 2660
    },
    {
      "epoch": 2.8563018464008563,
      "grad_norm": 0.05300240218639374,
      "learning_rate": 2.1923497267759562e-07,
      "logits/chosen": 1.4217418432235718,
      "logits/rejected": 0.39727503061294556,
      "logps/chosen": -154.20602416992188,
      "logps/rejected": -133.3855438232422,
      "loss": 0.0016531476750969887,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9965037107467651,
      "rewards/margins": 7.329445838928223,
      "rewards/rejected": -6.332942008972168,
      "step": 2670
    },
    {
      "epoch": 2.867005619480867,
      "grad_norm": 0.038425054401159286,
      "learning_rate": 2.1814207650273222e-07,
      "logits/chosen": 1.4403005838394165,
      "logits/rejected": 0.3128736913204193,
      "logps/chosen": -154.15708923339844,
      "logps/rejected": -134.17141723632812,
      "loss": 0.0010083511471748352,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0946711301803589,
      "rewards/margins": 7.56723165512085,
      "rewards/rejected": -6.472559928894043,
      "step": 2680
    },
    {
      "epoch": 2.8777093925608774,
      "grad_norm": 0.0615348294377327,
      "learning_rate": 2.1704918032786884e-07,
      "logits/chosen": 1.3261168003082275,
      "logits/rejected": 0.3124733865261078,
      "logps/chosen": -153.635986328125,
      "logps/rejected": -134.09945678710938,
      "loss": 0.000988207571208477,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.121828556060791,
      "rewards/margins": 7.673275947570801,
      "rewards/rejected": -6.551446437835693,
      "step": 2690
    },
    {
      "epoch": 2.8884131656408885,
      "grad_norm": 0.0643053650856018,
      "learning_rate": 2.1595628415300547e-07,
      "logits/chosen": 1.4643746614456177,
      "logits/rejected": 0.3066936135292053,
      "logps/chosen": -156.10214233398438,
      "logps/rejected": -134.61904907226562,
      "loss": 0.0011613748967647553,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9515478014945984,
      "rewards/margins": 7.554879665374756,
      "rewards/rejected": -6.60333251953125,
      "step": 2700
    },
    {
      "epoch": 2.899116938720899,
      "grad_norm": 0.03419085592031479,
      "learning_rate": 2.1486338797814206e-07,
      "logits/chosen": 1.438122034072876,
      "logits/rejected": 0.18847915530204773,
      "logps/chosen": -152.81793212890625,
      "logps/rejected": -136.8616943359375,
      "loss": 0.0007761525455862283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9996164441108704,
      "rewards/margins": 7.739602088928223,
      "rewards/rejected": -6.739985466003418,
      "step": 2710
    },
    {
      "epoch": 2.9098207118009096,
      "grad_norm": 0.01778268627822399,
      "learning_rate": 2.137704918032787e-07,
      "logits/chosen": 1.3492761850357056,
      "logits/rejected": 0.23993143439292908,
      "logps/chosen": -146.633056640625,
      "logps/rejected": -136.35848999023438,
      "loss": 0.0011082227341830731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.098083257675171,
      "rewards/margins": 7.804947853088379,
      "rewards/rejected": -6.706864356994629,
      "step": 2720
    },
    {
      "epoch": 2.9205244848809206,
      "grad_norm": 0.07054761052131653,
      "learning_rate": 2.1267759562841529e-07,
      "logits/chosen": 1.3855574131011963,
      "logits/rejected": 0.37239235639572144,
      "logps/chosen": -149.73501586914062,
      "logps/rejected": -132.35513305664062,
      "loss": 0.001573931984603405,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9713371396064758,
      "rewards/margins": 7.432826042175293,
      "rewards/rejected": -6.461489200592041,
      "step": 2730
    },
    {
      "epoch": 2.9312282579609312,
      "grad_norm": 0.1001250147819519,
      "learning_rate": 2.1158469945355188e-07,
      "logits/chosen": 1.4063754081726074,
      "logits/rejected": 0.36440515518188477,
      "logps/chosen": -144.05972290039062,
      "logps/rejected": -134.09130859375,
      "loss": 0.0013117991387844087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.066323161125183,
      "rewards/margins": 7.518584251403809,
      "rewards/rejected": -6.452261447906494,
      "step": 2740
    },
    {
      "epoch": 2.941932031040942,
      "grad_norm": 0.023092586547136307,
      "learning_rate": 2.104918032786885e-07,
      "logits/chosen": 1.4943186044692993,
      "logits/rejected": 0.19617865979671478,
      "logps/chosen": -160.7129364013672,
      "logps/rejected": -136.38577270507812,
      "loss": 0.0013701828196644784,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9478135108947754,
      "rewards/margins": 7.696821689605713,
      "rewards/rejected": -6.749009132385254,
      "step": 2750
    },
    {
      "epoch": 2.952635804120953,
      "grad_norm": 0.06432575732469559,
      "learning_rate": 2.0939890710382513e-07,
      "logits/chosen": 1.4706989526748657,
      "logits/rejected": 0.2465389221906662,
      "logps/chosen": -150.32351684570312,
      "logps/rejected": -136.71827697753906,
      "loss": 0.000951099768280983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8867028951644897,
      "rewards/margins": 7.625602722167969,
      "rewards/rejected": -6.738900661468506,
      "step": 2760
    },
    {
      "epoch": 2.9633395772009634,
      "grad_norm": 0.04613935574889183,
      "learning_rate": 2.0830601092896175e-07,
      "logits/chosen": 1.3570219278335571,
      "logits/rejected": 0.23818866908550262,
      "logps/chosen": -140.64239501953125,
      "logps/rejected": -136.9703369140625,
      "loss": 0.0009662887081503868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0489447116851807,
      "rewards/margins": 7.883837699890137,
      "rewards/rejected": -6.834893703460693,
      "step": 2770
    },
    {
      "epoch": 2.974043350280974,
      "grad_norm": 0.05503687262535095,
      "learning_rate": 2.0721311475409835e-07,
      "logits/chosen": 1.412192940711975,
      "logits/rejected": 0.2016412913799286,
      "logps/chosen": -153.32998657226562,
      "logps/rejected": -136.9432830810547,
      "loss": 0.001353878527879715,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.830988883972168,
      "rewards/margins": 7.6157941818237305,
      "rewards/rejected": -6.7848052978515625,
      "step": 2780
    },
    {
      "epoch": 2.984747123360985,
      "grad_norm": 0.09824024885892868,
      "learning_rate": 2.0612021857923495e-07,
      "logits/chosen": 1.3086819648742676,
      "logits/rejected": 0.24653713405132294,
      "logps/chosen": -145.84576416015625,
      "logps/rejected": -135.62765502929688,
      "loss": 0.0011718083173036576,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0205587148666382,
      "rewards/margins": 7.692143440246582,
      "rewards/rejected": -6.6715850830078125,
      "step": 2790
    },
    {
      "epoch": 2.9954508964409956,
      "grad_norm": 0.03917043283581734,
      "learning_rate": 2.0502732240437157e-07,
      "logits/chosen": 1.4392099380493164,
      "logits/rejected": 0.19929897785186768,
      "logps/chosen": -153.95254516601562,
      "logps/rejected": -138.0480194091797,
      "loss": 0.0008966853842139244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0493642091751099,
      "rewards/margins": 7.9137725830078125,
      "rewards/rejected": -6.86440896987915,
      "step": 2800
    },
    {
      "epoch": 3.0053518865400055,
      "grad_norm": 0.07306501269340515,
      "learning_rate": 2.0393442622950817e-07,
      "logits/chosen": 1.3453344106674194,
      "logits/rejected": 0.20074953138828278,
      "logps/chosen": -153.29583740234375,
      "logps/rejected": -138.13360595703125,
      "loss": 0.0008855184540152549,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0242849588394165,
      "rewards/margins": 7.880162239074707,
      "rewards/rejected": -6.85587739944458,
      "step": 2810
    },
    {
      "epoch": 3.016055659620016,
      "grad_norm": 0.05407831072807312,
      "learning_rate": 2.028415300546448e-07,
      "logits/chosen": 1.3907968997955322,
      "logits/rejected": 0.22868072986602783,
      "logps/chosen": -152.90216064453125,
      "logps/rejected": -135.76083374023438,
      "loss": 0.001335266325622797,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9671109914779663,
      "rewards/margins": 7.659773349761963,
      "rewards/rejected": -6.692661285400391,
      "step": 2820
    },
    {
      "epoch": 3.0267594327000267,
      "grad_norm": 0.0697435587644577,
      "learning_rate": 2.0174863387978142e-07,
      "logits/chosen": 1.465245246887207,
      "logits/rejected": 0.25784236192703247,
      "logps/chosen": -162.23802185058594,
      "logps/rejected": -134.8216094970703,
      "loss": 0.0010332504287362098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0200799703598022,
      "rewards/margins": 7.704682350158691,
      "rewards/rejected": -6.6846022605896,
      "step": 2830
    },
    {
      "epoch": 3.0374632057800373,
      "grad_norm": 0.0379030704498291,
      "learning_rate": 2.0065573770491804e-07,
      "logits/chosen": 1.4530431032180786,
      "logits/rejected": 0.23694109916687012,
      "logps/chosen": -156.1997528076172,
      "logps/rejected": -137.98922729492188,
      "loss": 0.0007155921775847673,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1732845306396484,
      "rewards/margins": 8.034769058227539,
      "rewards/rejected": -6.861485481262207,
      "step": 2840
    },
    {
      "epoch": 3.0481669788600483,
      "grad_norm": 0.02535276673734188,
      "learning_rate": 1.9956284153005464e-07,
      "logits/chosen": 1.3654245138168335,
      "logits/rejected": 0.1342659443616867,
      "logps/chosen": -149.31161499023438,
      "logps/rejected": -140.00355529785156,
      "loss": 0.0007596140261739492,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0595147609710693,
      "rewards/margins": 8.036767959594727,
      "rewards/rejected": -6.9772539138793945,
      "step": 2850
    },
    {
      "epoch": 3.058870751940059,
      "grad_norm": 0.024452507495880127,
      "learning_rate": 1.9846994535519124e-07,
      "logits/chosen": 1.3572235107421875,
      "logits/rejected": 0.14207907021045685,
      "logps/chosen": -141.69406127929688,
      "logps/rejected": -139.0668487548828,
      "loss": 0.000905858539044857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.07387375831604,
      "rewards/margins": 8.076395034790039,
      "rewards/rejected": -7.002520561218262,
      "step": 2860
    },
    {
      "epoch": 3.0695745250200694,
      "grad_norm": 0.10602739453315735,
      "learning_rate": 1.9737704918032786e-07,
      "logits/chosen": 1.4127576351165771,
      "logits/rejected": 0.23398180305957794,
      "logps/chosen": -141.50405883789062,
      "logps/rejected": -137.01231384277344,
      "loss": 0.000951547920703888,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9896615743637085,
      "rewards/margins": 7.787043571472168,
      "rewards/rejected": -6.797382354736328,
      "step": 2870
    },
    {
      "epoch": 3.0802782981000805,
      "grad_norm": 0.048557985574007034,
      "learning_rate": 1.9628415300546446e-07,
      "logits/chosen": 1.3577474355697632,
      "logits/rejected": 0.16123120486736298,
      "logps/chosen": -143.1715087890625,
      "logps/rejected": -140.1159210205078,
      "loss": 0.0007595416624099016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9894289970397949,
      "rewards/margins": 7.9409284591674805,
      "rewards/rejected": -6.951499938964844,
      "step": 2880
    },
    {
      "epoch": 3.090982071180091,
      "grad_norm": 0.05108559504151344,
      "learning_rate": 1.9519125683060108e-07,
      "logits/chosen": 1.412472128868103,
      "logits/rejected": 0.15658894181251526,
      "logps/chosen": -153.177734375,
      "logps/rejected": -137.45150756835938,
      "loss": 0.0009144015610218048,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9828529357910156,
      "rewards/margins": 7.897230625152588,
      "rewards/rejected": -6.914377689361572,
      "step": 2890
    },
    {
      "epoch": 3.1016858442601016,
      "grad_norm": 0.18194347620010376,
      "learning_rate": 1.940983606557377e-07,
      "logits/chosen": 1.3226845264434814,
      "logits/rejected": 0.3481005132198334,
      "logps/chosen": -149.9387664794922,
      "logps/rejected": -134.02182006835938,
      "loss": 0.001439474243670702,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9508253931999207,
      "rewards/margins": 7.493794918060303,
      "rewards/rejected": -6.542970180511475,
      "step": 2900
    },
    {
      "epoch": 3.112389617340112,
      "grad_norm": 0.0353451631963253,
      "learning_rate": 1.9300546448087433e-07,
      "logits/chosen": 1.3578355312347412,
      "logits/rejected": 0.19054996967315674,
      "logps/chosen": -146.86343383789062,
      "logps/rejected": -138.37557983398438,
      "loss": 0.0007422524038702249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.105670690536499,
      "rewards/margins": 8.034211158752441,
      "rewards/rejected": -6.9285407066345215,
      "step": 2910
    },
    {
      "epoch": 3.1230933904201232,
      "grad_norm": 0.051051005721092224,
      "learning_rate": 1.919125683060109e-07,
      "logits/chosen": 1.3748080730438232,
      "logits/rejected": 0.24877901375293732,
      "logps/chosen": -150.80996704101562,
      "logps/rejected": -136.74111938476562,
      "loss": 0.0010891648009419442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.993590235710144,
      "rewards/margins": 7.796212673187256,
      "rewards/rejected": -6.8026227951049805,
      "step": 2920
    },
    {
      "epoch": 3.133797163500134,
      "grad_norm": 0.1417771726846695,
      "learning_rate": 1.9081967213114753e-07,
      "logits/chosen": 1.5456105470657349,
      "logits/rejected": 0.2162286788225174,
      "logps/chosen": -172.15567016601562,
      "logps/rejected": -136.17251586914062,
      "loss": 0.0011463158763945103,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0289617776870728,
      "rewards/margins": 7.841347694396973,
      "rewards/rejected": -6.812384605407715,
      "step": 2930
    },
    {
      "epoch": 3.1445009365801444,
      "grad_norm": 0.0779951885342598,
      "learning_rate": 1.8972677595628415e-07,
      "logits/chosen": 1.4109731912612915,
      "logits/rejected": 0.28736773133277893,
      "logps/chosen": -157.33998107910156,
      "logps/rejected": -135.96609497070312,
      "loss": 0.0013140220195055007,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8560997247695923,
      "rewards/margins": 7.545416355133057,
      "rewards/rejected": -6.6893181800842285,
      "step": 2940
    },
    {
      "epoch": 3.155204709660155,
      "grad_norm": 0.018169889226555824,
      "learning_rate": 1.8863387978142075e-07,
      "logits/chosen": 1.340767741203308,
      "logits/rejected": 0.13973937928676605,
      "logps/chosen": -150.49595642089844,
      "logps/rejected": -139.36727905273438,
      "loss": 0.000827804859727621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0460779666900635,
      "rewards/margins": 8.017906188964844,
      "rewards/rejected": -6.971828460693359,
      "step": 2950
    },
    {
      "epoch": 3.165908482740166,
      "grad_norm": 0.11501125246286392,
      "learning_rate": 1.8754098360655737e-07,
      "logits/chosen": 1.4050424098968506,
      "logits/rejected": 0.23516826331615448,
      "logps/chosen": -155.10397338867188,
      "logps/rejected": -138.45614624023438,
      "loss": 0.0007658227346837521,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0967423915863037,
      "rewards/margins": 8.036796569824219,
      "rewards/rejected": -6.940054893493652,
      "step": 2960
    },
    {
      "epoch": 3.1766122558201766,
      "grad_norm": 0.12487789243459702,
      "learning_rate": 1.86448087431694e-07,
      "logits/chosen": 1.3662388324737549,
      "logits/rejected": 0.23212496936321259,
      "logps/chosen": -144.45663452148438,
      "logps/rejected": -137.21878051757812,
      "loss": 0.000994386151432991,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9875888824462891,
      "rewards/margins": 7.827722072601318,
      "rewards/rejected": -6.8401336669921875,
      "step": 2970
    },
    {
      "epoch": 3.187316028900187,
      "grad_norm": 0.041483547538518906,
      "learning_rate": 1.8535519125683062e-07,
      "logits/chosen": 1.3801648616790771,
      "logits/rejected": 0.31395405530929565,
      "logps/chosen": -145.80364990234375,
      "logps/rejected": -134.97607421875,
      "loss": 0.0010814500972628593,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.916144073009491,
      "rewards/margins": 7.596430778503418,
      "rewards/rejected": -6.6802873611450195,
      "step": 2980
    },
    {
      "epoch": 3.198019801980198,
      "grad_norm": 0.051093172281980515,
      "learning_rate": 1.842622950819672e-07,
      "logits/chosen": 1.3161920309066772,
      "logits/rejected": 0.12881137430667877,
      "logps/chosen": -146.6739959716797,
      "logps/rejected": -140.36019897460938,
      "loss": 0.0008965736255049705,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7939932942390442,
      "rewards/margins": 7.836361885070801,
      "rewards/rejected": -7.042367458343506,
      "step": 2990
    },
    {
      "epoch": 3.2087235750602088,
      "grad_norm": 0.013972664251923561,
      "learning_rate": 1.8316939890710381e-07,
      "logits/chosen": 1.2497408390045166,
      "logits/rejected": 0.17120519280433655,
      "logps/chosen": -139.9951629638672,
      "logps/rejected": -141.63055419921875,
      "loss": 0.0008666974492371083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8816238641738892,
      "rewards/margins": 8.016022682189941,
      "rewards/rejected": -7.1343994140625,
      "step": 3000
    },
    {
      "epoch": 3.2194273481402194,
      "grad_norm": 0.12386574596166611,
      "learning_rate": 1.8207650273224044e-07,
      "logits/chosen": 1.3447648286819458,
      "logits/rejected": 0.13457408547401428,
      "logps/chosen": -155.39157104492188,
      "logps/rejected": -139.49417114257812,
      "loss": 0.0008857903070747852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.052390217781067,
      "rewards/margins": 8.031548500061035,
      "rewards/rejected": -6.979158878326416,
      "step": 3010
    },
    {
      "epoch": 3.23013112122023,
      "grad_norm": 0.044015269726514816,
      "learning_rate": 1.8098360655737704e-07,
      "logits/chosen": 1.3431670665740967,
      "logits/rejected": 0.19663798809051514,
      "logps/chosen": -156.30245971679688,
      "logps/rejected": -136.9835662841797,
      "loss": 0.0009803721681237222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9257987141609192,
      "rewards/margins": 7.774540901184082,
      "rewards/rejected": -6.8487420082092285,
      "step": 3020
    },
    {
      "epoch": 3.240834894300241,
      "grad_norm": 0.05780787765979767,
      "learning_rate": 1.7989071038251366e-07,
      "logits/chosen": 1.4110243320465088,
      "logits/rejected": 0.248287633061409,
      "logps/chosen": -160.62429809570312,
      "logps/rejected": -135.02395629882812,
      "loss": 0.0008217799477279186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.028991937637329,
      "rewards/margins": 7.765312194824219,
      "rewards/rejected": -6.736320495605469,
      "step": 3030
    },
    {
      "epoch": 3.2515386673802515,
      "grad_norm": 0.0263589546084404,
      "learning_rate": 1.7879781420765028e-07,
      "logits/chosen": 1.3401482105255127,
      "logits/rejected": 0.16843543946743011,
      "logps/chosen": -144.23228454589844,
      "logps/rejected": -140.0468292236328,
      "loss": 0.0009124640375375748,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.990035355091095,
      "rewards/margins": 8.034244537353516,
      "rewards/rejected": -7.0442094802856445,
      "step": 3040
    },
    {
      "epoch": 3.262242440460262,
      "grad_norm": 0.032886289060115814,
      "learning_rate": 1.7770491803278685e-07,
      "logits/chosen": 1.4632364511489868,
      "logits/rejected": 0.1556113064289093,
      "logps/chosen": -160.3662872314453,
      "logps/rejected": -139.92898559570312,
      "loss": 0.0010319557040929794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.822860062122345,
      "rewards/margins": 7.9343414306640625,
      "rewards/rejected": -7.111480712890625,
      "step": 3050
    },
    {
      "epoch": 3.2729462135402727,
      "grad_norm": 0.10872314870357513,
      "learning_rate": 1.7661202185792348e-07,
      "logits/chosen": 1.337062120437622,
      "logits/rejected": 0.15407732129096985,
      "logps/chosen": -154.75550842285156,
      "logps/rejected": -140.55638122558594,
      "loss": 0.0009108807891607285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9970165491104126,
      "rewards/margins": 8.094816207885742,
      "rewards/rejected": -7.097800254821777,
      "step": 3060
    },
    {
      "epoch": 3.2836499866202837,
      "grad_norm": 0.07217072695493698,
      "learning_rate": 1.755191256830601e-07,
      "logits/chosen": 1.3642915487289429,
      "logits/rejected": 0.3002089858055115,
      "logps/chosen": -150.8215789794922,
      "logps/rejected": -136.12814331054688,
      "loss": 0.0009948529303073883,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1100399494171143,
      "rewards/margins": 7.9358391761779785,
      "rewards/rejected": -6.825799465179443,
      "step": 3070
    },
    {
      "epoch": 3.2943537597002943,
      "grad_norm": 0.02440693974494934,
      "learning_rate": 1.7442622950819673e-07,
      "logits/chosen": 1.3722584247589111,
      "logits/rejected": 0.188883438706398,
      "logps/chosen": -155.87265014648438,
      "logps/rejected": -139.25711059570312,
      "loss": 0.00106011601164937,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8856361508369446,
      "rewards/margins": 7.917356967926025,
      "rewards/rejected": -7.031720161437988,
      "step": 3080
    },
    {
      "epoch": 3.305057532780305,
      "grad_norm": 0.040449850261211395,
      "learning_rate": 1.7333333333333332e-07,
      "logits/chosen": 1.3373944759368896,
      "logits/rejected": 0.14957325160503387,
      "logps/chosen": -150.07521057128906,
      "logps/rejected": -139.87692260742188,
      "loss": 0.0008006785996258259,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9854381680488586,
      "rewards/margins": 8.059715270996094,
      "rewards/rejected": -7.074276924133301,
      "step": 3090
    },
    {
      "epoch": 3.315761305860316,
      "grad_norm": 0.06933362036943436,
      "learning_rate": 1.7224043715846995e-07,
      "logits/chosen": 1.381681203842163,
      "logits/rejected": 0.08400170505046844,
      "logps/chosen": -150.39059448242188,
      "logps/rejected": -140.3887939453125,
      "loss": 0.0009771876037120819,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7745355367660522,
      "rewards/margins": 7.955021858215332,
      "rewards/rejected": -7.180487155914307,
      "step": 3100
    },
    {
      "epoch": 3.3264650789403265,
      "grad_norm": 0.025173813104629517,
      "learning_rate": 1.7114754098360655e-07,
      "logits/chosen": 1.3882275819778442,
      "logits/rejected": 0.21092036366462708,
      "logps/chosen": -154.30149841308594,
      "logps/rejected": -138.20071411132812,
      "loss": 0.0005682646296918392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0514744520187378,
      "rewards/margins": 8.018999099731445,
      "rewards/rejected": -6.967525482177734,
      "step": 3110
    },
    {
      "epoch": 3.337168852020337,
      "grad_norm": 0.03024064004421234,
      "learning_rate": 1.7005464480874314e-07,
      "logits/chosen": 1.373705267906189,
      "logits/rejected": 0.13840773701667786,
      "logps/chosen": -153.0930938720703,
      "logps/rejected": -140.2211151123047,
      "loss": 0.0006726318970322609,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0796796083450317,
      "rewards/margins": 8.220938682556152,
      "rewards/rejected": -7.14125919342041,
      "step": 3120
    },
    {
      "epoch": 3.347872625100348,
      "grad_norm": 0.030711881816387177,
      "learning_rate": 1.6896174863387977e-07,
      "logits/chosen": 1.3762545585632324,
      "logits/rejected": 0.13025788962841034,
      "logps/chosen": -156.73080444335938,
      "logps/rejected": -140.36476135253906,
      "loss": 0.000741528533399105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0261859893798828,
      "rewards/margins": 8.165910720825195,
      "rewards/rejected": -7.139723777770996,
      "step": 3130
    },
    {
      "epoch": 3.3585763981803587,
      "grad_norm": 0.1801358461380005,
      "learning_rate": 1.678688524590164e-07,
      "logits/chosen": 1.2945080995559692,
      "logits/rejected": 0.16376391053199768,
      "logps/chosen": -135.66079711914062,
      "logps/rejected": -141.46868896484375,
      "loss": 0.0009315548464655876,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8754229545593262,
      "rewards/margins": 8.007087707519531,
      "rewards/rejected": -7.131665229797363,
      "step": 3140
    },
    {
      "epoch": 3.3692801712603693,
      "grad_norm": 0.02132701501250267,
      "learning_rate": 1.6677595628415301e-07,
      "logits/chosen": 1.323500394821167,
      "logits/rejected": 0.06305604428052902,
      "logps/chosen": -153.93589782714844,
      "logps/rejected": -142.76742553710938,
      "loss": 0.0005753753706812858,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0272142887115479,
      "rewards/margins": 8.407757759094238,
      "rewards/rejected": -7.380542755126953,
      "step": 3150
    },
    {
      "epoch": 3.37998394434038,
      "grad_norm": 0.0704352930188179,
      "learning_rate": 1.656830601092896e-07,
      "logits/chosen": 1.4081143140792847,
      "logits/rejected": 0.19216440618038177,
      "logps/chosen": -155.4608612060547,
      "logps/rejected": -139.50491333007812,
      "loss": 0.0007335466798394918,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9694738388061523,
      "rewards/margins": 8.018041610717773,
      "rewards/rejected": -7.048569679260254,
      "step": 3160
    },
    {
      "epoch": 3.390687717420391,
      "grad_norm": 0.04921186715364456,
      "learning_rate": 1.6459016393442624e-07,
      "logits/chosen": 1.265989899635315,
      "logits/rejected": 0.17362084984779358,
      "logps/chosen": -144.68893432617188,
      "logps/rejected": -138.7110595703125,
      "loss": 0.0010276378132402896,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9365490674972534,
      "rewards/margins": 7.921327114105225,
      "rewards/rejected": -6.984776973724365,
      "step": 3170
    },
    {
      "epoch": 3.4013914905004015,
      "grad_norm": 0.030974537134170532,
      "learning_rate": 1.6349726775956283e-07,
      "logits/chosen": 1.3023316860198975,
      "logits/rejected": 0.10087017714977264,
      "logps/chosen": -153.59278869628906,
      "logps/rejected": -141.00743103027344,
      "loss": 0.0008394175209105014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9117140769958496,
      "rewards/margins": 8.14505386352539,
      "rewards/rejected": -7.233340263366699,
      "step": 3180
    },
    {
      "epoch": 3.412095263580412,
      "grad_norm": 0.043868936598300934,
      "learning_rate": 1.6240437158469943e-07,
      "logits/chosen": 1.4315309524536133,
      "logits/rejected": 0.139360249042511,
      "logps/chosen": -174.25405883789062,
      "logps/rejected": -140.37948608398438,
      "loss": 0.0015675367787480355,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6954283714294434,
      "rewards/margins": 7.870538234710693,
      "rewards/rejected": -7.175108909606934,
      "step": 3190
    },
    {
      "epoch": 3.4227990366604226,
      "grad_norm": 0.05370011553168297,
      "learning_rate": 1.6131147540983605e-07,
      "logits/chosen": 1.263619303703308,
      "logits/rejected": 0.18145129084587097,
      "logps/chosen": -144.8199462890625,
      "logps/rejected": -141.20994567871094,
      "loss": 0.0008096323348581791,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9202225804328918,
      "rewards/margins": 8.056363105773926,
      "rewards/rejected": -7.1361403465271,
      "step": 3200
    },
    {
      "epoch": 3.4335028097404336,
      "grad_norm": 0.07579374313354492,
      "learning_rate": 1.6021857923497268e-07,
      "logits/chosen": 1.3689098358154297,
      "logits/rejected": 0.04966326430439949,
      "logps/chosen": -145.4207305908203,
      "logps/rejected": -144.044677734375,
      "loss": 0.0009275741875171661,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8584520220756531,
      "rewards/margins": 8.186436653137207,
      "rewards/rejected": -7.327983856201172,
      "step": 3210
    },
    {
      "epoch": 3.4442065828204442,
      "grad_norm": 0.08040694147348404,
      "learning_rate": 1.5912568306010928e-07,
      "logits/chosen": 1.296584129333496,
      "logits/rejected": 0.39012959599494934,
      "logps/chosen": -152.00314331054688,
      "logps/rejected": -135.33395385742188,
      "loss": 0.000987233780324459,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.022450566291809,
      "rewards/margins": 7.706080436706543,
      "rewards/rejected": -6.683630466461182,
      "step": 3220
    },
    {
      "epoch": 3.454910355900455,
      "grad_norm": 0.026637960225343704,
      "learning_rate": 1.580327868852459e-07,
      "logits/chosen": 1.35941481590271,
      "logits/rejected": 0.19521784782409668,
      "logps/chosen": -152.83566284179688,
      "logps/rejected": -139.90740966796875,
      "loss": 0.0007408112287521362,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9669984579086304,
      "rewards/margins": 8.069106101989746,
      "rewards/rejected": -7.102107048034668,
      "step": 3230
    },
    {
      "epoch": 3.465614128980466,
      "grad_norm": 0.02797798253595829,
      "learning_rate": 1.569398907103825e-07,
      "logits/chosen": 1.298931360244751,
      "logits/rejected": 0.06367112696170807,
      "logps/chosen": -140.5823974609375,
      "logps/rejected": -142.4440460205078,
      "loss": 0.0006064673885703087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0719722509384155,
      "rewards/margins": 8.37177848815918,
      "rewards/rejected": -7.299806118011475,
      "step": 3240
    },
    {
      "epoch": 3.4763179020604764,
      "grad_norm": 0.044723402708768845,
      "learning_rate": 1.5584699453551912e-07,
      "logits/chosen": 1.3885643482208252,
      "logits/rejected": 0.21196091175079346,
      "logps/chosen": -148.7043914794922,
      "logps/rejected": -138.56568908691406,
      "loss": 0.0011266423389315605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7469488382339478,
      "rewards/margins": 7.7832207679748535,
      "rewards/rejected": -7.036271572113037,
      "step": 3250
    },
    {
      "epoch": 3.487021675140487,
      "grad_norm": 0.018681934103369713,
      "learning_rate": 1.5475409836065572e-07,
      "logits/chosen": 1.3461050987243652,
      "logits/rejected": 0.09444350004196167,
      "logps/chosen": -157.67184448242188,
      "logps/rejected": -142.96810913085938,
      "loss": 0.0005744044203311205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.939261257648468,
      "rewards/margins": 8.280940055847168,
      "rewards/rejected": -7.341678619384766,
      "step": 3260
    },
    {
      "epoch": 3.4977254482204976,
      "grad_norm": 0.029486551880836487,
      "learning_rate": 1.5366120218579234e-07,
      "logits/chosen": 1.393033742904663,
      "logits/rejected": 0.10492011159658432,
      "logps/chosen": -156.4439239501953,
      "logps/rejected": -142.8816680908203,
      "loss": 0.00041324165649712084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0149706602096558,
      "rewards/margins": 8.415124893188477,
      "rewards/rejected": -7.400154113769531,
      "step": 3270
    },
    {
      "epoch": 3.508429221300508,
      "grad_norm": 0.03972816467285156,
      "learning_rate": 1.5256830601092897e-07,
      "logits/chosen": 1.4552478790283203,
      "logits/rejected": 0.1384682059288025,
      "logps/chosen": -151.90835571289062,
      "logps/rejected": -140.3160400390625,
      "loss": 0.0007622794713824987,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8914521932601929,
      "rewards/margins": 8.11625862121582,
      "rewards/rejected": -7.2248053550720215,
      "step": 3280
    },
    {
      "epoch": 3.519132994380519,
      "grad_norm": 0.014918830245733261,
      "learning_rate": 1.5147540983606556e-07,
      "logits/chosen": 1.3457581996917725,
      "logits/rejected": 0.13077279925346375,
      "logps/chosen": -144.9272918701172,
      "logps/rejected": -142.1326141357422,
      "loss": 0.0005015672650188208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0586097240447998,
      "rewards/margins": 8.297601699829102,
      "rewards/rejected": -7.238991737365723,
      "step": 3290
    },
    {
      "epoch": 3.5298367674605298,
      "grad_norm": 0.040642645210027695,
      "learning_rate": 1.503825136612022e-07,
      "logits/chosen": 1.3603476285934448,
      "logits/rejected": 0.11017434298992157,
      "logps/chosen": -156.5321044921875,
      "logps/rejected": -140.53805541992188,
      "loss": 0.0009866618551313878,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0128068923950195,
      "rewards/margins": 8.179204940795898,
      "rewards/rejected": -7.166398048400879,
      "step": 3300
    },
    {
      "epoch": 3.5405405405405403,
      "grad_norm": 0.014771382324397564,
      "learning_rate": 1.4928961748633879e-07,
      "logits/chosen": 1.306808590888977,
      "logits/rejected": 0.16495618224143982,
      "logps/chosen": -137.95181274414062,
      "logps/rejected": -141.2499542236328,
      "loss": 0.0006500579416751862,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0912683010101318,
      "rewards/margins": 8.263169288635254,
      "rewards/rejected": -7.171900749206543,
      "step": 3310
    },
    {
      "epoch": 3.5512443136205514,
      "grad_norm": 0.0813247412443161,
      "learning_rate": 1.481967213114754e-07,
      "logits/chosen": 1.362910509109497,
      "logits/rejected": 0.1720307320356369,
      "logps/chosen": -149.02760314941406,
      "logps/rejected": -139.27708435058594,
      "loss": 0.0007308508735150099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0650721788406372,
      "rewards/margins": 8.221009254455566,
      "rewards/rejected": -7.155937194824219,
      "step": 3320
    },
    {
      "epoch": 3.561948086700562,
      "grad_norm": 0.049581099301576614,
      "learning_rate": 1.47103825136612e-07,
      "logits/chosen": 1.418919324874878,
      "logits/rejected": 0.11601948738098145,
      "logps/chosen": -154.83743286132812,
      "logps/rejected": -140.60009765625,
      "loss": 0.0005542350467294454,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1629308462142944,
      "rewards/margins": 8.37814712524414,
      "rewards/rejected": -7.215216636657715,
      "step": 3330
    },
    {
      "epoch": 3.5726518597805725,
      "grad_norm": 0.02915607951581478,
      "learning_rate": 1.4601092896174863e-07,
      "logits/chosen": 1.2973811626434326,
      "logits/rejected": 0.07953652739524841,
      "logps/chosen": -138.31822204589844,
      "logps/rejected": -142.03329467773438,
      "loss": 0.0007696706801652908,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9176647067070007,
      "rewards/margins": 8.197324752807617,
      "rewards/rejected": -7.279659271240234,
      "step": 3340
    },
    {
      "epoch": 3.5833556328605836,
      "grad_norm": 0.13756977021694183,
      "learning_rate": 1.4491803278688525e-07,
      "logits/chosen": 1.3499674797058105,
      "logits/rejected": 0.13500583171844482,
      "logps/chosen": -146.8577423095703,
      "logps/rejected": -140.20547485351562,
      "loss": 0.0008886540308594704,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9582244753837585,
      "rewards/margins": 8.130958557128906,
      "rewards/rejected": -7.172733306884766,
      "step": 3350
    },
    {
      "epoch": 3.594059405940594,
      "grad_norm": 0.010355518199503422,
      "learning_rate": 1.4382513661202185e-07,
      "logits/chosen": 1.3572866916656494,
      "logits/rejected": 0.2062520533800125,
      "logps/chosen": -145.9790496826172,
      "logps/rejected": -138.4730224609375,
      "loss": 0.0008507361635565758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9446264505386353,
      "rewards/margins": 8.041685104370117,
      "rewards/rejected": -7.097058296203613,
      "step": 3360
    },
    {
      "epoch": 3.6047631790206047,
      "grad_norm": 0.05313092842698097,
      "learning_rate": 1.4273224043715845e-07,
      "logits/chosen": 1.457338571548462,
      "logits/rejected": 0.10045989602804184,
      "logps/chosen": -157.11451721191406,
      "logps/rejected": -139.17410278320312,
      "loss": 0.0009845411404967308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8661118745803833,
      "rewards/margins": 7.955796241760254,
      "rewards/rejected": -7.089683532714844,
      "step": 3370
    },
    {
      "epoch": 3.6154669521006153,
      "grad_norm": 0.03314642235636711,
      "learning_rate": 1.4163934426229507e-07,
      "logits/chosen": 1.4088099002838135,
      "logits/rejected": 0.14194193482398987,
      "logps/chosen": -161.3423309326172,
      "logps/rejected": -140.6217498779297,
      "loss": 0.0007086646277457475,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9962957501411438,
      "rewards/margins": 8.170287132263184,
      "rewards/rejected": -7.1739912033081055,
      "step": 3380
    },
    {
      "epoch": 3.6261707251806263,
      "grad_norm": 0.029637983068823814,
      "learning_rate": 1.405464480874317e-07,
      "logits/chosen": 1.383855938911438,
      "logits/rejected": 0.025822114199399948,
      "logps/chosen": -153.4468231201172,
      "logps/rejected": -143.8337860107422,
      "loss": 0.0005421060137450695,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0146774053573608,
      "rewards/margins": 8.425403594970703,
      "rewards/rejected": -7.410727024078369,
      "step": 3390
    },
    {
      "epoch": 3.636874498260637,
      "grad_norm": 0.035843923687934875,
      "learning_rate": 1.394535519125683e-07,
      "logits/chosen": 1.3509018421173096,
      "logits/rejected": 0.14832773804664612,
      "logps/chosen": -156.06141662597656,
      "logps/rejected": -140.46951293945312,
      "loss": 0.0009205508045852185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9367477297782898,
      "rewards/margins": 8.15396499633789,
      "rewards/rejected": -7.217217445373535,
      "step": 3400
    },
    {
      "epoch": 3.6475782713406475,
      "grad_norm": 0.016394495964050293,
      "learning_rate": 1.3836065573770492e-07,
      "logits/chosen": 1.3913719654083252,
      "logits/rejected": 0.18045073747634888,
      "logps/chosen": -151.4425811767578,
      "logps/rejected": -139.1437225341797,
      "loss": 0.0008185269311070442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9494484066963196,
      "rewards/margins": 8.07229232788086,
      "rewards/rejected": -7.1228437423706055,
      "step": 3410
    },
    {
      "epoch": 3.658282044420658,
      "grad_norm": 0.04118138551712036,
      "learning_rate": 1.3726775956284154e-07,
      "logits/chosen": 1.2830723524093628,
      "logits/rejected": 0.1996396780014038,
      "logps/chosen": -137.79129028320312,
      "logps/rejected": -140.22633361816406,
      "loss": 0.0008206984959542752,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8471513986587524,
      "rewards/margins": 7.983704566955566,
      "rewards/rejected": -7.1365532875061035,
      "step": 3420
    },
    {
      "epoch": 3.668985817500669,
      "grad_norm": 0.02053666114807129,
      "learning_rate": 1.3617486338797811e-07,
      "logits/chosen": 1.3327406644821167,
      "logits/rejected": 0.10780920088291168,
      "logps/chosen": -149.9761199951172,
      "logps/rejected": -142.63729858398438,
      "loss": 0.0006795030552893877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0269129276275635,
      "rewards/margins": 8.263142585754395,
      "rewards/rejected": -7.236228942871094,
      "step": 3430
    },
    {
      "epoch": 3.6796895905806797,
      "grad_norm": 0.051495108753442764,
      "learning_rate": 1.3508196721311474e-07,
      "logits/chosen": 1.3265540599822998,
      "logits/rejected": 0.10399609804153442,
      "logps/chosen": -151.87191772460938,
      "logps/rejected": -142.00799560546875,
      "loss": 0.0005775727797299624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9067379236221313,
      "rewards/margins": 8.170666694641113,
      "rewards/rejected": -7.2639288902282715,
      "step": 3440
    },
    {
      "epoch": 3.6903933636606903,
      "grad_norm": 0.05030538886785507,
      "learning_rate": 1.3398907103825136e-07,
      "logits/chosen": 1.3712279796600342,
      "logits/rejected": 0.12528784573078156,
      "logps/chosen": -159.4994354248047,
      "logps/rejected": -142.5216064453125,
      "loss": 0.0007800977677106857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8715052604675293,
      "rewards/margins": 8.20264720916748,
      "rewards/rejected": -7.331141471862793,
      "step": 3450
    },
    {
      "epoch": 3.7010971367407013,
      "grad_norm": 0.023847881704568863,
      "learning_rate": 1.3289617486338796e-07,
      "logits/chosen": 1.3360837697982788,
      "logits/rejected": 0.11481068283319473,
      "logps/chosen": -163.50692749023438,
      "logps/rejected": -141.4148406982422,
      "loss": 0.000872211717069149,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9807115793228149,
      "rewards/margins": 8.26112174987793,
      "rewards/rejected": -7.2804107666015625,
      "step": 3460
    },
    {
      "epoch": 3.711800909820712,
      "grad_norm": 0.03357597440481186,
      "learning_rate": 1.3180327868852458e-07,
      "logits/chosen": 1.322290301322937,
      "logits/rejected": 0.14702846109867096,
      "logps/chosen": -147.17408752441406,
      "logps/rejected": -139.6184539794922,
      "loss": 0.0007666427176445722,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8335502743721008,
      "rewards/margins": 8.039508819580078,
      "rewards/rejected": -7.205958366394043,
      "step": 3470
    },
    {
      "epoch": 3.7225046829007225,
      "grad_norm": 0.012949195690453053,
      "learning_rate": 1.307103825136612e-07,
      "logits/chosen": 1.3594658374786377,
      "logits/rejected": -0.01758432574570179,
      "logps/chosen": -156.90963745117188,
      "logps/rejected": -144.85427856445312,
      "loss": 0.0005793474148958922,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0032284259796143,
      "rewards/margins": 8.540521621704102,
      "rewards/rejected": -7.537293910980225,
      "step": 3480
    },
    {
      "epoch": 3.7332084559807335,
      "grad_norm": 0.04140304774045944,
      "learning_rate": 1.2961748633879783e-07,
      "logits/chosen": 1.4941009283065796,
      "logits/rejected": 0.09566035121679306,
      "logps/chosen": -169.41024780273438,
      "logps/rejected": -143.2548828125,
      "loss": 0.0007092066574841738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0127089023590088,
      "rewards/margins": 8.419717788696289,
      "rewards/rejected": -7.407009124755859,
      "step": 3490
    },
    {
      "epoch": 3.743912229060744,
      "grad_norm": 0.041306331753730774,
      "learning_rate": 1.285245901639344e-07,
      "logits/chosen": 1.3921356201171875,
      "logits/rejected": 0.10882790386676788,
      "logps/chosen": -163.60379028320312,
      "logps/rejected": -141.49388122558594,
      "loss": 0.0004693015478551388,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0021636486053467,
      "rewards/margins": 8.414910316467285,
      "rewards/rejected": -7.412747859954834,
      "step": 3500
    },
    {
      "epoch": 3.7546160021407546,
      "grad_norm": 0.04527802765369415,
      "learning_rate": 1.2743169398907103e-07,
      "logits/chosen": 1.295322060585022,
      "logits/rejected": 0.11440751701593399,
      "logps/chosen": -142.68099975585938,
      "logps/rejected": -142.34239196777344,
      "loss": 0.0005025391466915608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0657838582992554,
      "rewards/margins": 8.436944007873535,
      "rewards/rejected": -7.37116003036499,
      "step": 3510
    },
    {
      "epoch": 3.765319775220765,
      "grad_norm": 0.0459744855761528,
      "learning_rate": 1.2633879781420765e-07,
      "logits/chosen": 1.356693983078003,
      "logits/rejected": 0.03792623430490494,
      "logps/chosen": -156.71414184570312,
      "logps/rejected": -141.9502716064453,
      "loss": 0.000684323813766241,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8497673869132996,
      "rewards/margins": 8.198468208312988,
      "rewards/rejected": -7.348700046539307,
      "step": 3520
    },
    {
      "epoch": 3.776023548300776,
      "grad_norm": 0.012239309027791023,
      "learning_rate": 1.2524590163934425e-07,
      "logits/chosen": 1.357232928276062,
      "logits/rejected": 0.16773155331611633,
      "logps/chosen": -160.46112060546875,
      "logps/rejected": -142.11856079101562,
      "loss": 0.0005709524266421795,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9980162382125854,
      "rewards/margins": 8.299215316772461,
      "rewards/rejected": -7.301198482513428,
      "step": 3530
    },
    {
      "epoch": 3.786727321380787,
      "grad_norm": 0.008553487248718739,
      "learning_rate": 1.2415300546448087e-07,
      "logits/chosen": 1.2448294162750244,
      "logits/rejected": -0.05864673852920532,
      "logps/chosen": -145.0315399169922,
      "logps/rejected": -145.26864624023438,
      "loss": 0.0006303279194980859,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9408290982246399,
      "rewards/margins": 8.517759323120117,
      "rewards/rejected": -7.576930999755859,
      "step": 3540
    },
    {
      "epoch": 3.7974310944607974,
      "grad_norm": 0.01841919869184494,
      "learning_rate": 1.2306010928961747e-07,
      "logits/chosen": 1.391672968864441,
      "logits/rejected": 0.10068736225366592,
      "logps/chosen": -151.0814666748047,
      "logps/rejected": -142.75552368164062,
      "loss": 0.0006412039510905743,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0085304975509644,
      "rewards/margins": 8.377208709716797,
      "rewards/rejected": -7.368678092956543,
      "step": 3550
    },
    {
      "epoch": 3.808134867540808,
      "grad_norm": 0.014616157859563828,
      "learning_rate": 1.219672131147541e-07,
      "logits/chosen": 1.364532232284546,
      "logits/rejected": 0.10555549710988998,
      "logps/chosen": -159.44671630859375,
      "logps/rejected": -141.32192993164062,
      "loss": 0.0008037208579480648,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8662844896316528,
      "rewards/margins": 8.160116195678711,
      "rewards/rejected": -7.293832302093506,
      "step": 3560
    },
    {
      "epoch": 3.818838640620819,
      "grad_norm": 0.025948042050004005,
      "learning_rate": 1.2087431693989072e-07,
      "logits/chosen": 1.2643013000488281,
      "logits/rejected": 0.0824524387717247,
      "logps/chosen": -150.57223510742188,
      "logps/rejected": -142.77818298339844,
      "loss": 0.0007458192296326161,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9758148193359375,
      "rewards/margins": 8.399487495422363,
      "rewards/rejected": -7.423672676086426,
      "step": 3570
    },
    {
      "epoch": 3.8295424137008296,
      "grad_norm": 0.0997379794716835,
      "learning_rate": 1.1978142076502731e-07,
      "logits/chosen": 1.3235689401626587,
      "logits/rejected": 0.12676134705543518,
      "logps/chosen": -149.25027465820312,
      "logps/rejected": -143.54708862304688,
      "loss": 0.0005046528298407793,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0115997791290283,
      "rewards/margins": 8.352811813354492,
      "rewards/rejected": -7.341210842132568,
      "step": 3580
    },
    {
      "epoch": 3.84024618678084,
      "grad_norm": 0.054158665239810944,
      "learning_rate": 1.1868852459016392e-07,
      "logits/chosen": 1.297408938407898,
      "logits/rejected": 0.13629338145256042,
      "logps/chosen": -145.292724609375,
      "logps/rejected": -143.04014587402344,
      "loss": 0.0006476708222180605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9905897378921509,
      "rewards/margins": 8.357152938842773,
      "rewards/rejected": -7.366563320159912,
      "step": 3590
    },
    {
      "epoch": 3.850949959860851,
      "grad_norm": 0.046793051064014435,
      "learning_rate": 1.1759562841530055e-07,
      "logits/chosen": 1.3608722686767578,
      "logits/rejected": 0.24362187087535858,
      "logps/chosen": -145.37582397460938,
      "logps/rejected": -139.9859161376953,
      "loss": 0.0007614103145897388,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9124153256416321,
      "rewards/margins": 8.013704299926758,
      "rewards/rejected": -7.101288795471191,
      "step": 3600
    },
    {
      "epoch": 3.861653732940862,
      "grad_norm": 0.014702829532325268,
      "learning_rate": 1.1650273224043715e-07,
      "logits/chosen": 1.306524634361267,
      "logits/rejected": 0.09700118005275726,
      "logps/chosen": -147.0642547607422,
      "logps/rejected": -143.00120544433594,
      "loss": 0.0004617274273186922,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0171194076538086,
      "rewards/margins": 8.459596633911133,
      "rewards/rejected": -7.442476749420166,
      "step": 3610
    },
    {
      "epoch": 3.8723575060208724,
      "grad_norm": 0.014679471962153912,
      "learning_rate": 1.1540983606557377e-07,
      "logits/chosen": 1.3152849674224854,
      "logits/rejected": -0.10375350713729858,
      "logps/chosen": -143.85182189941406,
      "logps/rejected": -147.10960388183594,
      "loss": 0.0003531059715896845,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9600429534912109,
      "rewards/margins": 8.7983980178833,
      "rewards/rejected": -7.83835506439209,
      "step": 3620
    },
    {
      "epoch": 3.883061279100883,
      "grad_norm": 0.03914876654744148,
      "learning_rate": 1.1431693989071038e-07,
      "logits/chosen": 1.3453172445297241,
      "logits/rejected": 0.14013803005218506,
      "logps/chosen": -159.5238494873047,
      "logps/rejected": -141.82781982421875,
      "loss": 0.0006707158870995044,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9453996419906616,
      "rewards/margins": 8.408693313598633,
      "rewards/rejected": -7.463292598724365,
      "step": 3630
    },
    {
      "epoch": 3.8937650521808935,
      "grad_norm": 0.020072799175977707,
      "learning_rate": 1.1322404371584698e-07,
      "logits/chosen": 1.3582178354263306,
      "logits/rejected": 0.146757572889328,
      "logps/chosen": -169.90206909179688,
      "logps/rejected": -142.34242248535156,
      "loss": 0.0004395156167447567,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9238374829292297,
      "rewards/margins": 8.374893188476562,
      "rewards/rejected": -7.45105504989624,
      "step": 3640
    },
    {
      "epoch": 3.9044688252609046,
      "grad_norm": 0.03491934761404991,
      "learning_rate": 1.121311475409836e-07,
      "logits/chosen": 1.4274446964263916,
      "logits/rejected": 0.17582763731479645,
      "logps/chosen": -162.979736328125,
      "logps/rejected": -141.51248168945312,
      "loss": 0.0006243997719138861,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9953947067260742,
      "rewards/margins": 8.443263053894043,
      "rewards/rejected": -7.447868347167969,
      "step": 3650
    },
    {
      "epoch": 3.915172598340915,
      "grad_norm": 0.19568286836147308,
      "learning_rate": 1.1103825136612021e-07,
      "logits/chosen": 1.3442537784576416,
      "logits/rejected": 0.12049062550067902,
      "logps/chosen": -161.21304321289062,
      "logps/rejected": -143.20529174804688,
      "loss": 0.0007892495021224021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.947552502155304,
      "rewards/margins": 8.359524726867676,
      "rewards/rejected": -7.411971092224121,
      "step": 3660
    },
    {
      "epoch": 3.9258763714209257,
      "grad_norm": 0.024956874549388885,
      "learning_rate": 1.0994535519125682e-07,
      "logits/chosen": 1.286129355430603,
      "logits/rejected": -0.028957342728972435,
      "logps/chosen": -146.35662841796875,
      "logps/rejected": -145.3927459716797,
      "loss": 0.001098938938230276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9243165850639343,
      "rewards/margins": 8.522146224975586,
      "rewards/rejected": -7.597829341888428,
      "step": 3670
    },
    {
      "epoch": 3.9365801445009367,
      "grad_norm": 0.018398676067590714,
      "learning_rate": 1.0885245901639343e-07,
      "logits/chosen": 1.3158445358276367,
      "logits/rejected": 0.06316570937633514,
      "logps/chosen": -148.7244873046875,
      "logps/rejected": -143.08633422851562,
      "loss": 0.0006948716007173061,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9141227006912231,
      "rewards/margins": 8.332695960998535,
      "rewards/rejected": -7.418572902679443,
      "step": 3680
    },
    {
      "epoch": 3.9472839175809473,
      "grad_norm": 0.040437228977680206,
      "learning_rate": 1.0775956284153006e-07,
      "logits/chosen": 1.3323805332183838,
      "logits/rejected": 0.10726052522659302,
      "logps/chosen": -162.2141571044922,
      "logps/rejected": -142.8402099609375,
      "loss": 0.0005598449148237705,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9953706860542297,
      "rewards/margins": 8.432394027709961,
      "rewards/rejected": -7.437024116516113,
      "step": 3690
    },
    {
      "epoch": 3.957987690660958,
      "grad_norm": 0.03192394971847534,
      "learning_rate": 1.0666666666666667e-07,
      "logits/chosen": 1.310331106185913,
      "logits/rejected": 0.048560597002506256,
      "logps/chosen": -149.49935913085938,
      "logps/rejected": -142.72491455078125,
      "loss": 0.0006267370656132698,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8995734453201294,
      "rewards/margins": 8.322813987731934,
      "rewards/rejected": -7.42324161529541,
      "step": 3700
    },
    {
      "epoch": 3.968691463740969,
      "grad_norm": 0.12988702952861786,
      "learning_rate": 1.0557377049180327e-07,
      "logits/chosen": 1.2793012857437134,
      "logits/rejected": 0.13377109169960022,
      "logps/chosen": -145.08282470703125,
      "logps/rejected": -140.85791015625,
      "loss": 0.0008445544168353081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9480422139167786,
      "rewards/margins": 8.23322868347168,
      "rewards/rejected": -7.28518533706665,
      "step": 3710
    },
    {
      "epoch": 3.9793952368209795,
      "grad_norm": 0.01246361993253231,
      "learning_rate": 1.0448087431693989e-07,
      "logits/chosen": 1.4927036762237549,
      "logits/rejected": 0.025134574621915817,
      "logps/chosen": -168.3004150390625,
      "logps/rejected": -145.24549865722656,
      "loss": 0.0005834617651998997,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0968058109283447,
      "rewards/margins": 8.578208923339844,
      "rewards/rejected": -7.481402397155762,
      "step": 3720
    },
    {
      "epoch": 3.99009900990099,
      "grad_norm": 0.018899986520409584,
      "learning_rate": 1.033879781420765e-07,
      "logits/chosen": 1.4276875257492065,
      "logits/rejected": 0.0065218182280659676,
      "logps/chosen": -167.49307250976562,
      "logps/rejected": -145.43643188476562,
      "loss": 0.0005654997192323207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9702779650688171,
      "rewards/margins": 8.598753929138184,
      "rewards/rejected": -7.628476619720459,
      "step": 3730
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.007109507918357849,
      "learning_rate": 1.0229508196721311e-07,
      "logits/chosen": 1.3501389026641846,
      "logits/rejected": -0.009832723997533321,
      "logps/chosen": -143.97592163085938,
      "logps/rejected": -144.95530700683594,
      "loss": 0.00046841721050441267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9033430218696594,
      "rewards/margins": 8.566125869750977,
      "rewards/rejected": -7.662782192230225,
      "step": 3740
    },
    {
      "epoch": 4.010703773080011,
      "grad_norm": 0.01834270916879177,
      "learning_rate": 1.0120218579234972e-07,
      "logits/chosen": 1.3709301948547363,
      "logits/rejected": 0.11931443214416504,
      "logps/chosen": -162.5779266357422,
      "logps/rejected": -142.87322998046875,
      "loss": 0.0004927956499159337,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9937726855278015,
      "rewards/margins": 8.435111045837402,
      "rewards/rejected": -7.441338539123535,
      "step": 3750
    },
    {
      "epoch": 4.021407546160021,
      "grad_norm": 0.028088970109820366,
      "learning_rate": 1.0010928961748633e-07,
      "logits/chosen": 1.2842081785202026,
      "logits/rejected": 0.06710217893123627,
      "logps/chosen": -144.56332397460938,
      "logps/rejected": -143.115966796875,
      "loss": 0.0005169371142983437,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9600238800048828,
      "rewards/margins": 8.419690132141113,
      "rewards/rejected": -7.459664821624756,
      "step": 3760
    },
    {
      "epoch": 4.032111319240032,
      "grad_norm": 0.022872187197208405,
      "learning_rate": 9.901639344262294e-08,
      "logits/chosen": 1.2373073101043701,
      "logits/rejected": 0.08377228677272797,
      "logps/chosen": -144.30979919433594,
      "logps/rejected": -141.917724609375,
      "loss": 0.0005706170573830605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9412912130355835,
      "rewards/margins": 8.3878173828125,
      "rewards/rejected": -7.446525573730469,
      "step": 3770
    },
    {
      "epoch": 4.042815092320043,
      "grad_norm": 0.011639113537967205,
      "learning_rate": 9.792349726775955e-08,
      "logits/chosen": 1.3714025020599365,
      "logits/rejected": -0.003426801413297653,
      "logps/chosen": -148.76150512695312,
      "logps/rejected": -144.0309600830078,
      "loss": 0.00041267997585237026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1036179065704346,
      "rewards/margins": 8.700628280639648,
      "rewards/rejected": -7.597010612487793,
      "step": 3780
    },
    {
      "epoch": 4.053518865400053,
      "grad_norm": 0.03595113009214401,
      "learning_rate": 9.683060109289618e-08,
      "logits/chosen": 1.3548811674118042,
      "logits/rejected": 0.14140549302101135,
      "logps/chosen": -150.3718719482422,
      "logps/rejected": -144.54837036132812,
      "loss": 0.0004608703311532736,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0041937828063965,
      "rewards/margins": 8.497530937194824,
      "rewards/rejected": -7.493338108062744,
      "step": 3790
    },
    {
      "epoch": 4.064222638480064,
      "grad_norm": 0.12189223617315292,
      "learning_rate": 9.573770491803278e-08,
      "logits/chosen": 1.3147282600402832,
      "logits/rejected": 0.17359910905361176,
      "logps/chosen": -145.5796661376953,
      "logps/rejected": -141.30795288085938,
      "loss": 0.0008177298121154308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.866439700126648,
      "rewards/margins": 8.195394515991211,
      "rewards/rejected": -7.32895565032959,
      "step": 3800
    },
    {
      "epoch": 4.0749264115600745,
      "grad_norm": 0.011554022319614887,
      "learning_rate": 9.46448087431694e-08,
      "logits/chosen": 1.3495714664459229,
      "logits/rejected": 0.10572215169668198,
      "logps/chosen": -152.11521911621094,
      "logps/rejected": -144.01889038085938,
      "loss": 0.00048770345747470854,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9922389984130859,
      "rewards/margins": 8.505350112915039,
      "rewards/rejected": -7.513110160827637,
      "step": 3810
    },
    {
      "epoch": 4.0856301846400855,
      "grad_norm": 0.023664185777306557,
      "learning_rate": 9.355191256830601e-08,
      "logits/chosen": 1.3466250896453857,
      "logits/rejected": -0.03248077258467674,
      "logps/chosen": -154.2100067138672,
      "logps/rejected": -146.58285522460938,
      "loss": 0.0004364608321338892,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9030219912528992,
      "rewards/margins": 8.657114028930664,
      "rewards/rejected": -7.754090785980225,
      "step": 3820
    },
    {
      "epoch": 4.096333957720097,
      "grad_norm": 0.027643322944641113,
      "learning_rate": 9.245901639344261e-08,
      "logits/chosen": 1.448193073272705,
      "logits/rejected": 0.06836295127868652,
      "logps/chosen": -160.23611450195312,
      "logps/rejected": -143.44911193847656,
      "loss": 0.0006832084152847528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9808627963066101,
      "rewards/margins": 8.429244041442871,
      "rewards/rejected": -7.448380947113037,
      "step": 3830
    },
    {
      "epoch": 4.107037730800107,
      "grad_norm": 0.015638722106814384,
      "learning_rate": 9.136612021857923e-08,
      "logits/chosen": 1.4114412069320679,
      "logits/rejected": -0.011319970712065697,
      "logps/chosen": -169.27621459960938,
      "logps/rejected": -147.3397674560547,
      "loss": 0.00027798127848654985,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.037575364112854,
      "rewards/margins": 8.792540550231934,
      "rewards/rejected": -7.754965305328369,
      "step": 3840
    },
    {
      "epoch": 4.117741503880118,
      "grad_norm": 0.06556982547044754,
      "learning_rate": 9.027322404371584e-08,
      "logits/chosen": 1.4247465133666992,
      "logits/rejected": 0.05936552956700325,
      "logps/chosen": -165.6636962890625,
      "logps/rejected": -143.43203735351562,
      "loss": 0.000852357130497694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.956325352191925,
      "rewards/margins": 8.498406410217285,
      "rewards/rejected": -7.542081356048584,
      "step": 3850
    },
    {
      "epoch": 4.128445276960129,
      "grad_norm": 0.04757743701338768,
      "learning_rate": 8.918032786885247e-08,
      "logits/chosen": 1.3625034093856812,
      "logits/rejected": 0.0595894381403923,
      "logps/chosen": -162.60150146484375,
      "logps/rejected": -144.330322265625,
      "loss": 0.0005309309344738722,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9448732137680054,
      "rewards/margins": 8.518375396728516,
      "rewards/rejected": -7.573502540588379,
      "step": 3860
    },
    {
      "epoch": 4.139149050040139,
      "grad_norm": 0.04927407205104828,
      "learning_rate": 8.808743169398906e-08,
      "logits/chosen": 1.3549714088439941,
      "logits/rejected": -0.025362495332956314,
      "logps/chosen": -153.25949096679688,
      "logps/rejected": -145.34841918945312,
      "loss": 0.0005986867472529411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7794645428657532,
      "rewards/margins": 8.349205017089844,
      "rewards/rejected": -7.56973934173584,
      "step": 3870
    },
    {
      "epoch": 4.14985282312015,
      "grad_norm": 0.008769093081355095,
      "learning_rate": 8.699453551912567e-08,
      "logits/chosen": 1.303945541381836,
      "logits/rejected": 0.003902553813531995,
      "logps/chosen": -150.89695739746094,
      "logps/rejected": -145.25369262695312,
      "loss": 0.0004606024827808142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0642294883728027,
      "rewards/margins": 8.693339347839355,
      "rewards/rejected": -7.6291093826293945,
      "step": 3880
    },
    {
      "epoch": 4.160556596200161,
      "grad_norm": 0.06200234219431877,
      "learning_rate": 8.59016393442623e-08,
      "logits/chosen": 1.3542611598968506,
      "logits/rejected": -0.0012109421659260988,
      "logps/chosen": -155.131591796875,
      "logps/rejected": -144.99954223632812,
      "loss": 0.0006769621279090643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9481967687606812,
      "rewards/margins": 8.426119804382324,
      "rewards/rejected": -7.477923393249512,
      "step": 3890
    },
    {
      "epoch": 4.171260369280171,
      "grad_norm": 0.0706196203827858,
      "learning_rate": 8.48087431693989e-08,
      "logits/chosen": 1.312050700187683,
      "logits/rejected": -0.05431852489709854,
      "logps/chosen": -159.0074462890625,
      "logps/rejected": -147.19317626953125,
      "loss": 0.00048097795806825163,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9373488426208496,
      "rewards/margins": 8.646568298339844,
      "rewards/rejected": -7.709218502044678,
      "step": 3900
    },
    {
      "epoch": 4.181964142360182,
      "grad_norm": 0.021929854527115822,
      "learning_rate": 8.371584699453552e-08,
      "logits/chosen": 1.391982078552246,
      "logits/rejected": 0.09148092567920685,
      "logps/chosen": -156.73130798339844,
      "logps/rejected": -143.8202667236328,
      "loss": 0.0006423486396670341,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9077949523925781,
      "rewards/margins": 8.414566993713379,
      "rewards/rejected": -7.506772041320801,
      "step": 3910
    },
    {
      "epoch": 4.192667915440192,
      "grad_norm": 0.04093354567885399,
      "learning_rate": 8.262295081967213e-08,
      "logits/chosen": 1.2216739654541016,
      "logits/rejected": 0.05059995502233505,
      "logps/chosen": -144.2479248046875,
      "logps/rejected": -145.9246826171875,
      "loss": 0.000598176196217537,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7820325493812561,
      "rewards/margins": 8.479154586791992,
      "rewards/rejected": -7.697120666503906,
      "step": 3920
    },
    {
      "epoch": 4.203371688520203,
      "grad_norm": 0.04128481075167656,
      "learning_rate": 8.153005464480874e-08,
      "logits/chosen": 1.4116981029510498,
      "logits/rejected": 0.0354018360376358,
      "logps/chosen": -159.53506469726562,
      "logps/rejected": -144.13510131835938,
      "loss": 0.0004883658140897751,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9937635660171509,
      "rewards/margins": 8.558879852294922,
      "rewards/rejected": -7.565115928649902,
      "step": 3930
    },
    {
      "epoch": 4.214075461600214,
      "grad_norm": 0.013954549096524715,
      "learning_rate": 8.043715846994535e-08,
      "logits/chosen": 1.2955256700515747,
      "logits/rejected": 0.12261544167995453,
      "logps/chosen": -153.02218627929688,
      "logps/rejected": -143.79159545898438,
      "loss": 0.001297365128993988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9221295118331909,
      "rewards/margins": 8.446779251098633,
      "rewards/rejected": -7.524650573730469,
      "step": 3940
    },
    {
      "epoch": 4.224779234680224,
      "grad_norm": 0.017688153311610222,
      "learning_rate": 7.934426229508196e-08,
      "logits/chosen": 1.3253417015075684,
      "logits/rejected": 0.04677652195096016,
      "logps/chosen": -142.97262573242188,
      "logps/rejected": -143.609375,
      "loss": 0.000475413491949439,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9146539568901062,
      "rewards/margins": 8.420602798461914,
      "rewards/rejected": -7.505948066711426,
      "step": 3950
    },
    {
      "epoch": 4.2354830077602355,
      "grad_norm": 0.0239853598177433,
      "learning_rate": 7.825136612021857e-08,
      "logits/chosen": 1.3736910820007324,
      "logits/rejected": 0.051783014088869095,
      "logps/chosen": -163.97640991210938,
      "logps/rejected": -146.13034057617188,
      "loss": 0.00044348593801259997,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0373964309692383,
      "rewards/margins": 8.667655944824219,
      "rewards/rejected": -7.6302595138549805,
      "step": 3960
    },
    {
      "epoch": 4.2461867808402465,
      "grad_norm": 0.018150683492422104,
      "learning_rate": 7.715846994535518e-08,
      "logits/chosen": 1.3695712089538574,
      "logits/rejected": -0.013887515291571617,
      "logps/chosen": -155.28140258789062,
      "logps/rejected": -146.49697875976562,
      "loss": 0.0003468258073553443,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1148508787155151,
      "rewards/margins": 8.90870189666748,
      "rewards/rejected": -7.793851375579834,
      "step": 3970
    },
    {
      "epoch": 4.256890553920257,
      "grad_norm": 0.014828960411250591,
      "learning_rate": 7.606557377049181e-08,
      "logits/chosen": 1.352321982383728,
      "logits/rejected": 0.059020232409238815,
      "logps/chosen": -158.1693878173828,
      "logps/rejected": -144.87429809570312,
      "loss": 0.000585543503984809,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.896905243396759,
      "rewards/margins": 8.530789375305176,
      "rewards/rejected": -7.633883476257324,
      "step": 3980
    },
    {
      "epoch": 4.267594327000268,
      "grad_norm": 0.017682159319519997,
      "learning_rate": 7.49726775956284e-08,
      "logits/chosen": 1.2458961009979248,
      "logits/rejected": 0.09829395264387131,
      "logps/chosen": -141.35833740234375,
      "logps/rejected": -145.86422729492188,
      "loss": 0.0003822782775387168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1220707893371582,
      "rewards/margins": 8.737939834594727,
      "rewards/rejected": -7.61586856842041,
      "step": 3990
    },
    {
      "epoch": 4.278298100080279,
      "grad_norm": 0.019376957789063454,
      "learning_rate": 7.387978142076502e-08,
      "logits/chosen": 1.3743929862976074,
      "logits/rejected": 0.05834469199180603,
      "logps/chosen": -155.84152221679688,
      "logps/rejected": -144.6208038330078,
      "loss": 0.0005454487167298794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9461496472358704,
      "rewards/margins": 8.541935920715332,
      "rewards/rejected": -7.595785617828369,
      "step": 4000
    },
    {
      "epoch": 4.289001873160289,
      "grad_norm": 0.0241396464407444,
      "learning_rate": 7.278688524590164e-08,
      "logits/chosen": 1.290967583656311,
      "logits/rejected": 0.02824050560593605,
      "logps/chosen": -131.21047973632812,
      "logps/rejected": -144.13656616210938,
      "loss": 0.0004245345015078783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0177615880966187,
      "rewards/margins": 8.587621688842773,
      "rewards/rejected": -7.569859981536865,
      "step": 4010
    },
    {
      "epoch": 4.2997056462403,
      "grad_norm": 0.04828870669007301,
      "learning_rate": 7.169398907103825e-08,
      "logits/chosen": 1.3188265562057495,
      "logits/rejected": 0.11214470863342285,
      "logps/chosen": -156.6016387939453,
      "logps/rejected": -143.5327606201172,
      "loss": 0.0006978395394980907,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9120882153511047,
      "rewards/margins": 8.389976501464844,
      "rewards/rejected": -7.477889060974121,
      "step": 4020
    },
    {
      "epoch": 4.31040941932031,
      "grad_norm": 0.048706911504268646,
      "learning_rate": 7.060109289617486e-08,
      "logits/chosen": 1.3607360124588013,
      "logits/rejected": 0.1065378189086914,
      "logps/chosen": -164.47024536132812,
      "logps/rejected": -143.9337158203125,
      "loss": 0.000502793025225401,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0706908702850342,
      "rewards/margins": 8.603408813476562,
      "rewards/rejected": -7.532718658447266,
      "step": 4030
    },
    {
      "epoch": 4.321113192400321,
      "grad_norm": 0.050794705748558044,
      "learning_rate": 6.950819672131147e-08,
      "logits/chosen": 1.3488749265670776,
      "logits/rejected": 0.11672548949718475,
      "logps/chosen": -146.49586486816406,
      "logps/rejected": -146.02468872070312,
      "loss": 0.00046083503402769563,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.015435814857483,
      "rewards/margins": 8.631612777709961,
      "rewards/rejected": -7.616176605224609,
      "step": 4040
    },
    {
      "epoch": 4.331816965480332,
      "grad_norm": 0.012505581602454185,
      "learning_rate": 6.84153005464481e-08,
      "logits/chosen": 1.3207272291183472,
      "logits/rejected": -0.026346871629357338,
      "logps/chosen": -150.33218383789062,
      "logps/rejected": -145.76431274414062,
      "loss": 0.0006405595224350691,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7897377610206604,
      "rewards/margins": 8.483491897583008,
      "rewards/rejected": -7.69375467300415,
      "step": 4050
    },
    {
      "epoch": 4.342520738560342,
      "grad_norm": 0.01727052591741085,
      "learning_rate": 6.73224043715847e-08,
      "logits/chosen": 1.3129267692565918,
      "logits/rejected": -0.02873748540878296,
      "logps/chosen": -157.02796936035156,
      "logps/rejected": -144.8131866455078,
      "loss": 0.0007067728321999312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7959834933280945,
      "rewards/margins": 8.517422676086426,
      "rewards/rejected": -7.721438407897949,
      "step": 4060
    },
    {
      "epoch": 4.353224511640353,
      "grad_norm": 0.02341369353234768,
      "learning_rate": 6.62295081967213e-08,
      "logits/chosen": 1.2902634143829346,
      "logits/rejected": -0.04373802989721298,
      "logps/chosen": -143.86001586914062,
      "logps/rejected": -147.49295043945312,
      "loss": 0.0004965534899383783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8483489751815796,
      "rewards/margins": 8.632057189941406,
      "rewards/rejected": -7.783707618713379,
      "step": 4070
    },
    {
      "epoch": 4.363928284720364,
      "grad_norm": 0.028973769396543503,
      "learning_rate": 6.513661202185793e-08,
      "logits/chosen": 1.4499094486236572,
      "logits/rejected": 0.04105238988995552,
      "logps/chosen": -154.414794921875,
      "logps/rejected": -145.4014434814453,
      "loss": 0.0005887243896722794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8576475381851196,
      "rewards/margins": 8.595026016235352,
      "rewards/rejected": -7.7373785972595215,
      "step": 4080
    },
    {
      "epoch": 4.374632057800374,
      "grad_norm": 0.08706305176019669,
      "learning_rate": 6.404371584699453e-08,
      "logits/chosen": 1.3395869731903076,
      "logits/rejected": 0.21211044490337372,
      "logps/chosen": -155.04583740234375,
      "logps/rejected": -140.94798278808594,
      "loss": 0.0009328316897153855,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8078753352165222,
      "rewards/margins": 8.151629447937012,
      "rewards/rejected": -7.34375524520874,
      "step": 4090
    },
    {
      "epoch": 4.385335830880385,
      "grad_norm": 0.02223728597164154,
      "learning_rate": 6.295081967213115e-08,
      "logits/chosen": 1.3425805568695068,
      "logits/rejected": 0.046911634504795074,
      "logps/chosen": -159.46157836914062,
      "logps/rejected": -145.39125061035156,
      "loss": 0.0006184780038893222,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8784988522529602,
      "rewards/margins": 8.49793815612793,
      "rewards/rejected": -7.619438171386719,
      "step": 4100
    },
    {
      "epoch": 4.396039603960396,
      "grad_norm": 0.0119192348793149,
      "learning_rate": 6.185792349726776e-08,
      "logits/chosen": 1.4423072338104248,
      "logits/rejected": -0.013179870322346687,
      "logps/chosen": -162.94503784179688,
      "logps/rejected": -146.24331665039062,
      "loss": 0.00048501393757760525,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8277459144592285,
      "rewards/margins": 8.560789108276367,
      "rewards/rejected": -7.7330427169799805,
      "step": 4110
    },
    {
      "epoch": 4.4067433770404065,
      "grad_norm": 0.07733779400587082,
      "learning_rate": 6.076502732240437e-08,
      "logits/chosen": 1.2951090335845947,
      "logits/rejected": 0.11714699119329453,
      "logps/chosen": -152.05670166015625,
      "logps/rejected": -143.62191772460938,
      "loss": 0.0005645197350531816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9516770243644714,
      "rewards/margins": 8.460763931274414,
      "rewards/rejected": -7.509086608886719,
      "step": 4120
    },
    {
      "epoch": 4.4174471501204176,
      "grad_norm": 0.00644311960786581,
      "learning_rate": 5.967213114754098e-08,
      "logits/chosen": 1.377791404724121,
      "logits/rejected": -0.1154470294713974,
      "logps/chosen": -155.63294982910156,
      "logps/rejected": -147.21192932128906,
      "loss": 0.00041834409348666667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9179303050041199,
      "rewards/margins": 8.767817497253418,
      "rewards/rejected": -7.849886894226074,
      "step": 4130
    },
    {
      "epoch": 4.428150923200429,
      "grad_norm": 0.019941706210374832,
      "learning_rate": 5.85792349726776e-08,
      "logits/chosen": 1.3708343505859375,
      "logits/rejected": 0.017318645492196083,
      "logps/chosen": -155.61526489257812,
      "logps/rejected": -147.6149139404297,
      "loss": 0.00038551937323063614,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9259498715400696,
      "rewards/margins": 8.75230598449707,
      "rewards/rejected": -7.826355934143066,
      "step": 4140
    },
    {
      "epoch": 4.438854696280439,
      "grad_norm": 0.028372585773468018,
      "learning_rate": 5.74863387978142e-08,
      "logits/chosen": 1.3153631687164307,
      "logits/rejected": 0.10778689384460449,
      "logps/chosen": -160.34017944335938,
      "logps/rejected": -143.56423950195312,
      "loss": 0.0005508169531822204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8427242040634155,
      "rewards/margins": 8.374303817749023,
      "rewards/rejected": -7.531580924987793,
      "step": 4150
    },
    {
      "epoch": 4.44955846936045,
      "grad_norm": 0.026251230388879776,
      "learning_rate": 5.6393442622950814e-08,
      "logits/chosen": 1.3021996021270752,
      "logits/rejected": -0.013315963558852673,
      "logps/chosen": -147.5414276123047,
      "logps/rejected": -148.1024627685547,
      "loss": 0.0004022650420665741,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8984661102294922,
      "rewards/margins": 8.655667304992676,
      "rewards/rejected": -7.757200717926025,
      "step": 4160
    },
    {
      "epoch": 4.46026224244046,
      "grad_norm": 0.014400860294699669,
      "learning_rate": 5.530054644808743e-08,
      "logits/chosen": 1.2551294565200806,
      "logits/rejected": -0.05192176625132561,
      "logps/chosen": -145.34524536132812,
      "logps/rejected": -148.99839782714844,
      "loss": 0.0004031555727124214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9328290820121765,
      "rewards/margins": 8.817747116088867,
      "rewards/rejected": -7.884917259216309,
      "step": 4170
    },
    {
      "epoch": 4.470966015520471,
      "grad_norm": 0.07130862027406693,
      "learning_rate": 5.420765027322404e-08,
      "logits/chosen": 1.239534616470337,
      "logits/rejected": -0.18563544750213623,
      "logps/chosen": -151.2957000732422,
      "logps/rejected": -149.4719696044922,
      "loss": 0.00047510894946753977,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7962937951087952,
      "rewards/margins": 8.720377922058105,
      "rewards/rejected": -7.9240851402282715,
      "step": 4180
    },
    {
      "epoch": 4.481669788600482,
      "grad_norm": 0.007382665760815144,
      "learning_rate": 5.311475409836065e-08,
      "logits/chosen": 1.2663582563400269,
      "logits/rejected": 0.09192625433206558,
      "logps/chosen": -144.4110107421875,
      "logps/rejected": -145.93612670898438,
      "loss": 0.00045779673382639885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8784528970718384,
      "rewards/margins": 8.5912504196167,
      "rewards/rejected": -7.71279764175415,
      "step": 4190
    },
    {
      "epoch": 4.492373561680492,
      "grad_norm": 0.019302934408187866,
      "learning_rate": 5.202185792349727e-08,
      "logits/chosen": 1.2372596263885498,
      "logits/rejected": 0.02540203370153904,
      "logps/chosen": -140.24362182617188,
      "logps/rejected": -144.59576416015625,
      "loss": 0.0005323733668774367,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8370770215988159,
      "rewards/margins": 8.487494468688965,
      "rewards/rejected": -7.650418281555176,
      "step": 4200
    },
    {
      "epoch": 4.503077334760503,
      "grad_norm": 0.01990492083132267,
      "learning_rate": 5.0928961748633874e-08,
      "logits/chosen": 1.339148759841919,
      "logits/rejected": 0.06803284585475922,
      "logps/chosen": -147.86660766601562,
      "logps/rejected": -146.30661010742188,
      "loss": 0.0004372233524918556,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.866989254951477,
      "rewards/margins": 8.540800094604492,
      "rewards/rejected": -7.6738104820251465,
      "step": 4210
    },
    {
      "epoch": 4.513781107840514,
      "grad_norm": 0.01606481894850731,
      "learning_rate": 4.983606557377049e-08,
      "logits/chosen": 1.334784746170044,
      "logits/rejected": 0.06468045711517334,
      "logps/chosen": -155.0717010498047,
      "logps/rejected": -145.34054565429688,
      "loss": 0.00047233505174517634,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.825967013835907,
      "rewards/margins": 8.493955612182617,
      "rewards/rejected": -7.6679887771606445,
      "step": 4220
    },
    {
      "epoch": 4.524484880920524,
      "grad_norm": 0.0837402269244194,
      "learning_rate": 4.87431693989071e-08,
      "logits/chosen": 1.3567317724227905,
      "logits/rejected": -0.026760321110486984,
      "logps/chosen": -160.46664428710938,
      "logps/rejected": -147.4144744873047,
      "loss": 0.0003502950305119157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0353668928146362,
      "rewards/margins": 8.842145919799805,
      "rewards/rejected": -7.8067779541015625,
      "step": 4230
    },
    {
      "epoch": 4.535188654000535,
      "grad_norm": 0.026371818035840988,
      "learning_rate": 4.765027322404371e-08,
      "logits/chosen": 1.2291154861450195,
      "logits/rejected": 0.13157424330711365,
      "logps/chosen": -133.05606079101562,
      "logps/rejected": -145.3938751220703,
      "loss": 0.00041430494748055934,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9362018704414368,
      "rewards/margins": 8.55419635772705,
      "rewards/rejected": -7.6179938316345215,
      "step": 4240
    },
    {
      "epoch": 4.545892427080545,
      "grad_norm": 0.036562055349349976,
      "learning_rate": 4.655737704918033e-08,
      "logits/chosen": 1.2089037895202637,
      "logits/rejected": 0.06074945256114006,
      "logps/chosen": -149.09841918945312,
      "logps/rejected": -144.3571319580078,
      "loss": 0.0005366113502532244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8976367712020874,
      "rewards/margins": 8.48976993560791,
      "rewards/rejected": -7.592133522033691,
      "step": 4250
    },
    {
      "epoch": 4.556596200160556,
      "grad_norm": 0.07007699459791183,
      "learning_rate": 4.546448087431694e-08,
      "logits/chosen": 1.445381760597229,
      "logits/rejected": 0.011843450367450714,
      "logps/chosen": -171.4967803955078,
      "logps/rejected": -146.98147583007812,
      "loss": 0.0007869306020438672,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.835422694683075,
      "rewards/margins": 8.529470443725586,
      "rewards/rejected": -7.694048881530762,
      "step": 4260
    },
    {
      "epoch": 4.5672999732405675,
      "grad_norm": 0.010707790963351727,
      "learning_rate": 4.4371584699453545e-08,
      "logits/chosen": 1.4078730344772339,
      "logits/rejected": 0.0413445308804512,
      "logps/chosen": -155.95767211914062,
      "logps/rejected": -144.00978088378906,
      "loss": 0.0005706993862986565,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9821649789810181,
      "rewards/margins": 8.589457511901855,
      "rewards/rejected": -7.607292175292969,
      "step": 4270
    },
    {
      "epoch": 4.578003746320578,
      "grad_norm": 0.016313742846250534,
      "learning_rate": 4.327868852459016e-08,
      "logits/chosen": 1.3692796230316162,
      "logits/rejected": -0.04998275637626648,
      "logps/chosen": -161.81690979003906,
      "logps/rejected": -148.50070190429688,
      "loss": 0.0005326509010046721,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9233099222183228,
      "rewards/margins": 8.824052810668945,
      "rewards/rejected": -7.900743007659912,
      "step": 4280
    },
    {
      "epoch": 4.588707519400589,
      "grad_norm": 0.01632758043706417,
      "learning_rate": 4.218579234972677e-08,
      "logits/chosen": 1.2422245740890503,
      "logits/rejected": 0.06930297613143921,
      "logps/chosen": -149.55239868164062,
      "logps/rejected": -144.2703399658203,
      "loss": 0.0006401987280696631,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8641569018363953,
      "rewards/margins": 8.453611373901367,
      "rewards/rejected": -7.58945369720459,
      "step": 4290
    },
    {
      "epoch": 4.5994112924806,
      "grad_norm": 0.010969752445816994,
      "learning_rate": 4.109289617486339e-08,
      "logits/chosen": 1.270094394683838,
      "logits/rejected": -0.1089523583650589,
      "logps/chosen": -157.3478546142578,
      "logps/rejected": -149.1708526611328,
      "loss": 0.00042008268646895883,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9588541984558105,
      "rewards/margins": 8.884384155273438,
      "rewards/rejected": -7.925529479980469,
      "step": 4300
    },
    {
      "epoch": 4.61011506556061,
      "grad_norm": 0.044862050563097,
      "learning_rate": 4e-08,
      "logits/chosen": 1.310338020324707,
      "logits/rejected": -0.07204990088939667,
      "logps/chosen": -151.44619750976562,
      "logps/rejected": -147.90591430664062,
      "loss": 0.00038312010001391173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.841402530670166,
      "rewards/margins": 8.791401863098145,
      "rewards/rejected": -7.949999809265137,
      "step": 4310
    },
    {
      "epoch": 4.620818838640621,
      "grad_norm": 0.025257578119635582,
      "learning_rate": 3.890710382513661e-08,
      "logits/chosen": 1.4259051084518433,
      "logits/rejected": 0.07607028633356094,
      "logps/chosen": -158.40927124023438,
      "logps/rejected": -144.6295623779297,
      "loss": 0.0004040047060698271,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1066581010818481,
      "rewards/margins": 8.765321731567383,
      "rewards/rejected": -7.658664703369141,
      "step": 4320
    },
    {
      "epoch": 4.631522611720632,
      "grad_norm": 0.02488776296377182,
      "learning_rate": 3.781420765027322e-08,
      "logits/chosen": 1.3617209196090698,
      "logits/rejected": 0.0032915764022618532,
      "logps/chosen": -157.69671630859375,
      "logps/rejected": -146.48794555664062,
      "loss": 0.00035880778450518845,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9817930459976196,
      "rewards/margins": 8.672728538513184,
      "rewards/rejected": -7.690934658050537,
      "step": 4330
    },
    {
      "epoch": 4.642226384800642,
      "grad_norm": 0.026566553860902786,
      "learning_rate": 3.672131147540983e-08,
      "logits/chosen": 1.4060680866241455,
      "logits/rejected": -0.006864185445010662,
      "logps/chosen": -145.54954528808594,
      "logps/rejected": -146.7161102294922,
      "loss": 0.00038840915076434614,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0218095779418945,
      "rewards/margins": 8.803665161132812,
      "rewards/rejected": -7.781854152679443,
      "step": 4340
    },
    {
      "epoch": 4.652930157880653,
      "grad_norm": 0.02863188646733761,
      "learning_rate": 3.5628415300546444e-08,
      "logits/chosen": 1.3608630895614624,
      "logits/rejected": 0.04638059437274933,
      "logps/chosen": -156.52171325683594,
      "logps/rejected": -144.58924865722656,
      "loss": 0.0005326461046934128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8905729055404663,
      "rewards/margins": 8.576467514038086,
      "rewards/rejected": -7.6858954429626465,
      "step": 4350
    },
    {
      "epoch": 4.663633930960664,
      "grad_norm": 0.061847902834415436,
      "learning_rate": 3.453551912568306e-08,
      "logits/chosen": 1.2753212451934814,
      "logits/rejected": 0.03926383703947067,
      "logps/chosen": -138.2528076171875,
      "logps/rejected": -145.5101318359375,
      "loss": 0.0005420646164566278,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8040388226509094,
      "rewards/margins": 8.521703720092773,
      "rewards/rejected": -7.7176642417907715,
      "step": 4360
    },
    {
      "epoch": 4.674337704040674,
      "grad_norm": 0.03321227803826332,
      "learning_rate": 3.344262295081967e-08,
      "logits/chosen": 1.40919828414917,
      "logits/rejected": 0.11238064616918564,
      "logps/chosen": -160.7975311279297,
      "logps/rejected": -145.65536499023438,
      "loss": 0.0005005088169127703,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9729778170585632,
      "rewards/margins": 8.630463600158691,
      "rewards/rejected": -7.657484531402588,
      "step": 4370
    },
    {
      "epoch": 4.685041477120685,
      "grad_norm": 0.015789981931447983,
      "learning_rate": 3.234972677595629e-08,
      "logits/chosen": 1.2603652477264404,
      "logits/rejected": 0.08481226116418839,
      "logps/chosen": -153.2078399658203,
      "logps/rejected": -144.05496215820312,
      "loss": 0.0007021955214440822,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9528601765632629,
      "rewards/margins": 8.599319458007812,
      "rewards/rejected": -7.646460056304932,
      "step": 4380
    },
    {
      "epoch": 4.695745250200696,
      "grad_norm": 0.016099154949188232,
      "learning_rate": 3.125683060109289e-08,
      "logits/chosen": 1.3465652465820312,
      "logits/rejected": -0.022223245352506638,
      "logps/chosen": -150.74005126953125,
      "logps/rejected": -146.35195922851562,
      "loss": 0.0003672710852697492,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9752335548400879,
      "rewards/margins": 8.741371154785156,
      "rewards/rejected": -7.766137599945068,
      "step": 4390
    },
    {
      "epoch": 4.706449023280706,
      "grad_norm": 0.010460112243890762,
      "learning_rate": 3.016393442622951e-08,
      "logits/chosen": 1.259695291519165,
      "logits/rejected": -0.08322468400001526,
      "logps/chosen": -154.98526000976562,
      "logps/rejected": -149.3815155029297,
      "loss": 0.00033934405073523524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9287903904914856,
      "rewards/margins": 8.906950950622559,
      "rewards/rejected": -7.978160858154297,
      "step": 4400
    },
    {
      "epoch": 4.717152796360717,
      "grad_norm": 0.01075990591198206,
      "learning_rate": 2.9071038251366118e-08,
      "logits/chosen": 1.2865506410598755,
      "logits/rejected": -0.00634851586073637,
      "logps/chosen": -145.69223022460938,
      "logps/rejected": -148.487548828125,
      "loss": 0.00031793692614883183,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9495440721511841,
      "rewards/margins": 8.807873725891113,
      "rewards/rejected": -7.858328342437744,
      "step": 4410
    },
    {
      "epoch": 4.7278565694407275,
      "grad_norm": 0.02290794625878334,
      "learning_rate": 2.7978142076502732e-08,
      "logits/chosen": 1.3275623321533203,
      "logits/rejected": 0.018606361001729965,
      "logps/chosen": -164.27854919433594,
      "logps/rejected": -146.25308227539062,
      "loss": 0.00047149662859737875,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8798140287399292,
      "rewards/margins": 8.578530311584473,
      "rewards/rejected": -7.698716640472412,
      "step": 4420
    },
    {
      "epoch": 4.7385603425207385,
      "grad_norm": 0.03700646013021469,
      "learning_rate": 2.6885245901639342e-08,
      "logits/chosen": 1.2563053369522095,
      "logits/rejected": 0.02359999157488346,
      "logps/chosen": -143.90951538085938,
      "logps/rejected": -146.03831481933594,
      "loss": 0.0005127305630594492,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7955032587051392,
      "rewards/margins": 8.578021049499512,
      "rewards/rejected": -7.782517910003662,
      "step": 4430
    },
    {
      "epoch": 4.74926411560075,
      "grad_norm": 0.010148263536393642,
      "learning_rate": 2.5792349726775956e-08,
      "logits/chosen": 1.289739727973938,
      "logits/rejected": -0.02401496097445488,
      "logps/chosen": -151.6258544921875,
      "logps/rejected": -146.14462280273438,
      "loss": 0.00046099764294922353,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8913715481758118,
      "rewards/margins": 8.67127799987793,
      "rewards/rejected": -7.779905796051025,
      "step": 4440
    },
    {
      "epoch": 4.75996788868076,
      "grad_norm": 0.012388844974339008,
      "learning_rate": 2.4699453551912567e-08,
      "logits/chosen": 1.308013677597046,
      "logits/rejected": 0.17266477644443512,
      "logps/chosen": -141.0997772216797,
      "logps/rejected": -144.10061645507812,
      "loss": 0.0005522834602743387,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9696931838989258,
      "rewards/margins": 8.515947341918945,
      "rewards/rejected": -7.5462541580200195,
      "step": 4450
    },
    {
      "epoch": 4.770671661760771,
      "grad_norm": 0.021028442308306694,
      "learning_rate": 2.3606557377049178e-08,
      "logits/chosen": 1.2800037860870361,
      "logits/rejected": 0.058405209332704544,
      "logps/chosen": -151.58799743652344,
      "logps/rejected": -144.3465118408203,
      "loss": 0.0004846481140702963,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9406383633613586,
      "rewards/margins": 8.646382331848145,
      "rewards/rejected": -7.705743312835693,
      "step": 4460
    },
    {
      "epoch": 4.781375434840782,
      "grad_norm": 0.02681322954595089,
      "learning_rate": 2.2513661202185792e-08,
      "logits/chosen": 1.3282060623168945,
      "logits/rejected": 0.03398093208670616,
      "logps/chosen": -160.5074920654297,
      "logps/rejected": -148.38192749023438,
      "loss": 0.00045561152510344984,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9469491243362427,
      "rewards/margins": 8.78337574005127,
      "rewards/rejected": -7.83642578125,
      "step": 4470
    },
    {
      "epoch": 4.792079207920792,
      "grad_norm": 0.14510485529899597,
      "learning_rate": 2.1420765027322406e-08,
      "logits/chosen": 1.2825498580932617,
      "logits/rejected": 0.03305840119719505,
      "logps/chosen": -143.1026153564453,
      "logps/rejected": -147.40309143066406,
      "loss": 0.00047302735038101673,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0064637660980225,
      "rewards/margins": 8.777766227722168,
      "rewards/rejected": -7.771303653717041,
      "step": 4480
    },
    {
      "epoch": 4.802782981000803,
      "grad_norm": 0.0766916275024414,
      "learning_rate": 2.0327868852459013e-08,
      "logits/chosen": 1.39962899684906,
      "logits/rejected": 0.00986169558018446,
      "logps/chosen": -157.20486450195312,
      "logps/rejected": -146.43511962890625,
      "loss": 0.0004135354422032833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.01923668384552,
      "rewards/margins": 8.807138442993164,
      "rewards/rejected": -7.787901878356934,
      "step": 4490
    },
    {
      "epoch": 4.813486754080813,
      "grad_norm": 0.02168591134250164,
      "learning_rate": 1.9234972677595627e-08,
      "logits/chosen": 1.251204490661621,
      "logits/rejected": 0.01622825488448143,
      "logps/chosen": -140.74307250976562,
      "logps/rejected": -147.77926635742188,
      "loss": 0.0003194012213498354,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0268882513046265,
      "rewards/margins": 8.906072616577148,
      "rewards/rejected": -7.879183769226074,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 4675,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
