{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5351886540005352,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010703773080010704,
      "grad_norm": 8.042835235595703,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.6620283126831055,
      "logits/rejected": 1.6317756175994873,
      "logps/chosen": -154.88954162597656,
      "logps/rejected": -68.91143798828125,
      "loss": 0.6929930686950684,
      "rewards/accuracies": 0.36250001192092896,
      "rewards/chosen": 0.0027783107943832874,
      "rewards/margins": 0.0006214429740794003,
      "rewards/rejected": 0.002156867878511548,
      "step": 10
    },
    {
      "epoch": 0.02140754616002141,
      "grad_norm": 7.908276557922363,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.6803842782974243,
      "logits/rejected": 1.6823651790618896,
      "logps/chosen": -172.01377868652344,
      "logps/rejected": -69.42620849609375,
      "loss": 0.6901248455047607,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.0032467462588101625,
      "rewards/margins": 0.006624302826821804,
      "rewards/rejected": -0.0033775572665035725,
      "step": 20
    },
    {
      "epoch": 0.03211131924003211,
      "grad_norm": 8.849369049072266,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.7294156551361084,
      "logits/rejected": 1.7146995067596436,
      "logps/chosen": -156.42025756835938,
      "logps/rejected": -68.60186004638672,
      "loss": 0.6883335113525391,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.0077818394638597965,
      "rewards/margins": 0.010242929682135582,
      "rewards/rejected": -0.0024610902182757854,
      "step": 30
    },
    {
      "epoch": 0.04281509232004282,
      "grad_norm": 7.736130714416504,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.6949303150177002,
      "logits/rejected": 1.6702102422714233,
      "logps/chosen": -163.21951293945312,
      "logps/rejected": -68.36978912353516,
      "loss": 0.6939249992370605,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004687915090471506,
      "rewards/margins": -0.000950565212406218,
      "rewards/rejected": 0.005638480186462402,
      "step": 40
    },
    {
      "epoch": 0.05351886540005352,
      "grad_norm": 7.328680992126465,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.6597477197647095,
      "logits/rejected": 1.6957956552505493,
      "logps/chosen": -164.46815490722656,
      "logps/rejected": -69.56840515136719,
      "loss": 0.6954107284545898,
      "rewards/accuracies": 0.38749998807907104,
      "rewards/chosen": -0.0025431732647120953,
      "rewards/margins": -0.003903585020452738,
      "rewards/rejected": 0.0013604119885712862,
      "step": 50
    },
    {
      "epoch": 0.06422263848006422,
      "grad_norm": 8.188251495361328,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.5828840732574463,
      "logits/rejected": 1.6658637523651123,
      "logps/chosen": -165.49407958984375,
      "logps/rejected": -69.3355484008789,
      "loss": 0.6892322063446045,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.007503075059503317,
      "rewards/margins": 0.008510095067322254,
      "rewards/rejected": -0.0010070180287584662,
      "step": 60
    },
    {
      "epoch": 0.07492641156007493,
      "grad_norm": 8.65149211883545,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.7149341106414795,
      "logits/rejected": 1.6704447269439697,
      "logps/chosen": -158.31288146972656,
      "logps/rejected": -69.85413360595703,
      "loss": 0.6899673461914062,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.004872560501098633,
      "rewards/margins": 0.00689715426415205,
      "rewards/rejected": -0.0020245935302227736,
      "step": 70
    },
    {
      "epoch": 0.08563018464008564,
      "grad_norm": 8.285731315612793,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.7061173915863037,
      "logits/rejected": 1.6593306064605713,
      "logps/chosen": -148.55221557617188,
      "logps/rejected": -68.52693939208984,
      "loss": 0.6900406360626221,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.0032034304458647966,
      "rewards/margins": 0.006800008472055197,
      "rewards/rejected": -0.0035965777933597565,
      "step": 80
    },
    {
      "epoch": 0.09633395772009633,
      "grad_norm": 8.954898834228516,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.6642587184906006,
      "logits/rejected": 1.6277955770492554,
      "logps/chosen": -158.2709197998047,
      "logps/rejected": -70.13672637939453,
      "loss": 0.6845562934875489,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.012011649087071419,
      "rewards/margins": 0.017708750441670418,
      "rewards/rejected": -0.005697102285921574,
      "step": 90
    },
    {
      "epoch": 0.10703773080010703,
      "grad_norm": 9.460087776184082,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.6440887451171875,
      "logits/rejected": 1.666945457458496,
      "logps/chosen": -157.4323272705078,
      "logps/rejected": -69.00125122070312,
      "loss": 0.6818899631500244,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.016707099974155426,
      "rewards/margins": 0.02356214076280594,
      "rewards/rejected": -0.006855040788650513,
      "step": 100
    },
    {
      "epoch": 0.11774150388011774,
      "grad_norm": 9.953648567199707,
      "learning_rate": 4.99016393442623e-07,
      "logits/chosen": 1.7171710729599,
      "logits/rejected": 1.6603634357452393,
      "logps/chosen": -174.9585418701172,
      "logps/rejected": -68.0926742553711,
      "loss": 0.6798484325408936,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.01922713965177536,
      "rewards/margins": 0.02738826908171177,
      "rewards/rejected": -0.008161130361258984,
      "step": 110
    },
    {
      "epoch": 0.12844527696012845,
      "grad_norm": 8.520073890686035,
      "learning_rate": 4.979234972677595e-07,
      "logits/chosen": 1.6902961730957031,
      "logits/rejected": 1.6549479961395264,
      "logps/chosen": -167.37828063964844,
      "logps/rejected": -69.44087982177734,
      "loss": 0.6729569435119629,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.031610604375600815,
      "rewards/margins": 0.04162018746137619,
      "rewards/rejected": -0.010009574703872204,
      "step": 120
    },
    {
      "epoch": 0.13914905004013914,
      "grad_norm": 9.898834228515625,
      "learning_rate": 4.968306010928961e-07,
      "logits/chosen": 1.6194766759872437,
      "logits/rejected": 1.6620088815689087,
      "logps/chosen": -152.73416137695312,
      "logps/rejected": -69.17903900146484,
      "loss": 0.6615282535552979,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.04378412291407585,
      "rewards/margins": 0.06479620933532715,
      "rewards/rejected": -0.021012086421251297,
      "step": 130
    },
    {
      "epoch": 0.14985282312014986,
      "grad_norm": 7.924726486206055,
      "learning_rate": 4.957377049180328e-07,
      "logits/chosen": 1.6532785892486572,
      "logits/rejected": 1.6689271926879883,
      "logps/chosen": -149.36196899414062,
      "logps/rejected": -68.09927368164062,
      "loss": 0.6616442680358887,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": 0.04494362697005272,
      "rewards/margins": 0.06471928209066391,
      "rewards/rejected": -0.01977565698325634,
      "step": 140
    },
    {
      "epoch": 0.16055659620016055,
      "grad_norm": 9.148638725280762,
      "learning_rate": 4.946448087431694e-07,
      "logits/chosen": 1.6315438747406006,
      "logits/rejected": 1.7217543125152588,
      "logps/chosen": -164.35971069335938,
      "logps/rejected": -69.40621185302734,
      "loss": 0.6517998218536377,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.055680327117443085,
      "rewards/margins": 0.08524040132761002,
      "rewards/rejected": -0.029560070484876633,
      "step": 150
    },
    {
      "epoch": 0.17126036928017127,
      "grad_norm": 10.011578559875488,
      "learning_rate": 4.935519125683059e-07,
      "logits/chosen": 1.730621337890625,
      "logits/rejected": 1.6951007843017578,
      "logps/chosen": -163.42745971679688,
      "logps/rejected": -69.35670471191406,
      "loss": 0.6403472900390625,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.07630730420351028,
      "rewards/margins": 0.10929622501134872,
      "rewards/rejected": -0.032988931983709335,
      "step": 160
    },
    {
      "epoch": 0.18196414236018196,
      "grad_norm": 8.293572425842285,
      "learning_rate": 4.924590163934426e-07,
      "logits/chosen": 1.7120643854141235,
      "logits/rejected": 1.6681219339370728,
      "logps/chosen": -160.22293090820312,
      "logps/rejected": -69.96358489990234,
      "loss": 0.6249523639678956,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09709646552801132,
      "rewards/margins": 0.14246416091918945,
      "rewards/rejected": -0.04536769166588783,
      "step": 170
    },
    {
      "epoch": 0.19266791544019266,
      "grad_norm": 8.27168083190918,
      "learning_rate": 4.913661202185792e-07,
      "logits/chosen": 1.6911976337432861,
      "logits/rejected": 1.638209342956543,
      "logps/chosen": -156.54566955566406,
      "logps/rejected": -69.0328140258789,
      "loss": 0.6169334411621094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10367057472467422,
      "rewards/margins": 0.15983103215694427,
      "rewards/rejected": -0.056160468608140945,
      "step": 180
    },
    {
      "epoch": 0.20337168852020338,
      "grad_norm": 8.73447322845459,
      "learning_rate": 4.902732240437159e-07,
      "logits/chosen": 1.7855793237686157,
      "logits/rejected": 1.6400638818740845,
      "logps/chosen": -158.33712768554688,
      "logps/rejected": -70.53496551513672,
      "loss": 0.6121816158294677,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.11388534307479858,
      "rewards/margins": 0.17062537372112274,
      "rewards/rejected": -0.05674004554748535,
      "step": 190
    },
    {
      "epoch": 0.21407546160021407,
      "grad_norm": 8.191123008728027,
      "learning_rate": 4.891803278688524e-07,
      "logits/chosen": 1.6980412006378174,
      "logits/rejected": 1.6481969356536865,
      "logps/chosen": -152.1992950439453,
      "logps/rejected": -68.19105529785156,
      "loss": 0.6061748027801513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1223047524690628,
      "rewards/margins": 0.18418067693710327,
      "rewards/rejected": -0.061875928193330765,
      "step": 200
    },
    {
      "epoch": 0.2247792346802248,
      "grad_norm": 10.072147369384766,
      "learning_rate": 4.88087431693989e-07,
      "logits/chosen": 1.6401643753051758,
      "logits/rejected": 1.7380163669586182,
      "logps/chosen": -157.94541931152344,
      "logps/rejected": -70.68669128417969,
      "loss": 0.5895828247070313,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.14281681180000305,
      "rewards/margins": 0.22147062420845032,
      "rewards/rejected": -0.07865382730960846,
      "step": 210
    },
    {
      "epoch": 0.23548300776023548,
      "grad_norm": 7.548822402954102,
      "learning_rate": 4.869945355191257e-07,
      "logits/chosen": 1.6622155904769897,
      "logits/rejected": 1.7017467021942139,
      "logps/chosen": -148.46351623535156,
      "logps/rejected": -69.21295928955078,
      "loss": 0.5830491065979004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14975541830062866,
      "rewards/margins": 0.235938161611557,
      "rewards/rejected": -0.08618275821208954,
      "step": 220
    },
    {
      "epoch": 0.2461867808402462,
      "grad_norm": 8.452560424804688,
      "learning_rate": 4.859016393442622e-07,
      "logits/chosen": 1.6331592798233032,
      "logits/rejected": 1.7276771068572998,
      "logps/chosen": -154.79164123535156,
      "logps/rejected": -70.20716857910156,
      "loss": 0.5672767639160157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17895743250846863,
      "rewards/margins": 0.27279460430145264,
      "rewards/rejected": -0.09383717179298401,
      "step": 230
    },
    {
      "epoch": 0.2568905539202569,
      "grad_norm": 7.775155544281006,
      "learning_rate": 4.848087431693989e-07,
      "logits/chosen": 1.697218894958496,
      "logits/rejected": 1.7532260417938232,
      "logps/chosen": -151.79420471191406,
      "logps/rejected": -70.38407897949219,
      "loss": 0.5580480098724365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18484637141227722,
      "rewards/margins": 0.2951138913631439,
      "rewards/rejected": -0.1102675050497055,
      "step": 240
    },
    {
      "epoch": 0.2675943270002676,
      "grad_norm": 7.7155351638793945,
      "learning_rate": 4.837158469945355e-07,
      "logits/chosen": 1.7367427349090576,
      "logits/rejected": 1.687816858291626,
      "logps/chosen": -156.65438842773438,
      "logps/rejected": -70.59455108642578,
      "loss": 0.538788890838623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21229608356952667,
      "rewards/margins": 0.34001052379608154,
      "rewards/rejected": -0.12771447002887726,
      "step": 250
    },
    {
      "epoch": 0.2782981000802783,
      "grad_norm": 7.714850902557373,
      "learning_rate": 4.826229508196722e-07,
      "logits/chosen": 1.7488590478897095,
      "logits/rejected": 1.7122571468353271,
      "logps/chosen": -159.88613891601562,
      "logps/rejected": -69.44705200195312,
      "loss": 0.531544303894043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2298315465450287,
      "rewards/margins": 0.35841742157936096,
      "rewards/rejected": -0.1285858452320099,
      "step": 260
    },
    {
      "epoch": 0.289001873160289,
      "grad_norm": 7.462470531463623,
      "learning_rate": 4.815300546448087e-07,
      "logits/chosen": 1.6619943380355835,
      "logits/rejected": 1.7232564687728882,
      "logps/chosen": -158.8004608154297,
      "logps/rejected": -70.70526885986328,
      "loss": 0.518095588684082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24078914523124695,
      "rewards/margins": 0.3924974799156189,
      "rewards/rejected": -0.15170833468437195,
      "step": 270
    },
    {
      "epoch": 0.2997056462402997,
      "grad_norm": 7.329143524169922,
      "learning_rate": 4.804371584699453e-07,
      "logits/chosen": 1.733319878578186,
      "logits/rejected": 1.7422233819961548,
      "logps/chosen": -156.47251892089844,
      "logps/rejected": -70.48951721191406,
      "loss": 0.5063504219055176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25117042660713196,
      "rewards/margins": 0.4227348268032074,
      "rewards/rejected": -0.17156442999839783,
      "step": 280
    },
    {
      "epoch": 0.3104094193203104,
      "grad_norm": 8.61311149597168,
      "learning_rate": 4.79344262295082e-07,
      "logits/chosen": 1.8045895099639893,
      "logits/rejected": 1.799299955368042,
      "logps/chosen": -163.0063934326172,
      "logps/rejected": -72.11375427246094,
      "loss": 0.4894240379333496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27973300218582153,
      "rewards/margins": 0.46572867035865784,
      "rewards/rejected": -0.1859956681728363,
      "step": 290
    },
    {
      "epoch": 0.3211131924003211,
      "grad_norm": 7.378121376037598,
      "learning_rate": 4.782513661202186e-07,
      "logits/chosen": 1.7040908336639404,
      "logits/rejected": 1.7486766576766968,
      "logps/chosen": -156.3368377685547,
      "logps/rejected": -69.96931457519531,
      "loss": 0.47478561401367186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31315600872039795,
      "rewards/margins": 0.5039626359939575,
      "rewards/rejected": -0.190806582570076,
      "step": 300
    },
    {
      "epoch": 0.3318169654803318,
      "grad_norm": 7.064162731170654,
      "learning_rate": 4.771584699453552e-07,
      "logits/chosen": 1.7980601787567139,
      "logits/rejected": 1.7381725311279297,
      "logps/chosen": -153.16200256347656,
      "logps/rejected": -71.08973693847656,
      "loss": 0.46725010871887207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31458261609077454,
      "rewards/margins": 0.525361180305481,
      "rewards/rejected": -0.21077856421470642,
      "step": 310
    },
    {
      "epoch": 0.34252073856034254,
      "grad_norm": 6.610952854156494,
      "learning_rate": 4.760655737704918e-07,
      "logits/chosen": 1.7534401416778564,
      "logits/rejected": 1.7501399517059326,
      "logps/chosen": -168.30015563964844,
      "logps/rejected": -71.00263977050781,
      "loss": 0.4474502086639404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3498777747154236,
      "rewards/margins": 0.5853263139724731,
      "rewards/rejected": -0.23544852435588837,
      "step": 320
    },
    {
      "epoch": 0.35322451164035323,
      "grad_norm": 6.845317840576172,
      "learning_rate": 4.749726775956284e-07,
      "logits/chosen": 1.8165700435638428,
      "logits/rejected": 1.750357985496521,
      "logps/chosen": -177.55010986328125,
      "logps/rejected": -71.16143798828125,
      "loss": 0.4265284061431885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3805598318576813,
      "rewards/margins": 0.6398438215255737,
      "rewards/rejected": -0.25928401947021484,
      "step": 330
    },
    {
      "epoch": 0.3639282847203639,
      "grad_norm": 6.692675590515137,
      "learning_rate": 4.73879781420765e-07,
      "logits/chosen": 1.7772655487060547,
      "logits/rejected": 1.8082275390625,
      "logps/chosen": -159.55142211914062,
      "logps/rejected": -71.16816711425781,
      "loss": 0.40757203102111816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4074929654598236,
      "rewards/margins": 0.6997970938682556,
      "rewards/rejected": -0.2923041582107544,
      "step": 340
    },
    {
      "epoch": 0.3746320578003746,
      "grad_norm": 5.849478721618652,
      "learning_rate": 4.727868852459016e-07,
      "logits/chosen": 1.7856992483139038,
      "logits/rejected": 1.774206519126892,
      "logps/chosen": -157.7308349609375,
      "logps/rejected": -70.65202331542969,
      "loss": 0.4171758651733398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3858453929424286,
      "rewards/margins": 0.6697971224784851,
      "rewards/rejected": -0.28395166993141174,
      "step": 350
    },
    {
      "epoch": 0.3853358308803853,
      "grad_norm": 6.871621608734131,
      "learning_rate": 4.7169398907103825e-07,
      "logits/chosen": 1.7737483978271484,
      "logits/rejected": 1.7897913455963135,
      "logps/chosen": -163.47891235351562,
      "logps/rejected": -71.0719985961914,
      "loss": 0.3919903039932251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4211021959781647,
      "rewards/margins": 0.745856523513794,
      "rewards/rejected": -0.3247542977333069,
      "step": 360
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 6.033052921295166,
      "learning_rate": 4.706010928961748e-07,
      "logits/chosen": 1.7575725317001343,
      "logits/rejected": 1.7525899410247803,
      "logps/chosen": -158.105712890625,
      "logps/rejected": -71.40069580078125,
      "loss": 0.38487725257873534,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4209696650505066,
      "rewards/margins": 0.7734045386314392,
      "rewards/rejected": -0.35243481397628784,
      "step": 370
    },
    {
      "epoch": 0.40674337704040675,
      "grad_norm": 5.977532863616943,
      "learning_rate": 4.695081967213115e-07,
      "logits/chosen": 1.738138198852539,
      "logits/rejected": 1.7429298162460327,
      "logps/chosen": -165.0994415283203,
      "logps/rejected": -72.59822082519531,
      "loss": 0.3554192543029785,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4993690848350525,
      "rewards/margins": 0.8690775036811829,
      "rewards/rejected": -0.3697083592414856,
      "step": 380
    },
    {
      "epoch": 0.41744715012041744,
      "grad_norm": 5.488399028778076,
      "learning_rate": 4.6841530054644806e-07,
      "logits/chosen": 1.6882820129394531,
      "logits/rejected": 1.784976601600647,
      "logps/chosen": -151.66372680664062,
      "logps/rejected": -73.06888580322266,
      "loss": 0.33793528079986573,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5386590361595154,
      "rewards/margins": 0.9236882328987122,
      "rewards/rejected": -0.3850291967391968,
      "step": 390
    },
    {
      "epoch": 0.42815092320042814,
      "grad_norm": 5.640366077423096,
      "learning_rate": 4.6732240437158464e-07,
      "logits/chosen": 1.770328164100647,
      "logits/rejected": 1.7905588150024414,
      "logps/chosen": -156.48995971679688,
      "logps/rejected": -72.52394104003906,
      "loss": 0.34104599952697756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5009521245956421,
      "rewards/margins": 0.9176923632621765,
      "rewards/rejected": -0.4167402386665344,
      "step": 400
    },
    {
      "epoch": 0.4388546962804388,
      "grad_norm": 5.513765811920166,
      "learning_rate": 4.662295081967213e-07,
      "logits/chosen": 1.7738593816757202,
      "logits/rejected": 1.7476686239242554,
      "logps/chosen": -160.97093200683594,
      "logps/rejected": -73.36878204345703,
      "loss": 0.3168286561965942,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5848418474197388,
      "rewards/margins": 1.0141011476516724,
      "rewards/rejected": -0.42925921082496643,
      "step": 410
    },
    {
      "epoch": 0.4495584693604496,
      "grad_norm": 5.140445709228516,
      "learning_rate": 4.651366120218579e-07,
      "logits/chosen": 1.8044955730438232,
      "logits/rejected": 1.8697763681411743,
      "logps/chosen": -160.54498291015625,
      "logps/rejected": -72.71686553955078,
      "loss": 0.3175292730331421,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5357639193534851,
      "rewards/margins": 0.998553454875946,
      "rewards/rejected": -0.46278953552246094,
      "step": 420
    },
    {
      "epoch": 0.46026224244046027,
      "grad_norm": 5.378852844238281,
      "learning_rate": 4.640437158469945e-07,
      "logits/chosen": 1.7668836116790771,
      "logits/rejected": 1.8253040313720703,
      "logps/chosen": -159.06869506835938,
      "logps/rejected": -73.11555480957031,
      "loss": 0.3142409324645996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5424200296401978,
      "rewards/margins": 1.0229847431182861,
      "rewards/rejected": -0.48056483268737793,
      "step": 430
    },
    {
      "epoch": 0.47096601552047096,
      "grad_norm": 4.926112651824951,
      "learning_rate": 4.6295081967213113e-07,
      "logits/chosen": 1.8253841400146484,
      "logits/rejected": 1.8405574560165405,
      "logps/chosen": -154.3362579345703,
      "logps/rejected": -73.98931884765625,
      "loss": 0.2918151617050171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5944596529006958,
      "rewards/margins": 1.11243736743927,
      "rewards/rejected": -0.5179777145385742,
      "step": 440
    },
    {
      "epoch": 0.48166978860048165,
      "grad_norm": 5.213535785675049,
      "learning_rate": 4.6185792349726776e-07,
      "logits/chosen": 1.7885091304779053,
      "logits/rejected": 1.8195703029632568,
      "logps/chosen": -159.6781768798828,
      "logps/rejected": -74.87156677246094,
      "loss": 0.2732362985610962,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6446535587310791,
      "rewards/margins": 1.1925660371780396,
      "rewards/rejected": -0.5479124188423157,
      "step": 450
    },
    {
      "epoch": 0.4923735616804924,
      "grad_norm": 4.465903282165527,
      "learning_rate": 4.607650273224044e-07,
      "logits/chosen": 1.8170499801635742,
      "logits/rejected": 1.7966291904449463,
      "logps/chosen": -154.4861297607422,
      "logps/rejected": -74.51118469238281,
      "loss": 0.26926634311676023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6413015723228455,
      "rewards/margins": 1.2055747509002686,
      "rewards/rejected": -0.5642733573913574,
      "step": 460
    },
    {
      "epoch": 0.5030773347605031,
      "grad_norm": 4.684820652008057,
      "learning_rate": 4.5967213114754095e-07,
      "logits/chosen": 1.8400636911392212,
      "logits/rejected": 1.8353493213653564,
      "logps/chosen": -162.42608642578125,
      "logps/rejected": -74.98222351074219,
      "loss": 0.2574610233306885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.652793288230896,
      "rewards/margins": 1.25051748752594,
      "rewards/rejected": -0.597724199295044,
      "step": 470
    },
    {
      "epoch": 0.5137811078405138,
      "grad_norm": 4.326503276824951,
      "learning_rate": 4.585792349726776e-07,
      "logits/chosen": 1.7971071004867554,
      "logits/rejected": 1.790305733680725,
      "logps/chosen": -159.56289672851562,
      "logps/rejected": -75.2584457397461,
      "loss": 0.23904845714569092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7037224769592285,
      "rewards/margins": 1.3411359786987305,
      "rewards/rejected": -0.6374134421348572,
      "step": 480
    },
    {
      "epoch": 0.5244848809205245,
      "grad_norm": 4.167069911956787,
      "learning_rate": 4.574863387978142e-07,
      "logits/chosen": 1.7841503620147705,
      "logits/rejected": 1.8653568029403687,
      "logps/chosen": -165.16070556640625,
      "logps/rejected": -76.31249237060547,
      "loss": 0.23473503589630126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7132250070571899,
      "rewards/margins": 1.3674430847167969,
      "rewards/rejected": -0.6542181968688965,
      "step": 490
    },
    {
      "epoch": 0.5351886540005352,
      "grad_norm": 4.156453609466553,
      "learning_rate": 4.563934426229508e-07,
      "logits/chosen": 1.8409897089004517,
      "logits/rejected": 1.8359819650650024,
      "logps/chosen": -142.95703125,
      "logps/rejected": -75.07670593261719,
      "loss": 0.23639342784881592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7014516592025757,
      "rewards/margins": 1.3671777248382568,
      "rewards/rejected": -0.6657260060310364,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 4675,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
