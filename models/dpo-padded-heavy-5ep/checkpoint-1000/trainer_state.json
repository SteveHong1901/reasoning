{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0695745250200697,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010703773080010704,
      "grad_norm": 8.042835235595703,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.6620283126831055,
      "logits/rejected": 1.6317756175994873,
      "logps/chosen": -154.88954162597656,
      "logps/rejected": -68.91143798828125,
      "loss": 0.6929930686950684,
      "rewards/accuracies": 0.36250001192092896,
      "rewards/chosen": 0.0027783107943832874,
      "rewards/margins": 0.0006214429740794003,
      "rewards/rejected": 0.002156867878511548,
      "step": 10
    },
    {
      "epoch": 0.02140754616002141,
      "grad_norm": 7.908276557922363,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.6803842782974243,
      "logits/rejected": 1.6823651790618896,
      "logps/chosen": -172.01377868652344,
      "logps/rejected": -69.42620849609375,
      "loss": 0.6901248455047607,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.0032467462588101625,
      "rewards/margins": 0.006624302826821804,
      "rewards/rejected": -0.0033775572665035725,
      "step": 20
    },
    {
      "epoch": 0.03211131924003211,
      "grad_norm": 8.849369049072266,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.7294156551361084,
      "logits/rejected": 1.7146995067596436,
      "logps/chosen": -156.42025756835938,
      "logps/rejected": -68.60186004638672,
      "loss": 0.6883335113525391,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.0077818394638597965,
      "rewards/margins": 0.010242929682135582,
      "rewards/rejected": -0.0024610902182757854,
      "step": 30
    },
    {
      "epoch": 0.04281509232004282,
      "grad_norm": 7.736130714416504,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.6949303150177002,
      "logits/rejected": 1.6702102422714233,
      "logps/chosen": -163.21951293945312,
      "logps/rejected": -68.36978912353516,
      "loss": 0.6939249992370605,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.004687915090471506,
      "rewards/margins": -0.000950565212406218,
      "rewards/rejected": 0.005638480186462402,
      "step": 40
    },
    {
      "epoch": 0.05351886540005352,
      "grad_norm": 7.328680992126465,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.6597477197647095,
      "logits/rejected": 1.6957956552505493,
      "logps/chosen": -164.46815490722656,
      "logps/rejected": -69.56840515136719,
      "loss": 0.6954107284545898,
      "rewards/accuracies": 0.38749998807907104,
      "rewards/chosen": -0.0025431732647120953,
      "rewards/margins": -0.003903585020452738,
      "rewards/rejected": 0.0013604119885712862,
      "step": 50
    },
    {
      "epoch": 0.06422263848006422,
      "grad_norm": 8.188251495361328,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.5828840732574463,
      "logits/rejected": 1.6658637523651123,
      "logps/chosen": -165.49407958984375,
      "logps/rejected": -69.3355484008789,
      "loss": 0.6892322063446045,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.007503075059503317,
      "rewards/margins": 0.008510095067322254,
      "rewards/rejected": -0.0010070180287584662,
      "step": 60
    },
    {
      "epoch": 0.07492641156007493,
      "grad_norm": 8.65149211883545,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.7149341106414795,
      "logits/rejected": 1.6704447269439697,
      "logps/chosen": -158.31288146972656,
      "logps/rejected": -69.85413360595703,
      "loss": 0.6899673461914062,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.004872560501098633,
      "rewards/margins": 0.00689715426415205,
      "rewards/rejected": -0.0020245935302227736,
      "step": 70
    },
    {
      "epoch": 0.08563018464008564,
      "grad_norm": 8.285731315612793,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.7061173915863037,
      "logits/rejected": 1.6593306064605713,
      "logps/chosen": -148.55221557617188,
      "logps/rejected": -68.52693939208984,
      "loss": 0.6900406360626221,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.0032034304458647966,
      "rewards/margins": 0.006800008472055197,
      "rewards/rejected": -0.0035965777933597565,
      "step": 80
    },
    {
      "epoch": 0.09633395772009633,
      "grad_norm": 8.954898834228516,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.6642587184906006,
      "logits/rejected": 1.6277955770492554,
      "logps/chosen": -158.2709197998047,
      "logps/rejected": -70.13672637939453,
      "loss": 0.6845562934875489,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.012011649087071419,
      "rewards/margins": 0.017708750441670418,
      "rewards/rejected": -0.005697102285921574,
      "step": 90
    },
    {
      "epoch": 0.10703773080010703,
      "grad_norm": 9.460087776184082,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.6440887451171875,
      "logits/rejected": 1.666945457458496,
      "logps/chosen": -157.4323272705078,
      "logps/rejected": -69.00125122070312,
      "loss": 0.6818899631500244,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.016707099974155426,
      "rewards/margins": 0.02356214076280594,
      "rewards/rejected": -0.006855040788650513,
      "step": 100
    },
    {
      "epoch": 0.11774150388011774,
      "grad_norm": 9.953648567199707,
      "learning_rate": 4.99016393442623e-07,
      "logits/chosen": 1.7171710729599,
      "logits/rejected": 1.6603634357452393,
      "logps/chosen": -174.9585418701172,
      "logps/rejected": -68.0926742553711,
      "loss": 0.6798484325408936,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": 0.01922713965177536,
      "rewards/margins": 0.02738826908171177,
      "rewards/rejected": -0.008161130361258984,
      "step": 110
    },
    {
      "epoch": 0.12844527696012845,
      "grad_norm": 8.520073890686035,
      "learning_rate": 4.979234972677595e-07,
      "logits/chosen": 1.6902961730957031,
      "logits/rejected": 1.6549479961395264,
      "logps/chosen": -167.37828063964844,
      "logps/rejected": -69.44087982177734,
      "loss": 0.6729569435119629,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.031610604375600815,
      "rewards/margins": 0.04162018746137619,
      "rewards/rejected": -0.010009574703872204,
      "step": 120
    },
    {
      "epoch": 0.13914905004013914,
      "grad_norm": 9.898834228515625,
      "learning_rate": 4.968306010928961e-07,
      "logits/chosen": 1.6194766759872437,
      "logits/rejected": 1.6620088815689087,
      "logps/chosen": -152.73416137695312,
      "logps/rejected": -69.17903900146484,
      "loss": 0.6615282535552979,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.04378412291407585,
      "rewards/margins": 0.06479620933532715,
      "rewards/rejected": -0.021012086421251297,
      "step": 130
    },
    {
      "epoch": 0.14985282312014986,
      "grad_norm": 7.924726486206055,
      "learning_rate": 4.957377049180328e-07,
      "logits/chosen": 1.6532785892486572,
      "logits/rejected": 1.6689271926879883,
      "logps/chosen": -149.36196899414062,
      "logps/rejected": -68.09927368164062,
      "loss": 0.6616442680358887,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": 0.04494362697005272,
      "rewards/margins": 0.06471928209066391,
      "rewards/rejected": -0.01977565698325634,
      "step": 140
    },
    {
      "epoch": 0.16055659620016055,
      "grad_norm": 9.148638725280762,
      "learning_rate": 4.946448087431694e-07,
      "logits/chosen": 1.6315438747406006,
      "logits/rejected": 1.7217543125152588,
      "logps/chosen": -164.35971069335938,
      "logps/rejected": -69.40621185302734,
      "loss": 0.6517998218536377,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.055680327117443085,
      "rewards/margins": 0.08524040132761002,
      "rewards/rejected": -0.029560070484876633,
      "step": 150
    },
    {
      "epoch": 0.17126036928017127,
      "grad_norm": 10.011578559875488,
      "learning_rate": 4.935519125683059e-07,
      "logits/chosen": 1.730621337890625,
      "logits/rejected": 1.6951007843017578,
      "logps/chosen": -163.42745971679688,
      "logps/rejected": -69.35670471191406,
      "loss": 0.6403472900390625,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.07630730420351028,
      "rewards/margins": 0.10929622501134872,
      "rewards/rejected": -0.032988931983709335,
      "step": 160
    },
    {
      "epoch": 0.18196414236018196,
      "grad_norm": 8.293572425842285,
      "learning_rate": 4.924590163934426e-07,
      "logits/chosen": 1.7120643854141235,
      "logits/rejected": 1.6681219339370728,
      "logps/chosen": -160.22293090820312,
      "logps/rejected": -69.96358489990234,
      "loss": 0.6249523639678956,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09709646552801132,
      "rewards/margins": 0.14246416091918945,
      "rewards/rejected": -0.04536769166588783,
      "step": 170
    },
    {
      "epoch": 0.19266791544019266,
      "grad_norm": 8.27168083190918,
      "learning_rate": 4.913661202185792e-07,
      "logits/chosen": 1.6911976337432861,
      "logits/rejected": 1.638209342956543,
      "logps/chosen": -156.54566955566406,
      "logps/rejected": -69.0328140258789,
      "loss": 0.6169334411621094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.10367057472467422,
      "rewards/margins": 0.15983103215694427,
      "rewards/rejected": -0.056160468608140945,
      "step": 180
    },
    {
      "epoch": 0.20337168852020338,
      "grad_norm": 8.73447322845459,
      "learning_rate": 4.902732240437159e-07,
      "logits/chosen": 1.7855793237686157,
      "logits/rejected": 1.6400638818740845,
      "logps/chosen": -158.33712768554688,
      "logps/rejected": -70.53496551513672,
      "loss": 0.6121816158294677,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.11388534307479858,
      "rewards/margins": 0.17062537372112274,
      "rewards/rejected": -0.05674004554748535,
      "step": 190
    },
    {
      "epoch": 0.21407546160021407,
      "grad_norm": 8.191123008728027,
      "learning_rate": 4.891803278688524e-07,
      "logits/chosen": 1.6980412006378174,
      "logits/rejected": 1.6481969356536865,
      "logps/chosen": -152.1992950439453,
      "logps/rejected": -68.19105529785156,
      "loss": 0.6061748027801513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1223047524690628,
      "rewards/margins": 0.18418067693710327,
      "rewards/rejected": -0.061875928193330765,
      "step": 200
    },
    {
      "epoch": 0.2247792346802248,
      "grad_norm": 10.072147369384766,
      "learning_rate": 4.88087431693989e-07,
      "logits/chosen": 1.6401643753051758,
      "logits/rejected": 1.7380163669586182,
      "logps/chosen": -157.94541931152344,
      "logps/rejected": -70.68669128417969,
      "loss": 0.5895828247070313,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.14281681180000305,
      "rewards/margins": 0.22147062420845032,
      "rewards/rejected": -0.07865382730960846,
      "step": 210
    },
    {
      "epoch": 0.23548300776023548,
      "grad_norm": 7.548822402954102,
      "learning_rate": 4.869945355191257e-07,
      "logits/chosen": 1.6622155904769897,
      "logits/rejected": 1.7017467021942139,
      "logps/chosen": -148.46351623535156,
      "logps/rejected": -69.21295928955078,
      "loss": 0.5830491065979004,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14975541830062866,
      "rewards/margins": 0.235938161611557,
      "rewards/rejected": -0.08618275821208954,
      "step": 220
    },
    {
      "epoch": 0.2461867808402462,
      "grad_norm": 8.452560424804688,
      "learning_rate": 4.859016393442622e-07,
      "logits/chosen": 1.6331592798233032,
      "logits/rejected": 1.7276771068572998,
      "logps/chosen": -154.79164123535156,
      "logps/rejected": -70.20716857910156,
      "loss": 0.5672767639160157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17895743250846863,
      "rewards/margins": 0.27279460430145264,
      "rewards/rejected": -0.09383717179298401,
      "step": 230
    },
    {
      "epoch": 0.2568905539202569,
      "grad_norm": 7.775155544281006,
      "learning_rate": 4.848087431693989e-07,
      "logits/chosen": 1.697218894958496,
      "logits/rejected": 1.7532260417938232,
      "logps/chosen": -151.79420471191406,
      "logps/rejected": -70.38407897949219,
      "loss": 0.5580480098724365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.18484637141227722,
      "rewards/margins": 0.2951138913631439,
      "rewards/rejected": -0.1102675050497055,
      "step": 240
    },
    {
      "epoch": 0.2675943270002676,
      "grad_norm": 7.7155351638793945,
      "learning_rate": 4.837158469945355e-07,
      "logits/chosen": 1.7367427349090576,
      "logits/rejected": 1.687816858291626,
      "logps/chosen": -156.65438842773438,
      "logps/rejected": -70.59455108642578,
      "loss": 0.538788890838623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21229608356952667,
      "rewards/margins": 0.34001052379608154,
      "rewards/rejected": -0.12771447002887726,
      "step": 250
    },
    {
      "epoch": 0.2782981000802783,
      "grad_norm": 7.714850902557373,
      "learning_rate": 4.826229508196722e-07,
      "logits/chosen": 1.7488590478897095,
      "logits/rejected": 1.7122571468353271,
      "logps/chosen": -159.88613891601562,
      "logps/rejected": -69.44705200195312,
      "loss": 0.531544303894043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2298315465450287,
      "rewards/margins": 0.35841742157936096,
      "rewards/rejected": -0.1285858452320099,
      "step": 260
    },
    {
      "epoch": 0.289001873160289,
      "grad_norm": 7.462470531463623,
      "learning_rate": 4.815300546448087e-07,
      "logits/chosen": 1.6619943380355835,
      "logits/rejected": 1.7232564687728882,
      "logps/chosen": -158.8004608154297,
      "logps/rejected": -70.70526885986328,
      "loss": 0.518095588684082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24078914523124695,
      "rewards/margins": 0.3924974799156189,
      "rewards/rejected": -0.15170833468437195,
      "step": 270
    },
    {
      "epoch": 0.2997056462402997,
      "grad_norm": 7.329143524169922,
      "learning_rate": 4.804371584699453e-07,
      "logits/chosen": 1.733319878578186,
      "logits/rejected": 1.7422233819961548,
      "logps/chosen": -156.47251892089844,
      "logps/rejected": -70.48951721191406,
      "loss": 0.5063504219055176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25117042660713196,
      "rewards/margins": 0.4227348268032074,
      "rewards/rejected": -0.17156442999839783,
      "step": 280
    },
    {
      "epoch": 0.3104094193203104,
      "grad_norm": 8.61311149597168,
      "learning_rate": 4.79344262295082e-07,
      "logits/chosen": 1.8045895099639893,
      "logits/rejected": 1.799299955368042,
      "logps/chosen": -163.0063934326172,
      "logps/rejected": -72.11375427246094,
      "loss": 0.4894240379333496,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27973300218582153,
      "rewards/margins": 0.46572867035865784,
      "rewards/rejected": -0.1859956681728363,
      "step": 290
    },
    {
      "epoch": 0.3211131924003211,
      "grad_norm": 7.378121376037598,
      "learning_rate": 4.782513661202186e-07,
      "logits/chosen": 1.7040908336639404,
      "logits/rejected": 1.7486766576766968,
      "logps/chosen": -156.3368377685547,
      "logps/rejected": -69.96931457519531,
      "loss": 0.47478561401367186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31315600872039795,
      "rewards/margins": 0.5039626359939575,
      "rewards/rejected": -0.190806582570076,
      "step": 300
    },
    {
      "epoch": 0.3318169654803318,
      "grad_norm": 7.064162731170654,
      "learning_rate": 4.771584699453552e-07,
      "logits/chosen": 1.7980601787567139,
      "logits/rejected": 1.7381725311279297,
      "logps/chosen": -153.16200256347656,
      "logps/rejected": -71.08973693847656,
      "loss": 0.46725010871887207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.31458261609077454,
      "rewards/margins": 0.525361180305481,
      "rewards/rejected": -0.21077856421470642,
      "step": 310
    },
    {
      "epoch": 0.34252073856034254,
      "grad_norm": 6.610952854156494,
      "learning_rate": 4.760655737704918e-07,
      "logits/chosen": 1.7534401416778564,
      "logits/rejected": 1.7501399517059326,
      "logps/chosen": -168.30015563964844,
      "logps/rejected": -71.00263977050781,
      "loss": 0.4474502086639404,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3498777747154236,
      "rewards/margins": 0.5853263139724731,
      "rewards/rejected": -0.23544852435588837,
      "step": 320
    },
    {
      "epoch": 0.35322451164035323,
      "grad_norm": 6.845317840576172,
      "learning_rate": 4.749726775956284e-07,
      "logits/chosen": 1.8165700435638428,
      "logits/rejected": 1.750357985496521,
      "logps/chosen": -177.55010986328125,
      "logps/rejected": -71.16143798828125,
      "loss": 0.4265284061431885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3805598318576813,
      "rewards/margins": 0.6398438215255737,
      "rewards/rejected": -0.25928401947021484,
      "step": 330
    },
    {
      "epoch": 0.3639282847203639,
      "grad_norm": 6.692675590515137,
      "learning_rate": 4.73879781420765e-07,
      "logits/chosen": 1.7772655487060547,
      "logits/rejected": 1.8082275390625,
      "logps/chosen": -159.55142211914062,
      "logps/rejected": -71.16816711425781,
      "loss": 0.40757203102111816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4074929654598236,
      "rewards/margins": 0.6997970938682556,
      "rewards/rejected": -0.2923041582107544,
      "step": 340
    },
    {
      "epoch": 0.3746320578003746,
      "grad_norm": 5.849478721618652,
      "learning_rate": 4.727868852459016e-07,
      "logits/chosen": 1.7856992483139038,
      "logits/rejected": 1.774206519126892,
      "logps/chosen": -157.7308349609375,
      "logps/rejected": -70.65202331542969,
      "loss": 0.4171758651733398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3858453929424286,
      "rewards/margins": 0.6697971224784851,
      "rewards/rejected": -0.28395166993141174,
      "step": 350
    },
    {
      "epoch": 0.3853358308803853,
      "grad_norm": 6.871621608734131,
      "learning_rate": 4.7169398907103825e-07,
      "logits/chosen": 1.7737483978271484,
      "logits/rejected": 1.7897913455963135,
      "logps/chosen": -163.47891235351562,
      "logps/rejected": -71.0719985961914,
      "loss": 0.3919903039932251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4211021959781647,
      "rewards/margins": 0.745856523513794,
      "rewards/rejected": -0.3247542977333069,
      "step": 360
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 6.033052921295166,
      "learning_rate": 4.706010928961748e-07,
      "logits/chosen": 1.7575725317001343,
      "logits/rejected": 1.7525899410247803,
      "logps/chosen": -158.105712890625,
      "logps/rejected": -71.40069580078125,
      "loss": 0.38487725257873534,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4209696650505066,
      "rewards/margins": 0.7734045386314392,
      "rewards/rejected": -0.35243481397628784,
      "step": 370
    },
    {
      "epoch": 0.40674337704040675,
      "grad_norm": 5.977532863616943,
      "learning_rate": 4.695081967213115e-07,
      "logits/chosen": 1.738138198852539,
      "logits/rejected": 1.7429298162460327,
      "logps/chosen": -165.0994415283203,
      "logps/rejected": -72.59822082519531,
      "loss": 0.3554192543029785,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4993690848350525,
      "rewards/margins": 0.8690775036811829,
      "rewards/rejected": -0.3697083592414856,
      "step": 380
    },
    {
      "epoch": 0.41744715012041744,
      "grad_norm": 5.488399028778076,
      "learning_rate": 4.6841530054644806e-07,
      "logits/chosen": 1.6882820129394531,
      "logits/rejected": 1.784976601600647,
      "logps/chosen": -151.66372680664062,
      "logps/rejected": -73.06888580322266,
      "loss": 0.33793528079986573,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5386590361595154,
      "rewards/margins": 0.9236882328987122,
      "rewards/rejected": -0.3850291967391968,
      "step": 390
    },
    {
      "epoch": 0.42815092320042814,
      "grad_norm": 5.640366077423096,
      "learning_rate": 4.6732240437158464e-07,
      "logits/chosen": 1.770328164100647,
      "logits/rejected": 1.7905588150024414,
      "logps/chosen": -156.48995971679688,
      "logps/rejected": -72.52394104003906,
      "loss": 0.34104599952697756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5009521245956421,
      "rewards/margins": 0.9176923632621765,
      "rewards/rejected": -0.4167402386665344,
      "step": 400
    },
    {
      "epoch": 0.4388546962804388,
      "grad_norm": 5.513765811920166,
      "learning_rate": 4.662295081967213e-07,
      "logits/chosen": 1.7738593816757202,
      "logits/rejected": 1.7476686239242554,
      "logps/chosen": -160.97093200683594,
      "logps/rejected": -73.36878204345703,
      "loss": 0.3168286561965942,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5848418474197388,
      "rewards/margins": 1.0141011476516724,
      "rewards/rejected": -0.42925921082496643,
      "step": 410
    },
    {
      "epoch": 0.4495584693604496,
      "grad_norm": 5.140445709228516,
      "learning_rate": 4.651366120218579e-07,
      "logits/chosen": 1.8044955730438232,
      "logits/rejected": 1.8697763681411743,
      "logps/chosen": -160.54498291015625,
      "logps/rejected": -72.71686553955078,
      "loss": 0.3175292730331421,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5357639193534851,
      "rewards/margins": 0.998553454875946,
      "rewards/rejected": -0.46278953552246094,
      "step": 420
    },
    {
      "epoch": 0.46026224244046027,
      "grad_norm": 5.378852844238281,
      "learning_rate": 4.640437158469945e-07,
      "logits/chosen": 1.7668836116790771,
      "logits/rejected": 1.8253040313720703,
      "logps/chosen": -159.06869506835938,
      "logps/rejected": -73.11555480957031,
      "loss": 0.3142409324645996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5424200296401978,
      "rewards/margins": 1.0229847431182861,
      "rewards/rejected": -0.48056483268737793,
      "step": 430
    },
    {
      "epoch": 0.47096601552047096,
      "grad_norm": 4.926112651824951,
      "learning_rate": 4.6295081967213113e-07,
      "logits/chosen": 1.8253841400146484,
      "logits/rejected": 1.8405574560165405,
      "logps/chosen": -154.3362579345703,
      "logps/rejected": -73.98931884765625,
      "loss": 0.2918151617050171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5944596529006958,
      "rewards/margins": 1.11243736743927,
      "rewards/rejected": -0.5179777145385742,
      "step": 440
    },
    {
      "epoch": 0.48166978860048165,
      "grad_norm": 5.213535785675049,
      "learning_rate": 4.6185792349726776e-07,
      "logits/chosen": 1.7885091304779053,
      "logits/rejected": 1.8195703029632568,
      "logps/chosen": -159.6781768798828,
      "logps/rejected": -74.87156677246094,
      "loss": 0.2732362985610962,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6446535587310791,
      "rewards/margins": 1.1925660371780396,
      "rewards/rejected": -0.5479124188423157,
      "step": 450
    },
    {
      "epoch": 0.4923735616804924,
      "grad_norm": 4.465903282165527,
      "learning_rate": 4.607650273224044e-07,
      "logits/chosen": 1.8170499801635742,
      "logits/rejected": 1.7966291904449463,
      "logps/chosen": -154.4861297607422,
      "logps/rejected": -74.51118469238281,
      "loss": 0.26926634311676023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6413015723228455,
      "rewards/margins": 1.2055747509002686,
      "rewards/rejected": -0.5642733573913574,
      "step": 460
    },
    {
      "epoch": 0.5030773347605031,
      "grad_norm": 4.684820652008057,
      "learning_rate": 4.5967213114754095e-07,
      "logits/chosen": 1.8400636911392212,
      "logits/rejected": 1.8353493213653564,
      "logps/chosen": -162.42608642578125,
      "logps/rejected": -74.98222351074219,
      "loss": 0.2574610233306885,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.652793288230896,
      "rewards/margins": 1.25051748752594,
      "rewards/rejected": -0.597724199295044,
      "step": 470
    },
    {
      "epoch": 0.5137811078405138,
      "grad_norm": 4.326503276824951,
      "learning_rate": 4.585792349726776e-07,
      "logits/chosen": 1.7971071004867554,
      "logits/rejected": 1.790305733680725,
      "logps/chosen": -159.56289672851562,
      "logps/rejected": -75.2584457397461,
      "loss": 0.23904845714569092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7037224769592285,
      "rewards/margins": 1.3411359786987305,
      "rewards/rejected": -0.6374134421348572,
      "step": 480
    },
    {
      "epoch": 0.5244848809205245,
      "grad_norm": 4.167069911956787,
      "learning_rate": 4.574863387978142e-07,
      "logits/chosen": 1.7841503620147705,
      "logits/rejected": 1.8653568029403687,
      "logps/chosen": -165.16070556640625,
      "logps/rejected": -76.31249237060547,
      "loss": 0.23473503589630126,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7132250070571899,
      "rewards/margins": 1.3674430847167969,
      "rewards/rejected": -0.6542181968688965,
      "step": 490
    },
    {
      "epoch": 0.5351886540005352,
      "grad_norm": 4.156453609466553,
      "learning_rate": 4.563934426229508e-07,
      "logits/chosen": 1.8409897089004517,
      "logits/rejected": 1.8359819650650024,
      "logps/chosen": -142.95703125,
      "logps/rejected": -75.07670593261719,
      "loss": 0.23639342784881592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7014516592025757,
      "rewards/margins": 1.3671777248382568,
      "rewards/rejected": -0.6657260060310364,
      "step": 500
    },
    {
      "epoch": 0.5458924270805459,
      "grad_norm": 3.7900516986846924,
      "learning_rate": 4.553005464480874e-07,
      "logits/chosen": 1.812766671180725,
      "logits/rejected": 1.8012014627456665,
      "logps/chosen": -150.61380004882812,
      "logps/rejected": -75.01448822021484,
      "loss": 0.22986876964569092,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7077286243438721,
      "rewards/margins": 1.4026319980621338,
      "rewards/rejected": -0.6949034333229065,
      "step": 510
    },
    {
      "epoch": 0.5565962001605566,
      "grad_norm": 3.4346323013305664,
      "learning_rate": 4.54207650273224e-07,
      "logits/chosen": 1.8092663288116455,
      "logits/rejected": 1.7893707752227783,
      "logps/chosen": -151.3472900390625,
      "logps/rejected": -75.72801208496094,
      "loss": 0.2132643222808838,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7562977075576782,
      "rewards/margins": 1.4790534973144531,
      "rewards/rejected": -0.7227557301521301,
      "step": 520
    },
    {
      "epoch": 0.5672999732405672,
      "grad_norm": 3.513603925704956,
      "learning_rate": 4.5311475409836064e-07,
      "logits/chosen": 1.7969367504119873,
      "logits/rejected": 1.824254035949707,
      "logps/chosen": -155.95095825195312,
      "logps/rejected": -75.7593765258789,
      "loss": 0.21915624141693116,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.731634795665741,
      "rewards/margins": 1.4689702987670898,
      "rewards/rejected": -0.7373355627059937,
      "step": 530
    },
    {
      "epoch": 0.578003746320578,
      "grad_norm": 4.138045787811279,
      "learning_rate": 4.520218579234972e-07,
      "logits/chosen": 1.7642877101898193,
      "logits/rejected": 1.820688009262085,
      "logps/chosen": -145.81431579589844,
      "logps/rejected": -76.89228820800781,
      "loss": 0.20521259307861328,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7130760550498962,
      "rewards/margins": 1.5259830951690674,
      "rewards/rejected": -0.8129068613052368,
      "step": 540
    },
    {
      "epoch": 0.5887075194005887,
      "grad_norm": 2.9567062854766846,
      "learning_rate": 4.509289617486339e-07,
      "logits/chosen": 1.7720463275909424,
      "logits/rejected": 1.7897975444793701,
      "logps/chosen": -152.9249267578125,
      "logps/rejected": -76.35782623291016,
      "loss": 0.1861492395401001,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7950961589813232,
      "rewards/margins": 1.630152940750122,
      "rewards/rejected": -0.8350567817687988,
      "step": 550
    },
    {
      "epoch": 0.5994112924805994,
      "grad_norm": 2.969787359237671,
      "learning_rate": 4.4983606557377046e-07,
      "logits/chosen": 1.791115403175354,
      "logits/rejected": 1.8092257976531982,
      "logps/chosen": -143.38133239746094,
      "logps/rejected": -77.51371765136719,
      "loss": 0.1971064567565918,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7465590238571167,
      "rewards/margins": 1.5867109298706055,
      "rewards/rejected": -0.8401519656181335,
      "step": 560
    },
    {
      "epoch": 0.6101150655606101,
      "grad_norm": 3.3995563983917236,
      "learning_rate": 4.487431693989071e-07,
      "logits/chosen": 1.8000361919403076,
      "logits/rejected": 1.8211749792099,
      "logps/chosen": -155.05215454101562,
      "logps/rejected": -79.23160552978516,
      "loss": 0.17334927320480348,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.785712480545044,
      "rewards/margins": 1.723633050918579,
      "rewards/rejected": -0.9379204511642456,
      "step": 570
    },
    {
      "epoch": 0.6208188386406208,
      "grad_norm": 3.103102922439575,
      "learning_rate": 4.476502732240437e-07,
      "logits/chosen": 1.739972710609436,
      "logits/rejected": 1.812269926071167,
      "logps/chosen": -146.7483673095703,
      "logps/rejected": -78.83075714111328,
      "loss": 0.1659580111503601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8500654101371765,
      "rewards/margins": 1.7748111486434937,
      "rewards/rejected": -0.9247457385063171,
      "step": 580
    },
    {
      "epoch": 0.6315226117206315,
      "grad_norm": 3.165898084640503,
      "learning_rate": 4.465573770491803e-07,
      "logits/chosen": 1.8384262323379517,
      "logits/rejected": 1.8030710220336914,
      "logps/chosen": -160.6950225830078,
      "logps/rejected": -78.15794372558594,
      "loss": 0.15289690494537353,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8729274868965149,
      "rewards/margins": 1.8413591384887695,
      "rewards/rejected": -0.9684314727783203,
      "step": 590
    },
    {
      "epoch": 0.6422263848006422,
      "grad_norm": 3.076017141342163,
      "learning_rate": 4.454644808743169e-07,
      "logits/chosen": 1.819422721862793,
      "logits/rejected": 1.8624855279922485,
      "logps/chosen": -150.9158477783203,
      "logps/rejected": -78.68762969970703,
      "loss": 0.15469962358474731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8495267629623413,
      "rewards/margins": 1.8539130687713623,
      "rewards/rejected": -1.0043861865997314,
      "step": 600
    },
    {
      "epoch": 0.6529301578806529,
      "grad_norm": 3.3542444705963135,
      "learning_rate": 4.4437158469945353e-07,
      "logits/chosen": 1.7931493520736694,
      "logits/rejected": 1.7662004232406616,
      "logps/chosen": -156.47067260742188,
      "logps/rejected": -78.69563293457031,
      "loss": 0.15708862543106078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8011693954467773,
      "rewards/margins": 1.8293449878692627,
      "rewards/rejected": -1.0281753540039062,
      "step": 610
    },
    {
      "epoch": 0.6636339309606636,
      "grad_norm": 3.179837226867676,
      "learning_rate": 4.4327868852459015e-07,
      "logits/chosen": 1.786595106124878,
      "logits/rejected": 1.820146918296814,
      "logps/chosen": -152.81436157226562,
      "logps/rejected": -79.03211975097656,
      "loss": 0.14858046770095826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8299798965454102,
      "rewards/margins": 1.9021879434585571,
      "rewards/rejected": -1.0722078084945679,
      "step": 620
    },
    {
      "epoch": 0.6743377040406744,
      "grad_norm": 2.931001901626587,
      "learning_rate": 4.421857923497268e-07,
      "logits/chosen": 1.7775561809539795,
      "logits/rejected": 1.7981802225112915,
      "logps/chosen": -155.6448211669922,
      "logps/rejected": -80.45366668701172,
      "loss": 0.15442954301834105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7538518905639648,
      "rewards/margins": 1.8623638153076172,
      "rewards/rejected": -1.1085119247436523,
      "step": 630
    },
    {
      "epoch": 0.6850414771206851,
      "grad_norm": 3.2971746921539307,
      "learning_rate": 4.410928961748634e-07,
      "logits/chosen": 1.7837142944335938,
      "logits/rejected": 1.7658417224884033,
      "logps/chosen": -151.1968231201172,
      "logps/rejected": -78.75161743164062,
      "loss": 0.14259451627731323,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8242725133895874,
      "rewards/margins": 1.9472805261611938,
      "rewards/rejected": -1.1230080127716064,
      "step": 640
    },
    {
      "epoch": 0.6957452502006958,
      "grad_norm": 2.9427597522735596,
      "learning_rate": 4.3999999999999997e-07,
      "logits/chosen": 1.843504548072815,
      "logits/rejected": 1.7960821390151978,
      "logps/chosen": -150.39749145507812,
      "logps/rejected": -80.89216613769531,
      "loss": 0.12209330797195435,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9342406392097473,
      "rewards/margins": 2.117431402206421,
      "rewards/rejected": -1.183190941810608,
      "step": 650
    },
    {
      "epoch": 0.7064490232807065,
      "grad_norm": 2.174078941345215,
      "learning_rate": 4.389071038251366e-07,
      "logits/chosen": 1.763603925704956,
      "logits/rejected": 1.781469702720642,
      "logps/chosen": -143.51356506347656,
      "logps/rejected": -80.98930358886719,
      "loss": 0.12900182008743286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8648360371589661,
      "rewards/margins": 2.0690298080444336,
      "rewards/rejected": -1.2041938304901123,
      "step": 660
    },
    {
      "epoch": 0.7171527963607172,
      "grad_norm": 2.731015920639038,
      "learning_rate": 4.378142076502732e-07,
      "logits/chosen": 1.850423812866211,
      "logits/rejected": 1.8077869415283203,
      "logps/chosen": -159.25588989257812,
      "logps/rejected": -81.06141662597656,
      "loss": 0.1196125864982605,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9192136526107788,
      "rewards/margins": 2.1484951972961426,
      "rewards/rejected": -1.2292816638946533,
      "step": 670
    },
    {
      "epoch": 0.7278565694407279,
      "grad_norm": 2.2992358207702637,
      "learning_rate": 4.367213114754098e-07,
      "logits/chosen": 1.8160632848739624,
      "logits/rejected": 1.8401365280151367,
      "logps/chosen": -140.0146026611328,
      "logps/rejected": -82.35936737060547,
      "loss": 0.11418379545211792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8760480880737305,
      "rewards/margins": 2.1694564819335938,
      "rewards/rejected": -1.2934086322784424,
      "step": 680
    },
    {
      "epoch": 0.7385603425207385,
      "grad_norm": 2.5261237621307373,
      "learning_rate": 4.3562841530054647e-07,
      "logits/chosen": 1.7846043109893799,
      "logits/rejected": 1.7177053689956665,
      "logps/chosen": -162.27255249023438,
      "logps/rejected": -82.38078308105469,
      "loss": 0.10433937311172485,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9660691022872925,
      "rewards/margins": 2.294405460357666,
      "rewards/rejected": -1.3283361196517944,
      "step": 690
    },
    {
      "epoch": 0.7492641156007492,
      "grad_norm": 2.0589141845703125,
      "learning_rate": 4.3453551912568304e-07,
      "logits/chosen": 1.776180624961853,
      "logits/rejected": 1.7863147258758545,
      "logps/chosen": -149.65113830566406,
      "logps/rejected": -82.73945617675781,
      "loss": 0.10204199552536011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9478128552436829,
      "rewards/margins": 2.3019299507141113,
      "rewards/rejected": -1.3541171550750732,
      "step": 700
    },
    {
      "epoch": 0.7599678886807599,
      "grad_norm": 1.904205083847046,
      "learning_rate": 4.334426229508196e-07,
      "logits/chosen": 1.8321046829223633,
      "logits/rejected": 1.7787792682647705,
      "logps/chosen": -169.90652465820312,
      "logps/rejected": -82.6867904663086,
      "loss": 0.09450395107269287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.998293399810791,
      "rewards/margins": 2.405311107635498,
      "rewards/rejected": -1.407017707824707,
      "step": 710
    },
    {
      "epoch": 0.7706716617607706,
      "grad_norm": 2.5522873401641846,
      "learning_rate": 4.323497267759563e-07,
      "logits/chosen": 1.7917639017105103,
      "logits/rejected": 1.7664276361465454,
      "logps/chosen": -149.2853240966797,
      "logps/rejected": -83.3419189453125,
      "loss": 0.09824571013450623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9395872354507446,
      "rewards/margins": 2.3770480155944824,
      "rewards/rejected": -1.4374607801437378,
      "step": 720
    },
    {
      "epoch": 0.7813754348407814,
      "grad_norm": 1.9055136442184448,
      "learning_rate": 4.3125683060109286e-07,
      "logits/chosen": 1.7494118213653564,
      "logits/rejected": 1.7055559158325195,
      "logps/chosen": -148.74447631835938,
      "logps/rejected": -85.08723449707031,
      "loss": 0.08772898316383362,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9730061292648315,
      "rewards/margins": 2.487753391265869,
      "rewards/rejected": -1.5147473812103271,
      "step": 730
    },
    {
      "epoch": 0.7920792079207921,
      "grad_norm": 1.6576265096664429,
      "learning_rate": 4.301639344262295e-07,
      "logits/chosen": 1.8033357858657837,
      "logits/rejected": 1.6875845193862915,
      "logps/chosen": -163.80084228515625,
      "logps/rejected": -84.67510986328125,
      "loss": 0.08052144050598145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0615533590316772,
      "rewards/margins": 2.60038423538208,
      "rewards/rejected": -1.5388309955596924,
      "step": 740
    },
    {
      "epoch": 0.8027829810008028,
      "grad_norm": 1.7653721570968628,
      "learning_rate": 4.290710382513661e-07,
      "logits/chosen": 1.8351141214370728,
      "logits/rejected": 1.65499746799469,
      "logps/chosen": -157.83262634277344,
      "logps/rejected": -84.69694519042969,
      "loss": 0.07486096620559693,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0277754068374634,
      "rewards/margins": 2.637855291366577,
      "rewards/rejected": -1.6100800037384033,
      "step": 750
    },
    {
      "epoch": 0.8134867540808135,
      "grad_norm": 1.6472928524017334,
      "learning_rate": 4.2797814207650273e-07,
      "logits/chosen": 1.6718753576278687,
      "logits/rejected": 1.6622778177261353,
      "logps/chosen": -146.2825469970703,
      "logps/rejected": -84.47618103027344,
      "loss": 0.07485225200653076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0219066143035889,
      "rewards/margins": 2.6572508811950684,
      "rewards/rejected": -1.6353442668914795,
      "step": 760
    },
    {
      "epoch": 0.8241905271608242,
      "grad_norm": 1.7153552770614624,
      "learning_rate": 4.268852459016393e-07,
      "logits/chosen": 1.7719131708145142,
      "logits/rejected": 1.681692361831665,
      "logps/chosen": -163.47219848632812,
      "logps/rejected": -86.72774505615234,
      "loss": 0.07162449955940246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0017569065093994,
      "rewards/margins": 2.702376365661621,
      "rewards/rejected": -1.7006194591522217,
      "step": 770
    },
    {
      "epoch": 0.8348943002408349,
      "grad_norm": 1.7915538549423218,
      "learning_rate": 4.257923497267759e-07,
      "logits/chosen": 1.7588112354278564,
      "logits/rejected": 1.761612892150879,
      "logps/chosen": -158.7922821044922,
      "logps/rejected": -85.04820251464844,
      "loss": 0.08087860941886901,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9474912881851196,
      "rewards/margins": 2.605459690093994,
      "rewards/rejected": -1.657968282699585,
      "step": 780
    },
    {
      "epoch": 0.8455980733208456,
      "grad_norm": 1.5435279607772827,
      "learning_rate": 4.2469945355191255e-07,
      "logits/chosen": 1.6815217733383179,
      "logits/rejected": 1.659170150756836,
      "logps/chosen": -141.67153930664062,
      "logps/rejected": -86.1138687133789,
      "loss": 0.07111806273460389,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.959647536277771,
      "rewards/margins": 2.725346326828003,
      "rewards/rejected": -1.765699028968811,
      "step": 790
    },
    {
      "epoch": 0.8563018464008563,
      "grad_norm": 1.192418098449707,
      "learning_rate": 4.2360655737704917e-07,
      "logits/chosen": 1.7205194234848022,
      "logits/rejected": 1.5790023803710938,
      "logps/chosen": -140.65902709960938,
      "logps/rejected": -87.70341491699219,
      "loss": 0.06502756476402283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0407321453094482,
      "rewards/margins": 2.853187084197998,
      "rewards/rejected": -1.8124549388885498,
      "step": 800
    },
    {
      "epoch": 0.867005619480867,
      "grad_norm": 1.2954949140548706,
      "learning_rate": 4.225136612021858e-07,
      "logits/chosen": 1.7844030857086182,
      "logits/rejected": 1.6893689632415771,
      "logps/chosen": -155.53677368164062,
      "logps/rejected": -86.67449188232422,
      "loss": 0.06417385935783386,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0463283061981201,
      "rewards/margins": 2.8428380489349365,
      "rewards/rejected": -1.796510100364685,
      "step": 810
    },
    {
      "epoch": 0.8777093925608777,
      "grad_norm": 1.8784531354904175,
      "learning_rate": 4.2142076502732236e-07,
      "logits/chosen": 1.8235204219818115,
      "logits/rejected": 1.739553451538086,
      "logps/chosen": -149.76885986328125,
      "logps/rejected": -87.57658386230469,
      "loss": 0.06573216319084167,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9877670407295227,
      "rewards/margins": 2.8412609100341797,
      "rewards/rejected": -1.8534940481185913,
      "step": 820
    },
    {
      "epoch": 0.8884131656408885,
      "grad_norm": 1.3906311988830566,
      "learning_rate": 4.2032786885245904e-07,
      "logits/chosen": 1.7170041799545288,
      "logits/rejected": 1.6727221012115479,
      "logps/chosen": -142.951904296875,
      "logps/rejected": -89.37434387207031,
      "loss": 0.05886092782020569,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.964301586151123,
      "rewards/margins": 2.9349441528320312,
      "rewards/rejected": -1.9706424474716187,
      "step": 830
    },
    {
      "epoch": 0.8991169387208992,
      "grad_norm": 0.9178356528282166,
      "learning_rate": 4.192349726775956e-07,
      "logits/chosen": 1.7838985919952393,
      "logits/rejected": 1.6357009410858154,
      "logps/chosen": -160.9322967529297,
      "logps/rejected": -87.64883422851562,
      "loss": 0.055837112665176394,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0890274047851562,
      "rewards/margins": 3.0316686630249023,
      "rewards/rejected": -1.9426414966583252,
      "step": 840
    },
    {
      "epoch": 0.9098207118009098,
      "grad_norm": 1.0754969120025635,
      "learning_rate": 4.181420765027322e-07,
      "logits/chosen": 1.788027048110962,
      "logits/rejected": 1.5935801267623901,
      "logps/chosen": -162.02935791015625,
      "logps/rejected": -89.02740478515625,
      "loss": 0.04708324670791626,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1095348596572876,
      "rewards/margins": 3.150054454803467,
      "rewards/rejected": -2.040519952774048,
      "step": 850
    },
    {
      "epoch": 0.9205244848809205,
      "grad_norm": 1.1452856063842773,
      "learning_rate": 4.1704918032786886e-07,
      "logits/chosen": 1.7593824863433838,
      "logits/rejected": 1.6450179815292358,
      "logps/chosen": -150.4923553466797,
      "logps/rejected": -89.09027862548828,
      "loss": 0.04953871369361877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0339109897613525,
      "rewards/margins": 3.0847699642181396,
      "rewards/rejected": -2.050858736038208,
      "step": 860
    },
    {
      "epoch": 0.9312282579609312,
      "grad_norm": 0.9945034384727478,
      "learning_rate": 4.1595628415300543e-07,
      "logits/chosen": 1.7284057140350342,
      "logits/rejected": 1.629233717918396,
      "logps/chosen": -161.48593139648438,
      "logps/rejected": -91.5926513671875,
      "loss": 0.04700658917427063,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0734291076660156,
      "rewards/margins": 3.232520580291748,
      "rewards/rejected": -2.1590917110443115,
      "step": 870
    },
    {
      "epoch": 0.9419320310409419,
      "grad_norm": 1.6321930885314941,
      "learning_rate": 4.1486338797814206e-07,
      "logits/chosen": 1.7180430889129639,
      "logits/rejected": 1.6240301132202148,
      "logps/chosen": -146.04124450683594,
      "logps/rejected": -90.5680923461914,
      "loss": 0.04806958734989166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9799259305000305,
      "rewards/margins": 3.1595466136932373,
      "rewards/rejected": -2.1796205043792725,
      "step": 880
    },
    {
      "epoch": 0.9526358041209526,
      "grad_norm": 0.8668941259384155,
      "learning_rate": 4.137704918032787e-07,
      "logits/chosen": 1.7094818353652954,
      "logits/rejected": 1.5231965780258179,
      "logps/chosen": -156.80088806152344,
      "logps/rejected": -92.11121368408203,
      "loss": 0.046077588200569154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9766501188278198,
      "rewards/margins": 3.239579439163208,
      "rewards/rejected": -2.2629292011260986,
      "step": 890
    },
    {
      "epoch": 0.9633395772009633,
      "grad_norm": 1.4290539026260376,
      "learning_rate": 4.126775956284153e-07,
      "logits/chosen": 1.7265279293060303,
      "logits/rejected": 1.584498405456543,
      "logps/chosen": -142.72727966308594,
      "logps/rejected": -92.38348388671875,
      "loss": 0.03659718930721283,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1476142406463623,
      "rewards/margins": 3.4494094848632812,
      "rewards/rejected": -2.301795244216919,
      "step": 900
    },
    {
      "epoch": 0.974043350280974,
      "grad_norm": 0.8241678476333618,
      "learning_rate": 4.115846994535519e-07,
      "logits/chosen": 1.7337844371795654,
      "logits/rejected": 1.58919358253479,
      "logps/chosen": -152.03326416015625,
      "logps/rejected": -92.68684387207031,
      "loss": 0.04033022522926331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0825837850570679,
      "rewards/margins": 3.392866611480713,
      "rewards/rejected": -2.3102829456329346,
      "step": 910
    },
    {
      "epoch": 0.9847471233609848,
      "grad_norm": 0.8369371891021729,
      "learning_rate": 4.104918032786885e-07,
      "logits/chosen": 1.8130000829696655,
      "logits/rejected": 1.5563679933547974,
      "logps/chosen": -177.03248596191406,
      "logps/rejected": -93.50448608398438,
      "loss": 0.032793253660202026,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1613147258758545,
      "rewards/margins": 3.574037551879883,
      "rewards/rejected": -2.412722587585449,
      "step": 920
    },
    {
      "epoch": 0.9954508964409955,
      "grad_norm": 0.588119387626648,
      "learning_rate": 4.093989071038251e-07,
      "logits/chosen": 1.7225919961929321,
      "logits/rejected": 1.517499566078186,
      "logps/chosen": -145.09872436523438,
      "logps/rejected": -93.66281127929688,
      "loss": 0.03417066931724548,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0797823667526245,
      "rewards/margins": 3.5223441123962402,
      "rewards/rejected": -2.4425618648529053,
      "step": 930
    },
    {
      "epoch": 1.0053518865400053,
      "grad_norm": 0.8849689364433289,
      "learning_rate": 4.083060109289617e-07,
      "logits/chosen": 1.5755726099014282,
      "logits/rejected": 1.4725950956344604,
      "logps/chosen": -132.5122833251953,
      "logps/rejected": -95.16565704345703,
      "loss": 0.03245730400085449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0501840114593506,
      "rewards/margins": 3.6119842529296875,
      "rewards/rejected": -2.561800241470337,
      "step": 940
    },
    {
      "epoch": 1.016055659620016,
      "grad_norm": 0.8366124033927917,
      "learning_rate": 4.0721311475409837e-07,
      "logits/chosen": 1.8341636657714844,
      "logits/rejected": 1.4668307304382324,
      "logps/chosen": -165.87979125976562,
      "logps/rejected": -95.01008605957031,
      "loss": 0.031292271614074704,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0788172483444214,
      "rewards/margins": 3.6775989532470703,
      "rewards/rejected": -2.5987815856933594,
      "step": 950
    },
    {
      "epoch": 1.0267594327000267,
      "grad_norm": 0.6333491802215576,
      "learning_rate": 4.0612021857923494e-07,
      "logits/chosen": 1.7061717510223389,
      "logits/rejected": 1.4761234521865845,
      "logps/chosen": -154.01495361328125,
      "logps/rejected": -96.00778198242188,
      "loss": 0.03177412748336792,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0302543640136719,
      "rewards/margins": 3.6437790393829346,
      "rewards/rejected": -2.6135246753692627,
      "step": 960
    },
    {
      "epoch": 1.0374632057800375,
      "grad_norm": 0.9965106844902039,
      "learning_rate": 4.0502732240437156e-07,
      "logits/chosen": 1.695291519165039,
      "logits/rejected": 1.5310051441192627,
      "logps/chosen": -151.8094940185547,
      "logps/rejected": -94.58476257324219,
      "loss": 0.028743746876716613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1636403799057007,
      "rewards/margins": 3.7653377056121826,
      "rewards/rejected": -2.6016972064971924,
      "step": 970
    },
    {
      "epoch": 1.048166978860048,
      "grad_norm": 0.7560970783233643,
      "learning_rate": 4.039344262295082e-07,
      "logits/chosen": 1.755011796951294,
      "logits/rejected": 1.3940136432647705,
      "logps/chosen": -167.62318420410156,
      "logps/rejected": -96.64051818847656,
      "loss": 0.023827163875102995,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1457898616790771,
      "rewards/margins": 3.9066014289855957,
      "rewards/rejected": -2.7608115673065186,
      "step": 980
    },
    {
      "epoch": 1.0588707519400589,
      "grad_norm": 0.8368943333625793,
      "learning_rate": 4.0284153005464476e-07,
      "logits/chosen": 1.7236073017120361,
      "logits/rejected": 1.471868872642517,
      "logps/chosen": -146.08102416992188,
      "logps/rejected": -95.93193054199219,
      "loss": 0.025808066129684448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1423739194869995,
      "rewards/margins": 3.8906846046447754,
      "rewards/rejected": -2.7483105659484863,
      "step": 990
    },
    {
      "epoch": 1.0695745250200697,
      "grad_norm": 0.5986548662185669,
      "learning_rate": 4.0174863387978144e-07,
      "logits/chosen": 1.644383192062378,
      "logits/rejected": 1.303471326828003,
      "logps/chosen": -149.46023559570312,
      "logps/rejected": -97.68709564208984,
      "loss": 0.022938047349452973,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1230791807174683,
      "rewards/margins": 3.9801979064941406,
      "rewards/rejected": -2.857118606567383,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 4675,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
