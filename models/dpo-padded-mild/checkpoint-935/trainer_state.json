{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 935,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010703773080010704,
      "grad_norm": 7.749534606933594,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.6386102437973022,
      "logits/rejected": 1.6341050863265991,
      "logps/chosen": -142.2468719482422,
      "logps/rejected": -68.85421752929688,
      "loss": 0.6956057548522949,
      "rewards/accuracies": 0.2750000059604645,
      "rewards/chosen": -0.005865964572876692,
      "rewards/margins": -0.00457597803324461,
      "rewards/rejected": -0.001289987238124013,
      "step": 10
    },
    {
      "epoch": 0.02140754616002141,
      "grad_norm": 8.052937507629395,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.6590404510498047,
      "logits/rejected": 1.6829729080200195,
      "logps/chosen": -157.90542602539062,
      "logps/rejected": -69.39391326904297,
      "loss": 0.6928775787353516,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.001132011180743575,
      "rewards/margins": 0.0011906143045052886,
      "rewards/rejected": -0.0023226263001561165,
      "step": 20
    },
    {
      "epoch": 0.03211131924003211,
      "grad_norm": 8.698307037353516,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.704846739768982,
      "logits/rejected": 1.7148845195770264,
      "logps/chosen": -145.9049072265625,
      "logps/rejected": -68.55137634277344,
      "loss": 0.6991735458374023,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.009928608313202858,
      "rewards/margins": -0.011501455679535866,
      "rewards/rejected": 0.0015728473663330078,
      "step": 30
    },
    {
      "epoch": 0.04281509232004282,
      "grad_norm": 7.451376438140869,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.6448873281478882,
      "logits/rejected": 1.6676737070083618,
      "logps/chosen": -145.00802612304688,
      "logps/rejected": -68.42008209228516,
      "loss": 0.6936444759368896,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.006066984962671995,
      "rewards/margins": -0.0004435914452187717,
      "rewards/rejected": -0.005623393226414919,
      "step": 40
    },
    {
      "epoch": 0.05351886540005352,
      "grad_norm": 6.916481018066406,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.6081171035766602,
      "logits/rejected": 1.6937837600708008,
      "logps/chosen": -150.61947631835938,
      "logps/rejected": -69.54265594482422,
      "loss": 0.6947578907012939,
      "rewards/accuracies": 0.42500001192092896,
      "rewards/chosen": -0.001154761528596282,
      "rewards/margins": -0.0026723144110292196,
      "rewards/rejected": 0.001517553231678903,
      "step": 50
    },
    {
      "epoch": 0.06422263848006422,
      "grad_norm": 7.561282157897949,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.5654462575912476,
      "logits/rejected": 1.6648428440093994,
      "logps/chosen": -150.66366577148438,
      "logps/rejected": -69.3353271484375,
      "loss": 0.6928158283233643,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -0.00040882109897211194,
      "rewards/margins": 0.0013186171418055892,
      "rewards/rejected": -0.0017274379497393966,
      "step": 60
    },
    {
      "epoch": 0.07492641156007493,
      "grad_norm": 8.580316543579102,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.6857200860977173,
      "logits/rejected": 1.669213056564331,
      "logps/chosen": -147.57305908203125,
      "logps/rejected": -69.85322570800781,
      "loss": 0.6902610778808593,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.0047585004940629005,
      "rewards/margins": 0.006304621696472168,
      "rewards/rejected": -0.0015461205039173365,
      "step": 70
    },
    {
      "epoch": 0.08563018464008564,
      "grad_norm": 7.7908782958984375,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.6832557916641235,
      "logits/rejected": 1.660133719444275,
      "logps/chosen": -140.07228088378906,
      "logps/rejected": -68.54820251464844,
      "loss": 0.6871943473815918,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.0025395252741873264,
      "rewards/margins": 0.012391148135066032,
      "rewards/rejected": -0.009851622395217419,
      "step": 80
    },
    {
      "epoch": 0.09633395772009633,
      "grad_norm": 8.094836235046387,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.635920524597168,
      "logits/rejected": 1.6247339248657227,
      "logps/chosen": -143.47265625,
      "logps/rejected": -70.15863800048828,
      "loss": 0.685413408279419,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.006183228455483913,
      "rewards/margins": 0.016164366155862808,
      "rewards/rejected": -0.00998113676905632,
      "step": 90
    },
    {
      "epoch": 0.10703773080010703,
      "grad_norm": 9.14108657836914,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.6177440881729126,
      "logits/rejected": 1.666069746017456,
      "logps/chosen": -145.54498291015625,
      "logps/rejected": -69.01045227050781,
      "loss": 0.6832215309143066,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.010029025375843048,
      "rewards/margins": 0.020749863237142563,
      "rewards/rejected": -0.01072083879262209,
      "step": 100
    },
    {
      "epoch": 0.11774150388011774,
      "grad_norm": 9.399163246154785,
      "learning_rate": 4.946107784431138e-07,
      "logits/chosen": 1.6870629787445068,
      "logits/rejected": 1.6587769985198975,
      "logps/chosen": -160.3252716064453,
      "logps/rejected": -68.1123275756836,
      "loss": 0.6741155624389649,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.02881716750562191,
      "rewards/margins": 0.039212148636579514,
      "rewards/rejected": -0.010394983924925327,
      "step": 110
    },
    {
      "epoch": 0.12844527696012845,
      "grad_norm": 8.395679473876953,
      "learning_rate": 4.886227544910179e-07,
      "logits/chosen": 1.65679931640625,
      "logits/rejected": 1.6548900604248047,
      "logps/chosen": -152.66201782226562,
      "logps/rejected": -69.43843841552734,
      "loss": 0.6722606658935547,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.02872874215245247,
      "rewards/margins": 0.04303393512964249,
      "rewards/rejected": -0.014305196702480316,
      "step": 120
    },
    {
      "epoch": 0.13914905004013914,
      "grad_norm": 9.176633834838867,
      "learning_rate": 4.826347305389221e-07,
      "logits/chosen": 1.606738805770874,
      "logits/rejected": 1.6602483987808228,
      "logps/chosen": -139.3529510498047,
      "logps/rejected": -69.15409851074219,
      "loss": 0.6656756401062012,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": 0.03757764771580696,
      "rewards/margins": 0.05641884356737137,
      "rewards/rejected": -0.01884119026362896,
      "step": 130
    },
    {
      "epoch": 0.14985282312014986,
      "grad_norm": 7.867959976196289,
      "learning_rate": 4.766467065868263e-07,
      "logits/chosen": 1.614119529724121,
      "logits/rejected": 1.6709896326065063,
      "logps/chosen": -136.20907592773438,
      "logps/rejected": -68.09628295898438,
      "loss": 0.6596052169799804,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.046946875751018524,
      "rewards/margins": 0.0688096135854721,
      "rewards/rejected": -0.021862726658582687,
      "step": 140
    },
    {
      "epoch": 0.16055659620016055,
      "grad_norm": 8.678658485412598,
      "learning_rate": 4.7065868263473054e-07,
      "logits/chosen": 1.6162242889404297,
      "logits/rejected": 1.7208006381988525,
      "logps/chosen": -151.5668487548828,
      "logps/rejected": -69.3865737915039,
      "loss": 0.6507754802703858,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": 0.06367187201976776,
      "rewards/margins": 0.08757273852825165,
      "rewards/rejected": -0.023900866508483887,
      "step": 150
    },
    {
      "epoch": 0.17126036928017127,
      "grad_norm": 9.591712951660156,
      "learning_rate": 4.646706586826347e-07,
      "logits/chosen": 1.6933132410049438,
      "logits/rejected": 1.695102334022522,
      "logps/chosen": -150.09304809570312,
      "logps/rejected": -69.39521789550781,
      "loss": 0.6411234378814697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06943677365779877,
      "rewards/margins": 0.10757599771022797,
      "rewards/rejected": -0.0381392166018486,
      "step": 160
    },
    {
      "epoch": 0.18196414236018196,
      "grad_norm": 8.143529891967773,
      "learning_rate": 4.586826347305389e-07,
      "logits/chosen": 1.696366548538208,
      "logits/rejected": 1.6655223369598389,
      "logps/chosen": -149.1695098876953,
      "logps/rejected": -70.0084457397461,
      "loss": 0.6317351341247559,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.08242126554250717,
      "rewards/margins": 0.12786832451820374,
      "rewards/rejected": -0.04544704779982567,
      "step": 170
    },
    {
      "epoch": 0.19266791544019266,
      "grad_norm": 8.209756851196289,
      "learning_rate": 4.5269461077844314e-07,
      "logits/chosen": 1.6590473651885986,
      "logits/rejected": 1.6364275217056274,
      "logps/chosen": -145.5922088623047,
      "logps/rejected": -69.02527618408203,
      "loss": 0.6177900314331055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1014733538031578,
      "rewards/margins": 0.1580965518951416,
      "rewards/rejected": -0.056623198091983795,
      "step": 180
    },
    {
      "epoch": 0.20337168852020338,
      "grad_norm": 8.193597793579102,
      "learning_rate": 4.4670658682634725e-07,
      "logits/chosen": 1.7697521448135376,
      "logits/rejected": 1.6386922597885132,
      "logps/chosen": -146.7029266357422,
      "logps/rejected": -70.54417419433594,
      "loss": 0.6068077564239502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11398857831954956,
      "rewards/margins": 0.18238355219364166,
      "rewards/rejected": -0.0683949738740921,
      "step": 190
    },
    {
      "epoch": 0.21407546160021407,
      "grad_norm": 8.08067798614502,
      "learning_rate": 4.4071856287425147e-07,
      "logits/chosen": 1.6602718830108643,
      "logits/rejected": 1.6452583074569702,
      "logps/chosen": -139.6817169189453,
      "logps/rejected": -68.24710083007812,
      "loss": 0.6016545295715332,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12559093534946442,
      "rewards/margins": 0.19353091716766357,
      "rewards/rejected": -0.06793998181819916,
      "step": 200
    },
    {
      "epoch": 0.2247792346802248,
      "grad_norm": 9.679850578308105,
      "learning_rate": 4.347305389221557e-07,
      "logits/chosen": 1.6305221319198608,
      "logits/rejected": 1.7394355535507202,
      "logps/chosen": -143.742919921875,
      "logps/rejected": -70.6789779663086,
      "loss": 0.5913937568664551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14124496281147003,
      "rewards/margins": 0.21740691363811493,
      "rewards/rejected": -0.07616196572780609,
      "step": 210
    },
    {
      "epoch": 0.23548300776023548,
      "grad_norm": 7.047687530517578,
      "learning_rate": 4.2874251497005985e-07,
      "logits/chosen": 1.6397289037704468,
      "logits/rejected": 1.6985533237457275,
      "logps/chosen": -136.897216796875,
      "logps/rejected": -69.24632263183594,
      "loss": 0.5802598476409913,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15014132857322693,
      "rewards/margins": 0.24179577827453613,
      "rewards/rejected": -0.0916544646024704,
      "step": 220
    },
    {
      "epoch": 0.2461867808402462,
      "grad_norm": 7.724626541137695,
      "learning_rate": 4.2275449101796407e-07,
      "logits/chosen": 1.5911871194839478,
      "logits/rejected": 1.7253954410552979,
      "logps/chosen": -138.46852111816406,
      "logps/rejected": -70.15869140625,
      "loss": 0.5742578506469727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16112802922725677,
      "rewards/margins": 0.25606992840766907,
      "rewards/rejected": -0.09494189918041229,
      "step": 230
    },
    {
      "epoch": 0.2568905539202569,
      "grad_norm": 7.438562393188477,
      "learning_rate": 4.167664670658683e-07,
      "logits/chosen": 1.6604454517364502,
      "logits/rejected": 1.7507503032684326,
      "logps/chosen": -137.58729553222656,
      "logps/rejected": -70.36237335205078,
      "loss": 0.5652000427246093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17011448740959167,
      "rewards/margins": 0.2779960632324219,
      "rewards/rejected": -0.1078815832734108,
      "step": 240
    },
    {
      "epoch": 0.2675943270002676,
      "grad_norm": 7.294968128204346,
      "learning_rate": 4.107784431137724e-07,
      "logits/chosen": 1.7211517095565796,
      "logits/rejected": 1.6822826862335205,
      "logps/chosen": -145.1071014404297,
      "logps/rejected": -70.56084442138672,
      "loss": 0.5448286533355713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20027288794517517,
      "rewards/margins": 0.32471030950546265,
      "rewards/rejected": -0.12443741410970688,
      "step": 250
    },
    {
      "epoch": 0.2782981000802783,
      "grad_norm": 7.325588703155518,
      "learning_rate": 4.047904191616766e-07,
      "logits/chosen": 1.7219759225845337,
      "logits/rejected": 1.7079336643218994,
      "logps/chosen": -144.18466186523438,
      "logps/rejected": -69.44859313964844,
      "loss": 0.5371213912963867,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21912388503551483,
      "rewards/margins": 0.3443305790424347,
      "rewards/rejected": -0.12520667910575867,
      "step": 260
    },
    {
      "epoch": 0.289001873160289,
      "grad_norm": 6.935419082641602,
      "learning_rate": 3.9880239520958084e-07,
      "logits/chosen": 1.6424560546875,
      "logits/rejected": 1.716376543045044,
      "logps/chosen": -144.5414276123047,
      "logps/rejected": -70.6113510131836,
      "loss": 0.5330044746398925,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20996996760368347,
      "rewards/margins": 0.35539451241493225,
      "rewards/rejected": -0.14542452991008759,
      "step": 270
    },
    {
      "epoch": 0.2997056462402997,
      "grad_norm": 7.228213787078857,
      "learning_rate": 3.92814371257485e-07,
      "logits/chosen": 1.7079381942749023,
      "logits/rejected": 1.733976125717163,
      "logps/chosen": -143.84326171875,
      "logps/rejected": -70.37006378173828,
      "loss": 0.5159739017486572,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23778924345970154,
      "rewards/margins": 0.3967912793159485,
      "rewards/rejected": -0.15900200605392456,
      "step": 280
    },
    {
      "epoch": 0.3104094193203104,
      "grad_norm": 8.05090045928955,
      "learning_rate": 3.868263473053892e-07,
      "logits/chosen": 1.7840582132339478,
      "logits/rejected": 1.7894229888916016,
      "logps/chosen": -150.17330932617188,
      "logps/rejected": -71.97957611083984,
      "loss": 0.5038358688354492,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25261393189430237,
      "rewards/margins": 0.4284713864326477,
      "rewards/rejected": -0.17585746943950653,
      "step": 290
    },
    {
      "epoch": 0.3211131924003211,
      "grad_norm": 7.2161054611206055,
      "learning_rate": 3.8083832335329344e-07,
      "logits/chosen": 1.6528106927871704,
      "logits/rejected": 1.733485460281372,
      "logps/chosen": -141.58935546875,
      "logps/rejected": -69.84529113769531,
      "loss": 0.48693695068359377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2853284776210785,
      "rewards/margins": 0.47056418657302856,
      "rewards/rejected": -0.18523570895195007,
      "step": 300
    },
    {
      "epoch": 0.3318169654803318,
      "grad_norm": 6.972319602966309,
      "learning_rate": 3.748502994011976e-07,
      "logits/chosen": 1.772904634475708,
      "logits/rejected": 1.723565697669983,
      "logps/chosen": -141.63970947265625,
      "logps/rejected": -70.94783020019531,
      "loss": 0.48618507385253906,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27496328949928284,
      "rewards/margins": 0.4740881323814392,
      "rewards/rejected": -0.19912487268447876,
      "step": 310
    },
    {
      "epoch": 0.34252073856034254,
      "grad_norm": 6.828237533569336,
      "learning_rate": 3.6886227544910177e-07,
      "logits/chosen": 1.7217185497283936,
      "logits/rejected": 1.737383484840393,
      "logps/chosen": -151.706298828125,
      "logps/rejected": -70.70848083496094,
      "loss": 0.4743024826049805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29669347405433655,
      "rewards/margins": 0.5061872601509094,
      "rewards/rejected": -0.20949378609657288,
      "step": 320
    },
    {
      "epoch": 0.35322451164035323,
      "grad_norm": 7.068118572235107,
      "learning_rate": 3.6287425149700593e-07,
      "logits/chosen": 1.7742153406143188,
      "logits/rejected": 1.7355537414550781,
      "logps/chosen": -157.36465454101562,
      "logps/rejected": -70.80631256103516,
      "loss": 0.45133328437805176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3387316167354584,
      "rewards/margins": 0.5668846368789673,
      "rewards/rejected": -0.2281530350446701,
      "step": 330
    },
    {
      "epoch": 0.3639282847203639,
      "grad_norm": 7.044462203979492,
      "learning_rate": 3.5688622754491015e-07,
      "logits/chosen": 1.7302125692367554,
      "logits/rejected": 1.7909348011016846,
      "logps/chosen": -143.6007843017578,
      "logps/rejected": -70.85469818115234,
      "loss": 0.43280901908874514,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3599672317504883,
      "rewards/margins": 0.622040867805481,
      "rewards/rejected": -0.26207366585731506,
      "step": 340
    },
    {
      "epoch": 0.3746320578003746,
      "grad_norm": 6.152693271636963,
      "learning_rate": 3.5089820359281437e-07,
      "logits/chosen": 1.735661506652832,
      "logits/rejected": 1.7560594081878662,
      "logps/chosen": -142.8195037841797,
      "logps/rejected": -70.2818374633789,
      "loss": 0.44544501304626466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33374807238578796,
      "rewards/margins": 0.5845711827278137,
      "rewards/rejected": -0.25082308053970337,
      "step": 350
    },
    {
      "epoch": 0.3853358308803853,
      "grad_norm": 6.800623416900635,
      "learning_rate": 3.4491017964071854e-07,
      "logits/chosen": 1.7319329977035522,
      "logits/rejected": 1.7711904048919678,
      "logps/chosen": -146.68618774414062,
      "logps/rejected": -70.66557312011719,
      "loss": 0.42503933906555175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36174336075782776,
      "rewards/margins": 0.6437180042266846,
      "rewards/rejected": -0.2819747030735016,
      "step": 360
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 6.273284435272217,
      "learning_rate": 3.3892215568862275e-07,
      "logits/chosen": 1.7286608219146729,
      "logits/rejected": 1.7357441186904907,
      "logps/chosen": -145.67459106445312,
      "logps/rejected": -70.86426544189453,
      "loss": 0.42134413719177244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36360034346580505,
      "rewards/margins": 0.659022867679596,
      "rewards/rejected": -0.2954224944114685,
      "step": 370
    },
    {
      "epoch": 0.40674337704040675,
      "grad_norm": 6.540586471557617,
      "learning_rate": 3.3293413173652697e-07,
      "logits/chosen": 1.6903159618377686,
      "logits/rejected": 1.7236621379852295,
      "logps/chosen": -153.5884246826172,
      "logps/rejected": -72.02792358398438,
      "loss": 0.40235300064086915,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3996214270591736,
      "rewards/margins": 0.7140001058578491,
      "rewards/rejected": -0.31437867879867554,
      "step": 380
    },
    {
      "epoch": 0.41744715012041744,
      "grad_norm": 5.966968059539795,
      "learning_rate": 3.269461077844311e-07,
      "logits/chosen": 1.6529152393341064,
      "logits/rejected": 1.7658876180648804,
      "logps/chosen": -138.8733367919922,
      "logps/rejected": -72.3782958984375,
      "loss": 0.3820918321609497,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45754772424697876,
      "rewards/margins": 0.7747176885604858,
      "rewards/rejected": -0.31716999411582947,
      "step": 390
    },
    {
      "epoch": 0.42815092320042814,
      "grad_norm": 6.0693840980529785,
      "learning_rate": 3.209580838323353e-07,
      "logits/chosen": 1.7124595642089844,
      "logits/rejected": 1.7621967792510986,
      "logps/chosen": -145.87594604492188,
      "logps/rejected": -71.7154769897461,
      "loss": 0.3908966064453125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41245174407958984,
      "rewards/margins": 0.7477288842201233,
      "rewards/rejected": -0.33527714014053345,
      "step": 400
    },
    {
      "epoch": 0.4388546962804388,
      "grad_norm": 6.058930397033691,
      "learning_rate": 3.149700598802395e-07,
      "logits/chosen": 1.7023407220840454,
      "logits/rejected": 1.7199970483779907,
      "logps/chosen": -145.56149291992188,
      "logps/rejected": -72.53071594238281,
      "loss": 0.3660987138748169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48805490136146545,
      "rewards/margins": 0.8335456848144531,
      "rewards/rejected": -0.34549081325531006,
      "step": 410
    },
    {
      "epoch": 0.4495584693604496,
      "grad_norm": 5.7864990234375,
      "learning_rate": 3.089820359281437e-07,
      "logits/chosen": 1.775132417678833,
      "logits/rejected": 1.8398656845092773,
      "logps/chosen": -147.75180053710938,
      "logps/rejected": -71.70549011230469,
      "loss": 0.3741612911224365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4403243958950043,
      "rewards/margins": 0.8017618060112,
      "rewards/rejected": -0.36143746972084045,
      "step": 420
    },
    {
      "epoch": 0.46026224244046027,
      "grad_norm": 5.906116485595703,
      "learning_rate": 3.029940119760479e-07,
      "logits/chosen": 1.7171663045883179,
      "logits/rejected": 1.79586923122406,
      "logps/chosen": -143.77223205566406,
      "logps/rejected": -71.98396301269531,
      "loss": 0.3707864284515381,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4481941759586334,
      "rewards/margins": 0.8193783760070801,
      "rewards/rejected": -0.37118417024612427,
      "step": 430
    },
    {
      "epoch": 0.47096601552047096,
      "grad_norm": 5.669434070587158,
      "learning_rate": 2.970059880239521e-07,
      "logits/chosen": 1.7775344848632812,
      "logits/rejected": 1.8110110759735107,
      "logps/chosen": -140.7774658203125,
      "logps/rejected": -72.6899642944336,
      "loss": 0.35381712913513186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4872860014438629,
      "rewards/margins": 0.8757435083389282,
      "rewards/rejected": -0.3884574770927429,
      "step": 440
    },
    {
      "epoch": 0.48166978860048165,
      "grad_norm": 6.158790111541748,
      "learning_rate": 2.9101796407185623e-07,
      "logits/chosen": 1.7440952062606812,
      "logits/rejected": 1.787705421447754,
      "logps/chosen": -147.64334106445312,
      "logps/rejected": -73.48149108886719,
      "loss": 0.34398641586303713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5083939433097839,
      "rewards/margins": 0.9120082855224609,
      "rewards/rejected": -0.403614342212677,
      "step": 450
    },
    {
      "epoch": 0.4923735616804924,
      "grad_norm": 5.360244274139404,
      "learning_rate": 2.8502994011976045e-07,
      "logits/chosen": 1.7614514827728271,
      "logits/rejected": 1.7664897441864014,
      "logps/chosen": -141.90225219726562,
      "logps/rejected": -73.04267883300781,
      "loss": 0.33785262107849123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5058937072753906,
      "rewards/margins": 0.9288221597671509,
      "rewards/rejected": -0.4229283928871155,
      "step": 460
    },
    {
      "epoch": 0.5030773347605031,
      "grad_norm": 5.5311384201049805,
      "learning_rate": 2.7904191616766467e-07,
      "logits/chosen": 1.7972408533096313,
      "logits/rejected": 1.8077335357666016,
      "logps/chosen": -150.16925048828125,
      "logps/rejected": -73.39543151855469,
      "loss": 0.3268528938293457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5205182433128357,
      "rewards/margins": 0.9633939862251282,
      "rewards/rejected": -0.4428756833076477,
      "step": 470
    },
    {
      "epoch": 0.5137811078405138,
      "grad_norm": 5.4320387840271,
      "learning_rate": 2.7305389221556884e-07,
      "logits/chosen": 1.7308101654052734,
      "logits/rejected": 1.7627121210098267,
      "logps/chosen": -143.23165893554688,
      "logps/rejected": -73.47777557373047,
      "loss": 0.31190588474273684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.56322181224823,
      "rewards/margins": 1.024387240409851,
      "rewards/rejected": -0.46116551756858826,
      "step": 480
    },
    {
      "epoch": 0.5244848809205245,
      "grad_norm": 5.4135613441467285,
      "learning_rate": 2.6706586826347305e-07,
      "logits/chosen": 1.7359310388565063,
      "logits/rejected": 1.8377645015716553,
      "logps/chosen": -150.90682983398438,
      "logps/rejected": -74.45719909667969,
      "loss": 0.30845506191253663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5669752359390259,
      "rewards/margins": 1.0412242412567139,
      "rewards/rejected": -0.4742489755153656,
      "step": 490
    },
    {
      "epoch": 0.5351886540005352,
      "grad_norm": 5.1799445152282715,
      "learning_rate": 2.6107784431137727e-07,
      "logits/chosen": 1.7868820428848267,
      "logits/rejected": 1.8129628896713257,
      "logps/chosen": -134.04782104492188,
      "logps/rejected": -73.04761505126953,
      "loss": 0.3189507722854614,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5379789471626282,
      "rewards/margins": 1.0052403211593628,
      "rewards/rejected": -0.467261403799057,
      "step": 500
    },
    {
      "epoch": 0.5458924270805459,
      "grad_norm": 5.158182621002197,
      "learning_rate": 2.5508982035928144e-07,
      "logits/chosen": 1.765777349472046,
      "logits/rejected": 1.7790120840072632,
      "logps/chosen": -139.2451629638672,
      "logps/rejected": -72.92169189453125,
      "loss": 0.30747289657592775,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5601083040237427,
      "rewards/margins": 1.0514743328094482,
      "rewards/rejected": -0.4913661479949951,
      "step": 510
    },
    {
      "epoch": 0.5565962001605566,
      "grad_norm": 4.957439422607422,
      "learning_rate": 2.491017964071856e-07,
      "logits/chosen": 1.7534801959991455,
      "logits/rejected": 1.7656141519546509,
      "logps/chosen": -137.3502960205078,
      "logps/rejected": -73.47996520996094,
      "loss": 0.29703123569488527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5883492231369019,
      "rewards/margins": 1.0850014686584473,
      "rewards/rejected": -0.496652215719223,
      "step": 520
    },
    {
      "epoch": 0.5672999732405672,
      "grad_norm": 4.8131794929504395,
      "learning_rate": 2.431137724550898e-07,
      "logits/chosen": 1.741633653640747,
      "logits/rejected": 1.8076671361923218,
      "logps/chosen": -143.61611938476562,
      "logps/rejected": -73.49860382080078,
      "loss": 0.29990086555480955,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5694304704666138,
      "rewards/margins": 1.0833344459533691,
      "rewards/rejected": -0.5139039754867554,
      "step": 530
    },
    {
      "epoch": 0.578003746320578,
      "grad_norm": 5.162651062011719,
      "learning_rate": 2.3712574850299399e-07,
      "logits/chosen": 1.7189785242080688,
      "logits/rejected": 1.8071177005767822,
      "logps/chosen": -133.5211944580078,
      "logps/rejected": -74.31938171386719,
      "loss": 0.29055907726287844,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5600074529647827,
      "rewards/margins": 1.1181001663208008,
      "rewards/rejected": -0.5580927133560181,
      "step": 540
    },
    {
      "epoch": 0.5887075194005887,
      "grad_norm": 4.6631178855896,
      "learning_rate": 2.311377245508982e-07,
      "logits/chosen": 1.7243083715438843,
      "logits/rejected": 1.7784349918365479,
      "logps/chosen": -145.45767211914062,
      "logps/rejected": -73.64686584472656,
      "loss": 0.2670530557632446,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6413298845291138,
      "rewards/margins": 1.2058011293411255,
      "rewards/rejected": -0.5644712448120117,
      "step": 550
    },
    {
      "epoch": 0.5994112924805994,
      "grad_norm": 4.421760559082031,
      "learning_rate": 2.251497005988024e-07,
      "logits/chosen": 1.7561782598495483,
      "logits/rejected": 1.798410177230835,
      "logps/chosen": -132.97817993164062,
      "logps/rejected": -74.76167297363281,
      "loss": 0.285127854347229,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5784030556678772,
      "rewards/margins": 1.1433675289154053,
      "rewards/rejected": -0.5649645328521729,
      "step": 560
    },
    {
      "epoch": 0.6101150655606101,
      "grad_norm": 4.521356105804443,
      "learning_rate": 2.1916167664670656e-07,
      "logits/chosen": 1.7589542865753174,
      "logits/rejected": 1.8194202184677124,
      "logps/chosen": -144.3858184814453,
      "logps/rejected": -76.12110900878906,
      "loss": 0.26527581214904783,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5918964743614197,
      "rewards/margins": 1.217888593673706,
      "rewards/rejected": -0.6259921193122864,
      "step": 570
    },
    {
      "epoch": 0.6208188386406208,
      "grad_norm": 4.41516637802124,
      "learning_rate": 2.1317365269461078e-07,
      "logits/chosen": 1.6733496189117432,
      "logits/rejected": 1.8083419799804688,
      "logps/chosen": -134.78207397460938,
      "logps/rejected": -75.51148986816406,
      "loss": 0.2554614067077637,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6761244535446167,
      "rewards/margins": 1.268859624862671,
      "rewards/rejected": -0.5927351713180542,
      "step": 580
    },
    {
      "epoch": 0.6315226117206315,
      "grad_norm": 4.49969482421875,
      "learning_rate": 2.0718562874251497e-07,
      "logits/chosen": 1.802420973777771,
      "logits/rejected": 1.802490472793579,
      "logps/chosen": -151.6751251220703,
      "logps/rejected": -74.6409683227539,
      "loss": 0.24683611392974852,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6775757670402527,
      "rewards/margins": 1.2966382503509521,
      "rewards/rejected": -0.6190625429153442,
      "step": 590
    },
    {
      "epoch": 0.6422263848006422,
      "grad_norm": 4.3158063888549805,
      "learning_rate": 2.0119760479041914e-07,
      "logits/chosen": 1.764609932899475,
      "logits/rejected": 1.8661260604858398,
      "logps/chosen": -139.0083465576172,
      "logps/rejected": -74.94679260253906,
      "loss": 0.2493436574935913,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6576306223869324,
      "rewards/margins": 1.2949602603912354,
      "rewards/rejected": -0.6373296976089478,
      "step": 600
    },
    {
      "epoch": 0.6529301578806529,
      "grad_norm": 4.603701114654541,
      "learning_rate": 1.9520958083832333e-07,
      "logits/chosen": 1.7379977703094482,
      "logits/rejected": 1.770578145980835,
      "logps/chosen": -140.86471557617188,
      "logps/rejected": -74.72206115722656,
      "loss": 0.2567238092422485,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6194905042648315,
      "rewards/margins": 1.2541077136993408,
      "rewards/rejected": -0.634617269039154,
      "step": 610
    },
    {
      "epoch": 0.6636339309606636,
      "grad_norm": 4.097917556762695,
      "learning_rate": 1.8922155688622755e-07,
      "logits/chosen": 1.7416118383407593,
      "logits/rejected": 1.8348674774169922,
      "logps/chosen": -138.94577026367188,
      "logps/rejected": -74.902099609375,
      "loss": 0.24685120582580566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6493919491767883,
      "rewards/margins": 1.3079885244369507,
      "rewards/rejected": -0.6585966348648071,
      "step": 620
    },
    {
      "epoch": 0.6743377040406744,
      "grad_norm": 4.418319225311279,
      "learning_rate": 1.8323353293413174e-07,
      "logits/chosen": 1.7184722423553467,
      "logits/rejected": 1.8123438358306885,
      "logps/chosen": -140.5662841796875,
      "logps/rejected": -76.12516784667969,
      "loss": 0.2560744762420654,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5974591374397278,
      "rewards/margins": 1.2700304985046387,
      "rewards/rejected": -0.6725713610649109,
      "step": 630
    },
    {
      "epoch": 0.6850414771206851,
      "grad_norm": 4.548317909240723,
      "learning_rate": 1.772455089820359e-07,
      "logits/chosen": 1.7652679681777954,
      "logits/rejected": 1.785327672958374,
      "logps/chosen": -142.3883514404297,
      "logps/rejected": -74.2542495727539,
      "loss": 0.2488795757293701,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6300868988037109,
      "rewards/margins": 1.3063615560531616,
      "rewards/rejected": -0.6762746572494507,
      "step": 640
    },
    {
      "epoch": 0.6957452502006958,
      "grad_norm": 4.4317731857299805,
      "learning_rate": 1.7125748502994012e-07,
      "logits/chosen": 1.7969481945037842,
      "logits/rejected": 1.815792441368103,
      "logps/chosen": -136.4267578125,
      "logps/rejected": -76.06803894042969,
      "loss": 0.22467048168182374,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7178188562393188,
      "rewards/margins": 1.4194567203521729,
      "rewards/rejected": -0.7016379237174988,
      "step": 650
    },
    {
      "epoch": 0.7064490232807065,
      "grad_norm": 3.928558826446533,
      "learning_rate": 1.6526946107784431e-07,
      "logits/chosen": 1.7399944067001343,
      "logits/rejected": 1.8043749332427979,
      "logps/chosen": -134.42727661132812,
      "logps/rejected": -75.98246765136719,
      "loss": 0.2353428602218628,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6628230214118958,
      "rewards/margins": 1.3715388774871826,
      "rewards/rejected": -0.7087157964706421,
      "step": 660
    },
    {
      "epoch": 0.7171527963607172,
      "grad_norm": 4.134726047515869,
      "learning_rate": 1.5928143712574848e-07,
      "logits/chosen": 1.8170645236968994,
      "logits/rejected": 1.8515037298202515,
      "logps/chosen": -145.3916778564453,
      "logps/rejected": -75.65892791748047,
      "loss": 0.22760522365570068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7123415470123291,
      "rewards/margins": 1.4067983627319336,
      "rewards/rejected": -0.694456934928894,
      "step": 670
    },
    {
      "epoch": 0.7278565694407279,
      "grad_norm": 3.990267515182495,
      "learning_rate": 1.532934131736527e-07,
      "logits/chosen": 1.7855783700942993,
      "logits/rejected": 1.8755378723144531,
      "logps/chosen": -131.38966369628906,
      "logps/rejected": -76.72171020507812,
      "loss": 0.21972479820251464,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6998761892318726,
      "rewards/margins": 1.4344842433929443,
      "rewards/rejected": -0.7346081137657166,
      "step": 680
    },
    {
      "epoch": 0.7385603425207385,
      "grad_norm": 3.94036602973938,
      "learning_rate": 1.473053892215569e-07,
      "logits/chosen": 1.7463937997817993,
      "logits/rejected": 1.7643041610717773,
      "logps/chosen": -141.3234405517578,
      "logps/rejected": -76.37720489501953,
      "loss": 0.21513452529907226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.74072265625,
      "rewards/margins": 1.4729549884796143,
      "rewards/rejected": -0.7322325110435486,
      "step": 690
    },
    {
      "epoch": 0.7492641156007492,
      "grad_norm": 4.0133843421936035,
      "learning_rate": 1.4131736526946105e-07,
      "logits/chosen": 1.7460092306137085,
      "logits/rejected": 1.8414554595947266,
      "logps/chosen": -137.8076934814453,
      "logps/rejected": -76.48710632324219,
      "loss": 0.21738605499267577,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7267335057258606,
      "rewards/margins": 1.45694899559021,
      "rewards/rejected": -0.7302155494689941,
      "step": 700
    },
    {
      "epoch": 0.7599678886807599,
      "grad_norm": 3.6722400188446045,
      "learning_rate": 1.3532934131736525e-07,
      "logits/chosen": 1.7830826044082642,
      "logits/rejected": 1.835654854774475,
      "logps/chosen": -151.77178955078125,
      "logps/rejected": -76.0047836303711,
      "loss": 0.21535544395446776,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7281826138496399,
      "rewards/margins": 1.469092607498169,
      "rewards/rejected": -0.740909993648529,
      "step": 710
    },
    {
      "epoch": 0.7706716617607706,
      "grad_norm": 3.856961727142334,
      "learning_rate": 1.2934131736526946e-07,
      "logits/chosen": 1.7488033771514893,
      "logits/rejected": 1.8321723937988281,
      "logps/chosen": -136.1217041015625,
      "logps/rejected": -76.55415344238281,
      "loss": 0.2138247013092041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7275640964508057,
      "rewards/margins": 1.4848555326461792,
      "rewards/rejected": -0.7572914361953735,
      "step": 720
    },
    {
      "epoch": 0.7813754348407814,
      "grad_norm": 4.037120819091797,
      "learning_rate": 1.2335329341317366e-07,
      "logits/chosen": 1.7450885772705078,
      "logits/rejected": 1.7859115600585938,
      "logps/chosen": -140.2508087158203,
      "logps/rejected": -77.64500427246094,
      "loss": 0.21537280082702637,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6945157647132874,
      "rewards/margins": 1.4691877365112305,
      "rewards/rejected": -0.7746719121932983,
      "step": 730
    },
    {
      "epoch": 0.7920792079207921,
      "grad_norm": 3.615330457687378,
      "learning_rate": 1.1736526946107785e-07,
      "logits/chosen": 1.7701797485351562,
      "logits/rejected": 1.7741625308990479,
      "logps/chosen": -146.8361053466797,
      "logps/rejected": -76.98933410644531,
      "loss": 0.20460364818572999,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7678011059761047,
      "rewards/margins": 1.5381033420562744,
      "rewards/rejected": -0.7703022956848145,
      "step": 740
    },
    {
      "epoch": 0.8027829810008028,
      "grad_norm": 3.8646223545074463,
      "learning_rate": 1.1137724550898203e-07,
      "logits/chosen": 1.816789984703064,
      "logits/rejected": 1.7498910427093506,
      "logps/chosen": -144.65928649902344,
      "logps/rejected": -76.48170471191406,
      "loss": 0.20386760234832763,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7449041604995728,
      "rewards/margins": 1.5314377546310425,
      "rewards/rejected": -0.7865337133407593,
      "step": 750
    },
    {
      "epoch": 0.8134867540808135,
      "grad_norm": 3.4825022220611572,
      "learning_rate": 1.0538922155688622e-07,
      "logits/chosen": 1.6760637760162354,
      "logits/rejected": 1.7586052417755127,
      "logps/chosen": -141.0543212890625,
      "logps/rejected": -76.11383056640625,
      "loss": 0.19730901718139648,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7630606889724731,
      "rewards/margins": 1.5635852813720703,
      "rewards/rejected": -0.8005247116088867,
      "step": 760
    },
    {
      "epoch": 0.8241905271608242,
      "grad_norm": 3.433431625366211,
      "learning_rate": 9.940119760479042e-08,
      "logits/chosen": 1.747786283493042,
      "logits/rejected": 1.7997268438339233,
      "logps/chosen": -149.10293579101562,
      "logps/rejected": -77.65150451660156,
      "loss": 0.2045149803161621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7323285341262817,
      "rewards/margins": 1.5307790040969849,
      "rewards/rejected": -0.7984504699707031,
      "step": 770
    },
    {
      "epoch": 0.8348943002408349,
      "grad_norm": 3.566570520401001,
      "learning_rate": 9.34131736526946e-08,
      "logits/chosen": 1.7452516555786133,
      "logits/rejected": 1.8659995794296265,
      "logps/chosen": -146.29678344726562,
      "logps/rejected": -76.2309799194336,
      "loss": 0.21121542453765868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7252146005630493,
      "rewards/margins": 1.5033762454986572,
      "rewards/rejected": -0.7781617045402527,
      "step": 780
    },
    {
      "epoch": 0.8455980733208456,
      "grad_norm": 3.4663736820220947,
      "learning_rate": 8.74251497005988e-08,
      "logits/chosen": 1.6659457683563232,
      "logits/rejected": 1.7842499017715454,
      "logps/chosen": -132.67312622070312,
      "logps/rejected": -76.67434692382812,
      "loss": 0.2022383213043213,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7231441736221313,
      "rewards/margins": 1.5436455011367798,
      "rewards/rejected": -0.8205013275146484,
      "step": 790
    },
    {
      "epoch": 0.8563018464008563,
      "grad_norm": 3.3987667560577393,
      "learning_rate": 8.143712574850298e-08,
      "logits/chosen": 1.7271575927734375,
      "logits/rejected": 1.7202459573745728,
      "logps/chosen": -136.45516967773438,
      "logps/rejected": -77.56387329101562,
      "loss": 0.19638816118240357,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7829863429069519,
      "rewards/margins": 1.5835803747177124,
      "rewards/rejected": -0.80059415102005,
      "step": 800
    },
    {
      "epoch": 0.867005619480867,
      "grad_norm": 3.3635904788970947,
      "learning_rate": 7.544910179640718e-08,
      "logits/chosen": 1.7690298557281494,
      "logits/rejected": 1.8308074474334717,
      "logps/chosen": -145.4336395263672,
      "logps/rejected": -76.64090728759766,
      "loss": 0.20028858184814452,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7549171447753906,
      "rewards/margins": 1.5499107837677002,
      "rewards/rejected": -0.7949937582015991,
      "step": 810
    },
    {
      "epoch": 0.8777093925608777,
      "grad_norm": 3.3988428115844727,
      "learning_rate": 6.946107784431138e-08,
      "logits/chosen": 1.8215553760528564,
      "logits/rejected": 1.896654486656189,
      "logps/chosen": -140.36672973632812,
      "logps/rejected": -77.05322265625,
      "loss": 0.208185076713562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7245324850082397,
      "rewards/margins": 1.5235141515731812,
      "rewards/rejected": -0.7989817261695862,
      "step": 820
    },
    {
      "epoch": 0.8884131656408885,
      "grad_norm": 3.8782718181610107,
      "learning_rate": 6.347305389221556e-08,
      "logits/chosen": 1.723189115524292,
      "logits/rejected": 1.8468940258026123,
      "logps/chosen": -134.43785095214844,
      "logps/rejected": -77.81403350830078,
      "loss": 0.2015517234802246,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7322009205818176,
      "rewards/margins": 1.548459768295288,
      "rewards/rejected": -0.8162587881088257,
      "step": 830
    },
    {
      "epoch": 0.8991169387208992,
      "grad_norm": 3.2816662788391113,
      "learning_rate": 5.748502994011976e-08,
      "logits/chosen": 1.7754141092300415,
      "logits/rejected": 1.8011596202850342,
      "logps/chosen": -147.44705200195312,
      "logps/rejected": -76.50650787353516,
      "loss": 0.19266433715820314,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7756472229957581,
      "rewards/margins": 1.6067768335342407,
      "rewards/rejected": -0.8311297297477722,
      "step": 840
    },
    {
      "epoch": 0.9098207118009098,
      "grad_norm": 3.072996139526367,
      "learning_rate": 5.149700598802395e-08,
      "logits/chosen": 1.7903053760528564,
      "logits/rejected": 1.7942928075790405,
      "logps/chosen": -151.41732788085938,
      "logps/rejected": -76.77747344970703,
      "loss": 0.19085344076156616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7803470492362976,
      "rewards/margins": 1.6015424728393555,
      "rewards/rejected": -0.8211954236030579,
      "step": 850
    },
    {
      "epoch": 0.9205244848809205,
      "grad_norm": 3.3008244037628174,
      "learning_rate": 4.550898203592814e-08,
      "logits/chosen": 1.7615253925323486,
      "logits/rejected": 1.8332973718643188,
      "logps/chosen": -141.79835510253906,
      "logps/rejected": -76.78396606445312,
      "loss": 0.20054709911346436,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7235402464866638,
      "rewards/margins": 1.5476099252700806,
      "rewards/rejected": -0.8240696787834167,
      "step": 860
    },
    {
      "epoch": 0.9312282579609312,
      "grad_norm": 3.5607569217681885,
      "learning_rate": 3.952095808383234e-08,
      "logits/chosen": 1.7377218008041382,
      "logits/rejected": 1.8548266887664795,
      "logps/chosen": -145.808837890625,
      "logps/rejected": -78.31027221679688,
      "loss": 0.19617185592651368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7669254541397095,
      "rewards/margins": 1.6001415252685547,
      "rewards/rejected": -0.8332161903381348,
      "step": 870
    },
    {
      "epoch": 0.9419320310409419,
      "grad_norm": 4.1997246742248535,
      "learning_rate": 3.3532934131736525e-08,
      "logits/chosen": 1.7634700536727905,
      "logits/rejected": 1.8498132228851318,
      "logps/chosen": -139.12661743164062,
      "logps/rejected": -77.1301040649414,
      "loss": 0.19907418489456177,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7268336415290833,
      "rewards/margins": 1.5657073259353638,
      "rewards/rejected": -0.8388737440109253,
      "step": 880
    },
    {
      "epoch": 0.9526358041209526,
      "grad_norm": 3.28594708442688,
      "learning_rate": 2.7544910179640717e-08,
      "logits/chosen": 1.7488588094711304,
      "logits/rejected": 1.7704232931137085,
      "logps/chosen": -147.13150024414062,
      "logps/rejected": -77.97909545898438,
      "loss": 0.19738469123840333,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7283221483230591,
      "rewards/margins": 1.5795894861221313,
      "rewards/rejected": -0.8512671589851379,
      "step": 890
    },
    {
      "epoch": 0.9633395772009633,
      "grad_norm": 3.7501001358032227,
      "learning_rate": 2.155688622754491e-08,
      "logits/chosen": 1.7494144439697266,
      "logits/rejected": 1.8384708166122437,
      "logps/chosen": -133.22665405273438,
      "logps/rejected": -77.87442016601562,
      "loss": 0.18088364601135254,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8178327679634094,
      "rewards/margins": 1.6689115762710571,
      "rewards/rejected": -0.8510788083076477,
      "step": 900
    },
    {
      "epoch": 0.974043350280974,
      "grad_norm": 3.4232540130615234,
      "learning_rate": 1.55688622754491e-08,
      "logits/chosen": 1.7492427825927734,
      "logits/rejected": 1.8422960042953491,
      "logps/chosen": -138.7411346435547,
      "logps/rejected": -77.9305419921875,
      "loss": 0.19191781282424927,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7708931565284729,
      "rewards/margins": 1.6147266626358032,
      "rewards/rejected": -0.8438334465026855,
      "step": 910
    },
    {
      "epoch": 0.9847471233609848,
      "grad_norm": 3.6146180629730225,
      "learning_rate": 9.580838323353294e-09,
      "logits/chosen": 1.8464939594268799,
      "logits/rejected": 1.8519998788833618,
      "logps/chosen": -160.4117431640625,
      "logps/rejected": -77.70404052734375,
      "loss": 0.18279109001159669,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8217922449111938,
      "rewards/margins": 1.6555614471435547,
      "rewards/rejected": -0.8337693214416504,
      "step": 920
    },
    {
      "epoch": 0.9954508964409955,
      "grad_norm": 3.1998848915100098,
      "learning_rate": 3.592814371257485e-09,
      "logits/chosen": 1.7458164691925049,
      "logits/rejected": 1.8081529140472412,
      "logps/chosen": -135.0084228515625,
      "logps/rejected": -77.63662719726562,
      "loss": 0.19090063571929933,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7546181678771973,
      "rewards/margins": 1.6014035940170288,
      "rewards/rejected": -0.8467856645584106,
      "step": 930
    }
  ],
  "logging_steps": 10,
  "max_steps": 935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
