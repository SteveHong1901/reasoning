{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5351886540005352,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010703773080010704,
      "grad_norm": 7.749534606933594,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.6386102437973022,
      "logits/rejected": 1.6341050863265991,
      "logps/chosen": -142.2468719482422,
      "logps/rejected": -68.85421752929688,
      "loss": 0.6956057548522949,
      "rewards/accuracies": 0.2750000059604645,
      "rewards/chosen": -0.005865964572876692,
      "rewards/margins": -0.00457597803324461,
      "rewards/rejected": -0.001289987238124013,
      "step": 10
    },
    {
      "epoch": 0.02140754616002141,
      "grad_norm": 8.052937507629395,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.6590404510498047,
      "logits/rejected": 1.6829729080200195,
      "logps/chosen": -157.90542602539062,
      "logps/rejected": -69.39391326904297,
      "loss": 0.6928775787353516,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.001132011180743575,
      "rewards/margins": 0.0011906143045052886,
      "rewards/rejected": -0.0023226263001561165,
      "step": 20
    },
    {
      "epoch": 0.03211131924003211,
      "grad_norm": 8.698307037353516,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.704846739768982,
      "logits/rejected": 1.7148845195770264,
      "logps/chosen": -145.9049072265625,
      "logps/rejected": -68.55137634277344,
      "loss": 0.6991735458374023,
      "rewards/accuracies": 0.375,
      "rewards/chosen": -0.009928608313202858,
      "rewards/margins": -0.011501455679535866,
      "rewards/rejected": 0.0015728473663330078,
      "step": 30
    },
    {
      "epoch": 0.04281509232004282,
      "grad_norm": 7.451376438140869,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.6448873281478882,
      "logits/rejected": 1.6676737070083618,
      "logps/chosen": -145.00802612304688,
      "logps/rejected": -68.42008209228516,
      "loss": 0.6936444759368896,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.006066984962671995,
      "rewards/margins": -0.0004435914452187717,
      "rewards/rejected": -0.005623393226414919,
      "step": 40
    },
    {
      "epoch": 0.05351886540005352,
      "grad_norm": 6.916481018066406,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.6081171035766602,
      "logits/rejected": 1.6937837600708008,
      "logps/chosen": -150.61947631835938,
      "logps/rejected": -69.54265594482422,
      "loss": 0.6947578907012939,
      "rewards/accuracies": 0.42500001192092896,
      "rewards/chosen": -0.001154761528596282,
      "rewards/margins": -0.0026723144110292196,
      "rewards/rejected": 0.001517553231678903,
      "step": 50
    },
    {
      "epoch": 0.06422263848006422,
      "grad_norm": 7.561282157897949,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.5654462575912476,
      "logits/rejected": 1.6648428440093994,
      "logps/chosen": -150.66366577148438,
      "logps/rejected": -69.3353271484375,
      "loss": 0.6928158283233643,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -0.00040882109897211194,
      "rewards/margins": 0.0013186171418055892,
      "rewards/rejected": -0.0017274379497393966,
      "step": 60
    },
    {
      "epoch": 0.07492641156007493,
      "grad_norm": 8.580316543579102,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.6857200860977173,
      "logits/rejected": 1.669213056564331,
      "logps/chosen": -147.57305908203125,
      "logps/rejected": -69.85322570800781,
      "loss": 0.6902610778808593,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.0047585004940629005,
      "rewards/margins": 0.006304621696472168,
      "rewards/rejected": -0.0015461205039173365,
      "step": 70
    },
    {
      "epoch": 0.08563018464008564,
      "grad_norm": 7.7908782958984375,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.6832557916641235,
      "logits/rejected": 1.660133719444275,
      "logps/chosen": -140.07228088378906,
      "logps/rejected": -68.54820251464844,
      "loss": 0.6871943473815918,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.0025395252741873264,
      "rewards/margins": 0.012391148135066032,
      "rewards/rejected": -0.009851622395217419,
      "step": 80
    },
    {
      "epoch": 0.09633395772009633,
      "grad_norm": 8.094836235046387,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.635920524597168,
      "logits/rejected": 1.6247339248657227,
      "logps/chosen": -143.47265625,
      "logps/rejected": -70.15863800048828,
      "loss": 0.685413408279419,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.006183228455483913,
      "rewards/margins": 0.016164366155862808,
      "rewards/rejected": -0.00998113676905632,
      "step": 90
    },
    {
      "epoch": 0.10703773080010703,
      "grad_norm": 9.14108657836914,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.6177440881729126,
      "logits/rejected": 1.666069746017456,
      "logps/chosen": -145.54498291015625,
      "logps/rejected": -69.01045227050781,
      "loss": 0.6832215309143066,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.010029025375843048,
      "rewards/margins": 0.020749863237142563,
      "rewards/rejected": -0.01072083879262209,
      "step": 100
    },
    {
      "epoch": 0.11774150388011774,
      "grad_norm": 9.399163246154785,
      "learning_rate": 4.946107784431138e-07,
      "logits/chosen": 1.6870629787445068,
      "logits/rejected": 1.6587769985198975,
      "logps/chosen": -160.3252716064453,
      "logps/rejected": -68.1123275756836,
      "loss": 0.6741155624389649,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": 0.02881716750562191,
      "rewards/margins": 0.039212148636579514,
      "rewards/rejected": -0.010394983924925327,
      "step": 110
    },
    {
      "epoch": 0.12844527696012845,
      "grad_norm": 8.395679473876953,
      "learning_rate": 4.886227544910179e-07,
      "logits/chosen": 1.65679931640625,
      "logits/rejected": 1.6548900604248047,
      "logps/chosen": -152.66201782226562,
      "logps/rejected": -69.43843841552734,
      "loss": 0.6722606658935547,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.02872874215245247,
      "rewards/margins": 0.04303393512964249,
      "rewards/rejected": -0.014305196702480316,
      "step": 120
    },
    {
      "epoch": 0.13914905004013914,
      "grad_norm": 9.176633834838867,
      "learning_rate": 4.826347305389221e-07,
      "logits/chosen": 1.606738805770874,
      "logits/rejected": 1.6602483987808228,
      "logps/chosen": -139.3529510498047,
      "logps/rejected": -69.15409851074219,
      "loss": 0.6656756401062012,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": 0.03757764771580696,
      "rewards/margins": 0.05641884356737137,
      "rewards/rejected": -0.01884119026362896,
      "step": 130
    },
    {
      "epoch": 0.14985282312014986,
      "grad_norm": 7.867959976196289,
      "learning_rate": 4.766467065868263e-07,
      "logits/chosen": 1.614119529724121,
      "logits/rejected": 1.6709896326065063,
      "logps/chosen": -136.20907592773438,
      "logps/rejected": -68.09628295898438,
      "loss": 0.6596052169799804,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.046946875751018524,
      "rewards/margins": 0.0688096135854721,
      "rewards/rejected": -0.021862726658582687,
      "step": 140
    },
    {
      "epoch": 0.16055659620016055,
      "grad_norm": 8.678658485412598,
      "learning_rate": 4.7065868263473054e-07,
      "logits/chosen": 1.6162242889404297,
      "logits/rejected": 1.7208006381988525,
      "logps/chosen": -151.5668487548828,
      "logps/rejected": -69.3865737915039,
      "loss": 0.6507754802703858,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": 0.06367187201976776,
      "rewards/margins": 0.08757273852825165,
      "rewards/rejected": -0.023900866508483887,
      "step": 150
    },
    {
      "epoch": 0.17126036928017127,
      "grad_norm": 9.591712951660156,
      "learning_rate": 4.646706586826347e-07,
      "logits/chosen": 1.6933132410049438,
      "logits/rejected": 1.695102334022522,
      "logps/chosen": -150.09304809570312,
      "logps/rejected": -69.39521789550781,
      "loss": 0.6411234378814697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06943677365779877,
      "rewards/margins": 0.10757599771022797,
      "rewards/rejected": -0.0381392166018486,
      "step": 160
    },
    {
      "epoch": 0.18196414236018196,
      "grad_norm": 8.143529891967773,
      "learning_rate": 4.586826347305389e-07,
      "logits/chosen": 1.696366548538208,
      "logits/rejected": 1.6655223369598389,
      "logps/chosen": -149.1695098876953,
      "logps/rejected": -70.0084457397461,
      "loss": 0.6317351341247559,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.08242126554250717,
      "rewards/margins": 0.12786832451820374,
      "rewards/rejected": -0.04544704779982567,
      "step": 170
    },
    {
      "epoch": 0.19266791544019266,
      "grad_norm": 8.209756851196289,
      "learning_rate": 4.5269461077844314e-07,
      "logits/chosen": 1.6590473651885986,
      "logits/rejected": 1.6364275217056274,
      "logps/chosen": -145.5922088623047,
      "logps/rejected": -69.02527618408203,
      "loss": 0.6177900314331055,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.1014733538031578,
      "rewards/margins": 0.1580965518951416,
      "rewards/rejected": -0.056623198091983795,
      "step": 180
    },
    {
      "epoch": 0.20337168852020338,
      "grad_norm": 8.193597793579102,
      "learning_rate": 4.4670658682634725e-07,
      "logits/chosen": 1.7697521448135376,
      "logits/rejected": 1.6386922597885132,
      "logps/chosen": -146.7029266357422,
      "logps/rejected": -70.54417419433594,
      "loss": 0.6068077564239502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11398857831954956,
      "rewards/margins": 0.18238355219364166,
      "rewards/rejected": -0.0683949738740921,
      "step": 190
    },
    {
      "epoch": 0.21407546160021407,
      "grad_norm": 8.08067798614502,
      "learning_rate": 4.4071856287425147e-07,
      "logits/chosen": 1.6602718830108643,
      "logits/rejected": 1.6452583074569702,
      "logps/chosen": -139.6817169189453,
      "logps/rejected": -68.24710083007812,
      "loss": 0.6016545295715332,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.12559093534946442,
      "rewards/margins": 0.19353091716766357,
      "rewards/rejected": -0.06793998181819916,
      "step": 200
    },
    {
      "epoch": 0.2247792346802248,
      "grad_norm": 9.679850578308105,
      "learning_rate": 4.347305389221557e-07,
      "logits/chosen": 1.6305221319198608,
      "logits/rejected": 1.7394355535507202,
      "logps/chosen": -143.742919921875,
      "logps/rejected": -70.6789779663086,
      "loss": 0.5913937568664551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.14124496281147003,
      "rewards/margins": 0.21740691363811493,
      "rewards/rejected": -0.07616196572780609,
      "step": 210
    },
    {
      "epoch": 0.23548300776023548,
      "grad_norm": 7.047687530517578,
      "learning_rate": 4.2874251497005985e-07,
      "logits/chosen": 1.6397289037704468,
      "logits/rejected": 1.6985533237457275,
      "logps/chosen": -136.897216796875,
      "logps/rejected": -69.24632263183594,
      "loss": 0.5802598476409913,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15014132857322693,
      "rewards/margins": 0.24179577827453613,
      "rewards/rejected": -0.0916544646024704,
      "step": 220
    },
    {
      "epoch": 0.2461867808402462,
      "grad_norm": 7.724626541137695,
      "learning_rate": 4.2275449101796407e-07,
      "logits/chosen": 1.5911871194839478,
      "logits/rejected": 1.7253954410552979,
      "logps/chosen": -138.46852111816406,
      "logps/rejected": -70.15869140625,
      "loss": 0.5742578506469727,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.16112802922725677,
      "rewards/margins": 0.25606992840766907,
      "rewards/rejected": -0.09494189918041229,
      "step": 230
    },
    {
      "epoch": 0.2568905539202569,
      "grad_norm": 7.438562393188477,
      "learning_rate": 4.167664670658683e-07,
      "logits/chosen": 1.6604454517364502,
      "logits/rejected": 1.7507503032684326,
      "logps/chosen": -137.58729553222656,
      "logps/rejected": -70.36237335205078,
      "loss": 0.5652000427246093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17011448740959167,
      "rewards/margins": 0.2779960632324219,
      "rewards/rejected": -0.1078815832734108,
      "step": 240
    },
    {
      "epoch": 0.2675943270002676,
      "grad_norm": 7.294968128204346,
      "learning_rate": 4.107784431137724e-07,
      "logits/chosen": 1.7211517095565796,
      "logits/rejected": 1.6822826862335205,
      "logps/chosen": -145.1071014404297,
      "logps/rejected": -70.56084442138672,
      "loss": 0.5448286533355713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20027288794517517,
      "rewards/margins": 0.32471030950546265,
      "rewards/rejected": -0.12443741410970688,
      "step": 250
    },
    {
      "epoch": 0.2782981000802783,
      "grad_norm": 7.325588703155518,
      "learning_rate": 4.047904191616766e-07,
      "logits/chosen": 1.7219759225845337,
      "logits/rejected": 1.7079336643218994,
      "logps/chosen": -144.18466186523438,
      "logps/rejected": -69.44859313964844,
      "loss": 0.5371213912963867,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.21912388503551483,
      "rewards/margins": 0.3443305790424347,
      "rewards/rejected": -0.12520667910575867,
      "step": 260
    },
    {
      "epoch": 0.289001873160289,
      "grad_norm": 6.935419082641602,
      "learning_rate": 3.9880239520958084e-07,
      "logits/chosen": 1.6424560546875,
      "logits/rejected": 1.716376543045044,
      "logps/chosen": -144.5414276123047,
      "logps/rejected": -70.6113510131836,
      "loss": 0.5330044746398925,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20996996760368347,
      "rewards/margins": 0.35539451241493225,
      "rewards/rejected": -0.14542452991008759,
      "step": 270
    },
    {
      "epoch": 0.2997056462402997,
      "grad_norm": 7.228213787078857,
      "learning_rate": 3.92814371257485e-07,
      "logits/chosen": 1.7079381942749023,
      "logits/rejected": 1.733976125717163,
      "logps/chosen": -143.84326171875,
      "logps/rejected": -70.37006378173828,
      "loss": 0.5159739017486572,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.23778924345970154,
      "rewards/margins": 0.3967912793159485,
      "rewards/rejected": -0.15900200605392456,
      "step": 280
    },
    {
      "epoch": 0.3104094193203104,
      "grad_norm": 8.05090045928955,
      "learning_rate": 3.868263473053892e-07,
      "logits/chosen": 1.7840582132339478,
      "logits/rejected": 1.7894229888916016,
      "logps/chosen": -150.17330932617188,
      "logps/rejected": -71.97957611083984,
      "loss": 0.5038358688354492,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25261393189430237,
      "rewards/margins": 0.4284713864326477,
      "rewards/rejected": -0.17585746943950653,
      "step": 290
    },
    {
      "epoch": 0.3211131924003211,
      "grad_norm": 7.2161054611206055,
      "learning_rate": 3.8083832335329344e-07,
      "logits/chosen": 1.6528106927871704,
      "logits/rejected": 1.733485460281372,
      "logps/chosen": -141.58935546875,
      "logps/rejected": -69.84529113769531,
      "loss": 0.48693695068359377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.2853284776210785,
      "rewards/margins": 0.47056418657302856,
      "rewards/rejected": -0.18523570895195007,
      "step": 300
    },
    {
      "epoch": 0.3318169654803318,
      "grad_norm": 6.972319602966309,
      "learning_rate": 3.748502994011976e-07,
      "logits/chosen": 1.772904634475708,
      "logits/rejected": 1.723565697669983,
      "logps/chosen": -141.63970947265625,
      "logps/rejected": -70.94783020019531,
      "loss": 0.48618507385253906,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.27496328949928284,
      "rewards/margins": 0.4740881323814392,
      "rewards/rejected": -0.19912487268447876,
      "step": 310
    },
    {
      "epoch": 0.34252073856034254,
      "grad_norm": 6.828237533569336,
      "learning_rate": 3.6886227544910177e-07,
      "logits/chosen": 1.7217185497283936,
      "logits/rejected": 1.737383484840393,
      "logps/chosen": -151.706298828125,
      "logps/rejected": -70.70848083496094,
      "loss": 0.4743024826049805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29669347405433655,
      "rewards/margins": 0.5061872601509094,
      "rewards/rejected": -0.20949378609657288,
      "step": 320
    },
    {
      "epoch": 0.35322451164035323,
      "grad_norm": 7.068118572235107,
      "learning_rate": 3.6287425149700593e-07,
      "logits/chosen": 1.7742153406143188,
      "logits/rejected": 1.7355537414550781,
      "logps/chosen": -157.36465454101562,
      "logps/rejected": -70.80631256103516,
      "loss": 0.45133328437805176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3387316167354584,
      "rewards/margins": 0.5668846368789673,
      "rewards/rejected": -0.2281530350446701,
      "step": 330
    },
    {
      "epoch": 0.3639282847203639,
      "grad_norm": 7.044462203979492,
      "learning_rate": 3.5688622754491015e-07,
      "logits/chosen": 1.7302125692367554,
      "logits/rejected": 1.7909348011016846,
      "logps/chosen": -143.6007843017578,
      "logps/rejected": -70.85469818115234,
      "loss": 0.43280901908874514,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3599672317504883,
      "rewards/margins": 0.622040867805481,
      "rewards/rejected": -0.26207366585731506,
      "step": 340
    },
    {
      "epoch": 0.3746320578003746,
      "grad_norm": 6.152693271636963,
      "learning_rate": 3.5089820359281437e-07,
      "logits/chosen": 1.735661506652832,
      "logits/rejected": 1.7560594081878662,
      "logps/chosen": -142.8195037841797,
      "logps/rejected": -70.2818374633789,
      "loss": 0.44544501304626466,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.33374807238578796,
      "rewards/margins": 0.5845711827278137,
      "rewards/rejected": -0.25082308053970337,
      "step": 350
    },
    {
      "epoch": 0.3853358308803853,
      "grad_norm": 6.800623416900635,
      "learning_rate": 3.4491017964071854e-07,
      "logits/chosen": 1.7319329977035522,
      "logits/rejected": 1.7711904048919678,
      "logps/chosen": -146.68618774414062,
      "logps/rejected": -70.66557312011719,
      "loss": 0.42503933906555175,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36174336075782776,
      "rewards/margins": 0.6437180042266846,
      "rewards/rejected": -0.2819747030735016,
      "step": 360
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 6.273284435272217,
      "learning_rate": 3.3892215568862275e-07,
      "logits/chosen": 1.7286608219146729,
      "logits/rejected": 1.7357441186904907,
      "logps/chosen": -145.67459106445312,
      "logps/rejected": -70.86426544189453,
      "loss": 0.42134413719177244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.36360034346580505,
      "rewards/margins": 0.659022867679596,
      "rewards/rejected": -0.2954224944114685,
      "step": 370
    },
    {
      "epoch": 0.40674337704040675,
      "grad_norm": 6.540586471557617,
      "learning_rate": 3.3293413173652697e-07,
      "logits/chosen": 1.6903159618377686,
      "logits/rejected": 1.7236621379852295,
      "logps/chosen": -153.5884246826172,
      "logps/rejected": -72.02792358398438,
      "loss": 0.40235300064086915,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3996214270591736,
      "rewards/margins": 0.7140001058578491,
      "rewards/rejected": -0.31437867879867554,
      "step": 380
    },
    {
      "epoch": 0.41744715012041744,
      "grad_norm": 5.966968059539795,
      "learning_rate": 3.269461077844311e-07,
      "logits/chosen": 1.6529152393341064,
      "logits/rejected": 1.7658876180648804,
      "logps/chosen": -138.8733367919922,
      "logps/rejected": -72.3782958984375,
      "loss": 0.3820918321609497,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.45754772424697876,
      "rewards/margins": 0.7747176885604858,
      "rewards/rejected": -0.31716999411582947,
      "step": 390
    },
    {
      "epoch": 0.42815092320042814,
      "grad_norm": 6.0693840980529785,
      "learning_rate": 3.209580838323353e-07,
      "logits/chosen": 1.7124595642089844,
      "logits/rejected": 1.7621967792510986,
      "logps/chosen": -145.87594604492188,
      "logps/rejected": -71.7154769897461,
      "loss": 0.3908966064453125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41245174407958984,
      "rewards/margins": 0.7477288842201233,
      "rewards/rejected": -0.33527714014053345,
      "step": 400
    },
    {
      "epoch": 0.4388546962804388,
      "grad_norm": 6.058930397033691,
      "learning_rate": 3.149700598802395e-07,
      "logits/chosen": 1.7023407220840454,
      "logits/rejected": 1.7199970483779907,
      "logps/chosen": -145.56149291992188,
      "logps/rejected": -72.53071594238281,
      "loss": 0.3660987138748169,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.48805490136146545,
      "rewards/margins": 0.8335456848144531,
      "rewards/rejected": -0.34549081325531006,
      "step": 410
    },
    {
      "epoch": 0.4495584693604496,
      "grad_norm": 5.7864990234375,
      "learning_rate": 3.089820359281437e-07,
      "logits/chosen": 1.775132417678833,
      "logits/rejected": 1.8398656845092773,
      "logps/chosen": -147.75180053710938,
      "logps/rejected": -71.70549011230469,
      "loss": 0.3741612911224365,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4403243958950043,
      "rewards/margins": 0.8017618060112,
      "rewards/rejected": -0.36143746972084045,
      "step": 420
    },
    {
      "epoch": 0.46026224244046027,
      "grad_norm": 5.906116485595703,
      "learning_rate": 3.029940119760479e-07,
      "logits/chosen": 1.7171663045883179,
      "logits/rejected": 1.79586923122406,
      "logps/chosen": -143.77223205566406,
      "logps/rejected": -71.98396301269531,
      "loss": 0.3707864284515381,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4481941759586334,
      "rewards/margins": 0.8193783760070801,
      "rewards/rejected": -0.37118417024612427,
      "step": 430
    },
    {
      "epoch": 0.47096601552047096,
      "grad_norm": 5.669434070587158,
      "learning_rate": 2.970059880239521e-07,
      "logits/chosen": 1.7775344848632812,
      "logits/rejected": 1.8110110759735107,
      "logps/chosen": -140.7774658203125,
      "logps/rejected": -72.6899642944336,
      "loss": 0.35381712913513186,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4872860014438629,
      "rewards/margins": 0.8757435083389282,
      "rewards/rejected": -0.3884574770927429,
      "step": 440
    },
    {
      "epoch": 0.48166978860048165,
      "grad_norm": 6.158790111541748,
      "learning_rate": 2.9101796407185623e-07,
      "logits/chosen": 1.7440952062606812,
      "logits/rejected": 1.787705421447754,
      "logps/chosen": -147.64334106445312,
      "logps/rejected": -73.48149108886719,
      "loss": 0.34398641586303713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5083939433097839,
      "rewards/margins": 0.9120082855224609,
      "rewards/rejected": -0.403614342212677,
      "step": 450
    },
    {
      "epoch": 0.4923735616804924,
      "grad_norm": 5.360244274139404,
      "learning_rate": 2.8502994011976045e-07,
      "logits/chosen": 1.7614514827728271,
      "logits/rejected": 1.7664897441864014,
      "logps/chosen": -141.90225219726562,
      "logps/rejected": -73.04267883300781,
      "loss": 0.33785262107849123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5058937072753906,
      "rewards/margins": 0.9288221597671509,
      "rewards/rejected": -0.4229283928871155,
      "step": 460
    },
    {
      "epoch": 0.5030773347605031,
      "grad_norm": 5.5311384201049805,
      "learning_rate": 2.7904191616766467e-07,
      "logits/chosen": 1.7972408533096313,
      "logits/rejected": 1.8077335357666016,
      "logps/chosen": -150.16925048828125,
      "logps/rejected": -73.39543151855469,
      "loss": 0.3268528938293457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5205182433128357,
      "rewards/margins": 0.9633939862251282,
      "rewards/rejected": -0.4428756833076477,
      "step": 470
    },
    {
      "epoch": 0.5137811078405138,
      "grad_norm": 5.4320387840271,
      "learning_rate": 2.7305389221556884e-07,
      "logits/chosen": 1.7308101654052734,
      "logits/rejected": 1.7627121210098267,
      "logps/chosen": -143.23165893554688,
      "logps/rejected": -73.47777557373047,
      "loss": 0.31190588474273684,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.56322181224823,
      "rewards/margins": 1.024387240409851,
      "rewards/rejected": -0.46116551756858826,
      "step": 480
    },
    {
      "epoch": 0.5244848809205245,
      "grad_norm": 5.4135613441467285,
      "learning_rate": 2.6706586826347305e-07,
      "logits/chosen": 1.7359310388565063,
      "logits/rejected": 1.8377645015716553,
      "logps/chosen": -150.90682983398438,
      "logps/rejected": -74.45719909667969,
      "loss": 0.30845506191253663,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5669752359390259,
      "rewards/margins": 1.0412242412567139,
      "rewards/rejected": -0.4742489755153656,
      "step": 490
    },
    {
      "epoch": 0.5351886540005352,
      "grad_norm": 5.1799445152282715,
      "learning_rate": 2.6107784431137727e-07,
      "logits/chosen": 1.7868820428848267,
      "logits/rejected": 1.8129628896713257,
      "logps/chosen": -134.04782104492188,
      "logps/rejected": -73.04761505126953,
      "loss": 0.3189507722854614,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5379789471626282,
      "rewards/margins": 1.0052403211593628,
      "rewards/rejected": -0.467261403799057,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
