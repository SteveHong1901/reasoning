data:
  dataset_config: main
  dataset_name: openai/gsm8k
  max_samples: null
  padding_level: clean
  seed: 42
  test_split_ratio: 0.1
eval:
  batch_size: 8
  do_sample: false
  max_new_tokens: 512
  num_samples: null
  temperature: 0.0
model:
  load_in_4bit: false
  max_seq_length: 2048
  name: meta-llama/Llama-3.2-1B-Instruct
  use_flash_attention: false
name: dpo-clean
seed: 42
train:
  beta: 0.1
  gradient_accumulation_steps: 4
  learning_rate: 5.0e-07
  logging_steps: 10
  lora_alpha: 32
  lora_dropout: 0.05
  lora_r: 16
  max_length: 2048
  max_prompt_length: 512
  max_steps: -1
  method: dpo
  num_train_epochs: 1
  output_dir: models/dpo-clean
  per_device_train_batch_size: 2
  save_steps: 500
  use_peft: true
  warmup_steps: 100
use_wandb: true
wandb_project: reasoning-mirage
