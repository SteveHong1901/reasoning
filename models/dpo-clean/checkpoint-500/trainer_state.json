{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5351886540005352,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010703773080010704,
      "grad_norm": 7.6642746925354,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.5458600521087646,
      "logits/rejected": 1.6335700750350952,
      "logps/chosen": -95.66376495361328,
      "logps/rejected": -68.86592102050781,
      "loss": 0.6961907863616943,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0024644467048346996,
      "rewards/margins": -0.005714812316000462,
      "rewards/rejected": 0.0032503653783351183,
      "step": 10
    },
    {
      "epoch": 0.02140754616002141,
      "grad_norm": 7.9436540603637695,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.5691773891448975,
      "logits/rejected": 1.682748794555664,
      "logps/chosen": -102.9636001586914,
      "logps/rejected": -69.40105438232422,
      "loss": 0.6936207294464112,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.001637868583202362,
      "rewards/margins": -0.0004828590899705887,
      "rewards/rejected": -0.001155009143985808,
      "step": 20
    },
    {
      "epoch": 0.03211131924003211,
      "grad_norm": 9.800686836242676,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.6136157512664795,
      "logits/rejected": 1.7152601480484009,
      "logps/chosen": -98.2775650024414,
      "logps/rejected": -68.61070251464844,
      "loss": 0.6963084697723388,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -0.010276569053530693,
      "rewards/margins": -0.005914372857660055,
      "rewards/rejected": -0.0043621971271932125,
      "step": 30
    },
    {
      "epoch": 0.04281509232004282,
      "grad_norm": 8.499246597290039,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.5499022006988525,
      "logits/rejected": 1.6691229343414307,
      "logps/chosen": -94.12925720214844,
      "logps/rejected": -68.43936920166016,
      "loss": 0.6901679515838623,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.0018616060260683298,
      "rewards/margins": 0.0065512508153915405,
      "rewards/rejected": -0.004689645953476429,
      "step": 40
    },
    {
      "epoch": 0.05351886540005352,
      "grad_norm": 7.339582920074463,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.5132286548614502,
      "logits/rejected": 1.693886160850525,
      "logps/chosen": -96.28523254394531,
      "logps/rejected": -69.509521484375,
      "loss": 0.6953918933868408,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.0013333609094843268,
      "rewards/margins": -0.00400154571980238,
      "rewards/rejected": 0.0026681851595640182,
      "step": 50
    },
    {
      "epoch": 0.06422263848006422,
      "grad_norm": 7.616441249847412,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.4452617168426514,
      "logits/rejected": 1.6660493612289429,
      "logps/chosen": -95.88685607910156,
      "logps/rejected": -69.34846496582031,
      "loss": 0.6899733066558837,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.006554870866239071,
      "rewards/margins": 0.0069150542840361595,
      "rewards/rejected": -0.000360183825250715,
      "step": 60
    },
    {
      "epoch": 0.07492641156007493,
      "grad_norm": 8.235770225524902,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.580561637878418,
      "logits/rejected": 1.6698585748672485,
      "logps/chosen": -96.81475830078125,
      "logps/rejected": -69.85762786865234,
      "loss": 0.6874208450317383,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.009662116877734661,
      "rewards/margins": 0.011918206699192524,
      "rewards/rejected": -0.002256088424474001,
      "step": 70
    },
    {
      "epoch": 0.08563018464008564,
      "grad_norm": 8.219965934753418,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.5853630304336548,
      "logits/rejected": 1.6623961925506592,
      "logps/chosen": -93.53421020507812,
      "logps/rejected": -68.52235412597656,
      "loss": 0.6875598430633545,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.0035239695571362972,
      "rewards/margins": 0.011648541316390038,
      "rewards/rejected": -0.008124571293592453,
      "step": 80
    },
    {
      "epoch": 0.09633395772009633,
      "grad_norm": 8.622967720031738,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.5529725551605225,
      "logits/rejected": 1.6251685619354248,
      "logps/chosen": -100.60663604736328,
      "logps/rejected": -70.12767028808594,
      "loss": 0.6861987590789795,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.009107065387070179,
      "rewards/margins": 0.014429683797061443,
      "rewards/rejected": -0.005322618409991264,
      "step": 90
    },
    {
      "epoch": 0.10703773080010703,
      "grad_norm": 9.32264232635498,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.5080032348632812,
      "logits/rejected": 1.6655700206756592,
      "logps/chosen": -102.71744537353516,
      "logps/rejected": -69.01951599121094,
      "loss": 0.6753100395202637,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.02363564446568489,
      "rewards/margins": 0.0367756113409996,
      "rewards/rejected": -0.013139968737959862,
      "step": 100
    },
    {
      "epoch": 0.11774150388011774,
      "grad_norm": 9.538298606872559,
      "learning_rate": 4.946107784431138e-07,
      "logits/chosen": 1.580507516860962,
      "logits/rejected": 1.6615736484527588,
      "logps/chosen": -102.25989532470703,
      "logps/rejected": -68.10111236572266,
      "loss": 0.6748167514801026,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.03098013997077942,
      "rewards/margins": 0.037550754845142365,
      "rewards/rejected": -0.006570611149072647,
      "step": 110
    },
    {
      "epoch": 0.12844527696012845,
      "grad_norm": 8.479535102844238,
      "learning_rate": 4.886227544910179e-07,
      "logits/chosen": 1.5477255582809448,
      "logits/rejected": 1.6556965112686157,
      "logps/chosen": -98.18047332763672,
      "logps/rejected": -69.49666595458984,
      "loss": 0.6664756298065185,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": 0.03427378088235855,
      "rewards/margins": 0.054745931178331375,
      "rewards/rejected": -0.020472148433327675,
      "step": 120
    },
    {
      "epoch": 0.13914905004013914,
      "grad_norm": 9.705656051635742,
      "learning_rate": 4.826347305389221e-07,
      "logits/chosen": 1.5088087320327759,
      "logits/rejected": 1.6631864309310913,
      "logps/chosen": -90.45843505859375,
      "logps/rejected": -69.1974868774414,
      "loss": 0.6600105285644531,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": 0.04008815437555313,
      "rewards/margins": 0.06805978715419769,
      "rewards/rejected": -0.027971630915999413,
      "step": 130
    },
    {
      "epoch": 0.14985282312014986,
      "grad_norm": 8.278407096862793,
      "learning_rate": 4.766467065868263e-07,
      "logits/chosen": 1.524910807609558,
      "logits/rejected": 1.6695661544799805,
      "logps/chosen": -90.56741333007812,
      "logps/rejected": -68.1983871459961,
      "loss": 0.6498828411102295,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.054790329188108444,
      "rewards/margins": 0.08905218541622162,
      "rewards/rejected": -0.03426186740398407,
      "step": 140
    },
    {
      "epoch": 0.16055659620016055,
      "grad_norm": 9.161384582519531,
      "learning_rate": 4.7065868263473054e-07,
      "logits/chosen": 1.5155388116836548,
      "logits/rejected": 1.7237215042114258,
      "logps/chosen": -99.10457611083984,
      "logps/rejected": -69.4609603881836,
      "loss": 0.646856689453125,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.061636824160814285,
      "rewards/margins": 0.09540145844221115,
      "rewards/rejected": -0.033764638006687164,
      "step": 150
    },
    {
      "epoch": 0.17126036928017127,
      "grad_norm": 9.973076820373535,
      "learning_rate": 4.646706586826347e-07,
      "logits/chosen": 1.6003284454345703,
      "logits/rejected": 1.697081208229065,
      "logps/chosen": -98.66423797607422,
      "logps/rejected": -69.4610595703125,
      "loss": 0.6331616878509522,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.08159245550632477,
      "rewards/margins": 0.1247086375951767,
      "rewards/rejected": -0.043116189539432526,
      "step": 160
    },
    {
      "epoch": 0.18196414236018196,
      "grad_norm": 8.571202278137207,
      "learning_rate": 4.586826347305389e-07,
      "logits/chosen": 1.5911263227462769,
      "logits/rejected": 1.6706289052963257,
      "logps/chosen": -99.03817749023438,
      "logps/rejected": -70.0931167602539,
      "loss": 0.6234090805053711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09243493527173996,
      "rewards/margins": 0.1455097198486328,
      "rewards/rejected": -0.05307478830218315,
      "step": 170
    },
    {
      "epoch": 0.19266791544019266,
      "grad_norm": 8.174881935119629,
      "learning_rate": 4.5269461077844314e-07,
      "logits/chosen": 1.5722379684448242,
      "logits/rejected": 1.6388050317764282,
      "logps/chosen": -95.92591857910156,
      "logps/rejected": -69.16011810302734,
      "loss": 0.6038780689239502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11492500454187393,
      "rewards/margins": 0.18828174471855164,
      "rewards/rejected": -0.07335672527551651,
      "step": 180
    },
    {
      "epoch": 0.20337168852020338,
      "grad_norm": 8.453973770141602,
      "learning_rate": 4.4670658682634725e-07,
      "logits/chosen": 1.6810516119003296,
      "logits/rejected": 1.6408863067626953,
      "logps/chosen": -98.49278259277344,
      "logps/rejected": -70.6387710571289,
      "loss": 0.6022417545318604,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11506612598896027,
      "rewards/margins": 0.1922977715730667,
      "rewards/rejected": -0.07723163813352585,
      "step": 190
    },
    {
      "epoch": 0.21407546160021407,
      "grad_norm": 8.054610252380371,
      "learning_rate": 4.4071856287425147e-07,
      "logits/chosen": 1.5649921894073486,
      "logits/rejected": 1.6489553451538086,
      "logps/chosen": -92.58233642578125,
      "logps/rejected": -68.34495544433594,
      "loss": 0.5924675941467286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13528597354888916,
      "rewards/margins": 0.2138102501630783,
      "rewards/rejected": -0.07852427661418915,
      "step": 200
    },
    {
      "epoch": 0.2247792346802248,
      "grad_norm": 9.819232940673828,
      "learning_rate": 4.347305389221557e-07,
      "logits/chosen": 1.5479886531829834,
      "logits/rejected": 1.7383744716644287,
      "logps/chosen": -100.10493469238281,
      "logps/rejected": -70.84512329101562,
      "loss": 0.5756711006164551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15901491045951843,
      "rewards/margins": 0.2525728642940521,
      "rewards/rejected": -0.09355796873569489,
      "step": 210
    },
    {
      "epoch": 0.23548300776023548,
      "grad_norm": 7.087208271026611,
      "learning_rate": 4.2874251497005985e-07,
      "logits/chosen": 1.5610172748565674,
      "logits/rejected": 1.7009871006011963,
      "logps/chosen": -94.79389953613281,
      "logps/rejected": -69.43296813964844,
      "loss": 0.5619078636169433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17162112891674042,
      "rewards/margins": 0.28410452604293823,
      "rewards/rejected": -0.1124834269285202,
      "step": 220
    },
    {
      "epoch": 0.2461867808402462,
      "grad_norm": 7.856379985809326,
      "learning_rate": 4.2275449101796407e-07,
      "logits/chosen": 1.4823147058486938,
      "logits/rejected": 1.7282905578613281,
      "logps/chosen": -89.38038635253906,
      "logps/rejected": -70.40660095214844,
      "loss": 0.5503712654113769,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19074074923992157,
      "rewards/margins": 0.31166332960128784,
      "rewards/rejected": -0.12092256546020508,
      "step": 230
    },
    {
      "epoch": 0.2568905539202569,
      "grad_norm": 7.489407539367676,
      "learning_rate": 4.167664670658683e-07,
      "logits/chosen": 1.5966589450836182,
      "logits/rejected": 1.7562414407730103,
      "logps/chosen": -100.88385772705078,
      "logps/rejected": -70.61569213867188,
      "loss": 0.5412288665771484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20187297463417053,
      "rewards/margins": 0.33501893281936646,
      "rewards/rejected": -0.1331459879875183,
      "step": 240
    },
    {
      "epoch": 0.2675943270002676,
      "grad_norm": 7.757894992828369,
      "learning_rate": 4.107784431137724e-07,
      "logits/chosen": 1.638357400894165,
      "logits/rejected": 1.6881768703460693,
      "logps/chosen": -99.85393524169922,
      "logps/rejected": -70.73631286621094,
      "loss": 0.5263247013092041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22895050048828125,
      "rewards/margins": 0.3698437511920929,
      "rewards/rejected": -0.14089326560497284,
      "step": 250
    },
    {
      "epoch": 0.2782981000802783,
      "grad_norm": 7.4479851722717285,
      "learning_rate": 4.047904191616766e-07,
      "logits/chosen": 1.6495978832244873,
      "logits/rejected": 1.7126394510269165,
      "logps/chosen": -98.19386291503906,
      "logps/rejected": -69.6965103149414,
      "loss": 0.5141325950622558,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.249807208776474,
      "rewards/margins": 0.40186962485313416,
      "rewards/rejected": -0.15206241607666016,
      "step": 260
    },
    {
      "epoch": 0.289001873160289,
      "grad_norm": 7.0618462562561035,
      "learning_rate": 3.9880239520958084e-07,
      "logits/chosen": 1.5478734970092773,
      "logits/rejected": 1.7197999954223633,
      "logps/chosen": -98.96894073486328,
      "logps/rejected": -70.8837890625,
      "loss": 0.5042704582214356,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25116997957229614,
      "rewards/margins": 0.4274437427520752,
      "rewards/rejected": -0.17627373337745667,
      "step": 270
    },
    {
      "epoch": 0.2997056462402997,
      "grad_norm": 7.098910331726074,
      "learning_rate": 3.92814371257485e-07,
      "logits/chosen": 1.6080620288848877,
      "logits/rejected": 1.739174485206604,
      "logps/chosen": -93.48577880859375,
      "logps/rejected": -70.62389373779297,
      "loss": 0.49785604476928713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25901538133621216,
      "rewards/margins": 0.44246333837509155,
      "rewards/rejected": -0.18344800174236298,
      "step": 280
    },
    {
      "epoch": 0.3104094193203104,
      "grad_norm": 8.209229469299316,
      "learning_rate": 3.868263473053892e-07,
      "logits/chosen": 1.6969859600067139,
      "logits/rejected": 1.7968254089355469,
      "logps/chosen": -99.03827667236328,
      "logps/rejected": -72.38906860351562,
      "loss": 0.4695486068725586,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29927676916122437,
      "rewards/margins": 0.5175185203552246,
      "rewards/rejected": -0.21824176609516144,
      "step": 290
    },
    {
      "epoch": 0.3211131924003211,
      "grad_norm": 6.914257049560547,
      "learning_rate": 3.8083832335329344e-07,
      "logits/chosen": 1.5457210540771484,
      "logits/rejected": 1.7393678426742554,
      "logps/chosen": -89.77306365966797,
      "logps/rejected": -70.17650604248047,
      "loss": 0.463011360168457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32002362608909607,
      "rewards/margins": 0.5344886183738708,
      "rewards/rejected": -0.21446505188941956,
      "step": 300
    },
    {
      "epoch": 0.3318169654803318,
      "grad_norm": 6.719634056091309,
      "learning_rate": 3.748502994011976e-07,
      "logits/chosen": 1.6695798635482788,
      "logits/rejected": 1.7295268774032593,
      "logps/chosen": -90.53406524658203,
      "logps/rejected": -71.26698303222656,
      "loss": 0.45705761909484866,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32206642627716064,
      "rewards/margins": 0.5520795583724976,
      "rewards/rejected": -0.23001310229301453,
      "step": 310
    },
    {
      "epoch": 0.34252073856034254,
      "grad_norm": 6.576138019561768,
      "learning_rate": 3.6886227544910177e-07,
      "logits/chosen": 1.6436488628387451,
      "logits/rejected": 1.7413718700408936,
      "logps/chosen": -101.37760925292969,
      "logps/rejected": -71.17918395996094,
      "loss": 0.43967881202697756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34505581855773926,
      "rewards/margins": 0.602986752986908,
      "rewards/rejected": -0.2579309344291687,
      "step": 320
    },
    {
      "epoch": 0.35322451164035323,
      "grad_norm": 6.496006011962891,
      "learning_rate": 3.6287425149700593e-07,
      "logits/chosen": 1.662093162536621,
      "logits/rejected": 1.7380307912826538,
      "logps/chosen": -95.29132843017578,
      "logps/rejected": -71.30264282226562,
      "loss": 0.42283291816711427,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3701649308204651,
      "rewards/margins": 0.6487516164779663,
      "rewards/rejected": -0.2785867154598236,
      "step": 330
    },
    {
      "epoch": 0.3639282847203639,
      "grad_norm": 6.677147388458252,
      "learning_rate": 3.5688622754491015e-07,
      "logits/chosen": 1.6489474773406982,
      "logits/rejected": 1.7989866733551025,
      "logps/chosen": -92.63616180419922,
      "logps/rejected": -71.27923583984375,
      "loss": 0.4017041683197021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4128795266151428,
      "rewards/margins": 0.7152994275093079,
      "rewards/rejected": -0.3024199604988098,
      "step": 340
    },
    {
      "epoch": 0.3746320578003746,
      "grad_norm": 5.897606372833252,
      "learning_rate": 3.5089820359281437e-07,
      "logits/chosen": 1.6566699743270874,
      "logits/rejected": 1.7608058452606201,
      "logps/chosen": -94.15969848632812,
      "logps/rejected": -70.76769256591797,
      "loss": 0.4114583969116211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38643866777420044,
      "rewards/margins": 0.6839457750320435,
      "rewards/rejected": -0.297507107257843,
      "step": 350
    },
    {
      "epoch": 0.3853358308803853,
      "grad_norm": 6.492706775665283,
      "learning_rate": 3.4491017964071854e-07,
      "logits/chosen": 1.6202013492584229,
      "logits/rejected": 1.77265202999115,
      "logps/chosen": -92.70109558105469,
      "logps/rejected": -71.14518737792969,
      "loss": 0.3902395486831665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41617822647094727,
      "rewards/margins": 0.7486181855201721,
      "rewards/rejected": -0.33243995904922485,
      "step": 360
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 6.193428993225098,
      "learning_rate": 3.3892215568862275e-07,
      "logits/chosen": 1.6211570501327515,
      "logits/rejected": 1.7373650074005127,
      "logps/chosen": -90.1979751586914,
      "logps/rejected": -71.37921905517578,
      "loss": 0.3881149053573608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41052594780921936,
      "rewards/margins": 0.7598143219947815,
      "rewards/rejected": -0.34928831458091736,
      "step": 370
    },
    {
      "epoch": 0.40674337704040675,
      "grad_norm": 6.197150707244873,
      "learning_rate": 3.3293413173652697e-07,
      "logits/chosen": 1.5564836263656616,
      "logits/rejected": 1.7266842126846313,
      "logps/chosen": -95.49320983886719,
      "logps/rejected": -72.54872131347656,
      "loss": 0.36820387840270996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4559079110622406,
      "rewards/margins": 0.8260034322738647,
      "rewards/rejected": -0.3700955808162689,
      "step": 380
    },
    {
      "epoch": 0.41744715012041744,
      "grad_norm": 5.682110786437988,
      "learning_rate": 3.269461077844311e-07,
      "logits/chosen": 1.5680351257324219,
      "logits/rejected": 1.7714035511016846,
      "logps/chosen": -90.64232635498047,
      "logps/rejected": -73.0176010131836,
      "loss": 0.3437328815460205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5225237011909485,
      "rewards/margins": 0.9017510414123535,
      "rewards/rejected": -0.37922734022140503,
      "step": 390
    },
    {
      "epoch": 0.42815092320042814,
      "grad_norm": 5.8264994621276855,
      "learning_rate": 3.209580838323353e-07,
      "logits/chosen": 1.6181936264038086,
      "logits/rejected": 1.7681995630264282,
      "logps/chosen": -94.05583953857422,
      "logps/rejected": -72.37445068359375,
      "loss": 0.34638774394989014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49568861722946167,
      "rewards/margins": 0.8957290649414062,
      "rewards/rejected": -0.4000404477119446,
      "step": 400
    },
    {
      "epoch": 0.4388546962804388,
      "grad_norm": 5.834861755371094,
      "learning_rate": 3.149700598802395e-07,
      "logits/chosen": 1.6122732162475586,
      "logits/rejected": 1.7244033813476562,
      "logps/chosen": -91.63870239257812,
      "logps/rejected": -73.1224365234375,
      "loss": 0.33021016120910646,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5486727952957153,
      "rewards/margins": 0.9576877355575562,
      "rewards/rejected": -0.4090149402618408,
      "step": 410
    },
    {
      "epoch": 0.4495584693604496,
      "grad_norm": 5.51858377456665,
      "learning_rate": 3.089820359281437e-07,
      "logits/chosen": 1.6775171756744385,
      "logits/rejected": 1.8410613536834717,
      "logps/chosen": -95.22389221191406,
      "logps/rejected": -72.4255142211914,
      "loss": 0.33907532691955566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4861533045768738,
      "rewards/margins": 0.9185035824775696,
      "rewards/rejected": -0.432350218296051,
      "step": 420
    },
    {
      "epoch": 0.46026224244046027,
      "grad_norm": 5.675708770751953,
      "learning_rate": 3.029940119760479e-07,
      "logits/chosen": 1.636405348777771,
      "logits/rejected": 1.7928879261016846,
      "logps/chosen": -97.23365783691406,
      "logps/rejected": -72.67338562011719,
      "loss": 0.3372178554534912,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4979669451713562,
      "rewards/margins": 0.9371122121810913,
      "rewards/rejected": -0.43914517760276794,
      "step": 430
    },
    {
      "epoch": 0.47096601552047096,
      "grad_norm": 5.508388519287109,
      "learning_rate": 2.970059880239521e-07,
      "logits/chosen": 1.6702356338500977,
      "logits/rejected": 1.807557463645935,
      "logps/chosen": -83.1475830078125,
      "logps/rejected": -73.44693756103516,
      "loss": 0.31704206466674806,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5440910458564758,
      "rewards/margins": 1.007099986076355,
      "rewards/rejected": -0.4630088210105896,
      "step": 440
    },
    {
      "epoch": 0.48166978860048165,
      "grad_norm": 5.862466335296631,
      "learning_rate": 2.9101796407185623e-07,
      "logits/chosen": 1.6620204448699951,
      "logits/rejected": 1.7857038974761963,
      "logps/chosen": -93.39292907714844,
      "logps/rejected": -74.21806335449219,
      "loss": 0.3062004089355469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5721822381019592,
      "rewards/margins": 1.0536423921585083,
      "rewards/rejected": -0.4814601540565491,
      "step": 450
    },
    {
      "epoch": 0.4923735616804924,
      "grad_norm": 5.086695194244385,
      "learning_rate": 2.8502994011976045e-07,
      "logits/chosen": 1.6780589818954468,
      "logits/rejected": 1.7611554861068726,
      "logps/chosen": -93.4439926147461,
      "logps/rejected": -73.86016845703125,
      "loss": 0.2953150749206543,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5849720239639282,
      "rewards/margins": 1.0891199111938477,
      "rewards/rejected": -0.5041478872299194,
      "step": 460
    },
    {
      "epoch": 0.5030773347605031,
      "grad_norm": 5.000400543212891,
      "learning_rate": 2.7904191616766467e-07,
      "logits/chosen": 1.722110390663147,
      "logits/rejected": 1.8043245077133179,
      "logps/chosen": -95.8530044555664,
      "logps/rejected": -74.17149353027344,
      "loss": 0.2876912832260132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5920961499214172,
      "rewards/margins": 1.1115853786468506,
      "rewards/rejected": -0.5194891691207886,
      "step": 470
    },
    {
      "epoch": 0.5137811078405138,
      "grad_norm": 4.843569755554199,
      "learning_rate": 2.7305389221556884e-07,
      "logits/chosen": 1.6513891220092773,
      "logits/rejected": 1.7580721378326416,
      "logps/chosen": -88.65401458740234,
      "logps/rejected": -74.3830337524414,
      "loss": 0.2707385063171387,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6374225616455078,
      "rewards/margins": 1.187923789024353,
      "rewards/rejected": -0.5505013465881348,
      "step": 480
    },
    {
      "epoch": 0.5244848809205245,
      "grad_norm": 4.905799865722656,
      "learning_rate": 2.6706586826347305e-07,
      "logits/chosen": 1.662369966506958,
      "logits/rejected": 1.8304805755615234,
      "logps/chosen": -102.0279769897461,
      "logps/rejected": -75.33492279052734,
      "loss": 0.2732326745986938,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6177634000778198,
      "rewards/margins": 1.179307222366333,
      "rewards/rejected": -0.5615440011024475,
      "step": 490
    },
    {
      "epoch": 0.5351886540005352,
      "grad_norm": 4.733295917510986,
      "learning_rate": 2.6107784431137727e-07,
      "logits/chosen": 1.7069475650787354,
      "logits/rejected": 1.8011726140975952,
      "logps/chosen": -87.66189575195312,
      "logps/rejected": -74.02265930175781,
      "loss": 0.27316253185272216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6247161626815796,
      "rewards/margins": 1.1876275539398193,
      "rewards/rejected": -0.562911331653595,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
