{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 935,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010703773080010704,
      "grad_norm": 7.6642746925354,
      "learning_rate": 4.5e-08,
      "logits/chosen": 1.5458600521087646,
      "logits/rejected": 1.6335700750350952,
      "logps/chosen": -95.66376495361328,
      "logps/rejected": -68.86592102050781,
      "loss": 0.6961907863616943,
      "rewards/accuracies": 0.25,
      "rewards/chosen": -0.0024644467048346996,
      "rewards/margins": -0.005714812316000462,
      "rewards/rejected": 0.0032503653783351183,
      "step": 10
    },
    {
      "epoch": 0.02140754616002141,
      "grad_norm": 7.9436540603637695,
      "learning_rate": 9.499999999999999e-08,
      "logits/chosen": 1.5691773891448975,
      "logits/rejected": 1.682748794555664,
      "logps/chosen": -102.9636001586914,
      "logps/rejected": -69.40105438232422,
      "loss": 0.6936207294464112,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": -0.001637868583202362,
      "rewards/margins": -0.0004828590899705887,
      "rewards/rejected": -0.001155009143985808,
      "step": 20
    },
    {
      "epoch": 0.03211131924003211,
      "grad_norm": 9.800686836242676,
      "learning_rate": 1.45e-07,
      "logits/chosen": 1.6136157512664795,
      "logits/rejected": 1.7152601480484009,
      "logps/chosen": -98.2775650024414,
      "logps/rejected": -68.61070251464844,
      "loss": 0.6963084697723388,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": -0.010276569053530693,
      "rewards/margins": -0.005914372857660055,
      "rewards/rejected": -0.0043621971271932125,
      "step": 30
    },
    {
      "epoch": 0.04281509232004282,
      "grad_norm": 8.499246597290039,
      "learning_rate": 1.9499999999999999e-07,
      "logits/chosen": 1.5499022006988525,
      "logits/rejected": 1.6691229343414307,
      "logps/chosen": -94.12925720214844,
      "logps/rejected": -68.43936920166016,
      "loss": 0.6901679515838623,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.0018616060260683298,
      "rewards/margins": 0.0065512508153915405,
      "rewards/rejected": -0.004689645953476429,
      "step": 40
    },
    {
      "epoch": 0.05351886540005352,
      "grad_norm": 7.339582920074463,
      "learning_rate": 2.45e-07,
      "logits/chosen": 1.5132286548614502,
      "logits/rejected": 1.693886160850525,
      "logps/chosen": -96.28523254394531,
      "logps/rejected": -69.509521484375,
      "loss": 0.6953918933868408,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": -0.0013333609094843268,
      "rewards/margins": -0.00400154571980238,
      "rewards/rejected": 0.0026681851595640182,
      "step": 50
    },
    {
      "epoch": 0.06422263848006422,
      "grad_norm": 7.616441249847412,
      "learning_rate": 2.95e-07,
      "logits/chosen": 1.4452617168426514,
      "logits/rejected": 1.6660493612289429,
      "logps/chosen": -95.88685607910156,
      "logps/rejected": -69.34846496582031,
      "loss": 0.6899733066558837,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.006554870866239071,
      "rewards/margins": 0.0069150542840361595,
      "rewards/rejected": -0.000360183825250715,
      "step": 60
    },
    {
      "epoch": 0.07492641156007493,
      "grad_norm": 8.235770225524902,
      "learning_rate": 3.45e-07,
      "logits/chosen": 1.580561637878418,
      "logits/rejected": 1.6698585748672485,
      "logps/chosen": -96.81475830078125,
      "logps/rejected": -69.85762786865234,
      "loss": 0.6874208450317383,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.009662116877734661,
      "rewards/margins": 0.011918206699192524,
      "rewards/rejected": -0.002256088424474001,
      "step": 70
    },
    {
      "epoch": 0.08563018464008564,
      "grad_norm": 8.219965934753418,
      "learning_rate": 3.95e-07,
      "logits/chosen": 1.5853630304336548,
      "logits/rejected": 1.6623961925506592,
      "logps/chosen": -93.53421020507812,
      "logps/rejected": -68.52235412597656,
      "loss": 0.6875598430633545,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.0035239695571362972,
      "rewards/margins": 0.011648541316390038,
      "rewards/rejected": -0.008124571293592453,
      "step": 80
    },
    {
      "epoch": 0.09633395772009633,
      "grad_norm": 8.622967720031738,
      "learning_rate": 4.45e-07,
      "logits/chosen": 1.5529725551605225,
      "logits/rejected": 1.6251685619354248,
      "logps/chosen": -100.60663604736328,
      "logps/rejected": -70.12767028808594,
      "loss": 0.6861987590789795,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.009107065387070179,
      "rewards/margins": 0.014429683797061443,
      "rewards/rejected": -0.005322618409991264,
      "step": 90
    },
    {
      "epoch": 0.10703773080010703,
      "grad_norm": 9.32264232635498,
      "learning_rate": 4.95e-07,
      "logits/chosen": 1.5080032348632812,
      "logits/rejected": 1.6655700206756592,
      "logps/chosen": -102.71744537353516,
      "logps/rejected": -69.01951599121094,
      "loss": 0.6753100395202637,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.02363564446568489,
      "rewards/margins": 0.0367756113409996,
      "rewards/rejected": -0.013139968737959862,
      "step": 100
    },
    {
      "epoch": 0.11774150388011774,
      "grad_norm": 9.538298606872559,
      "learning_rate": 4.946107784431138e-07,
      "logits/chosen": 1.580507516860962,
      "logits/rejected": 1.6615736484527588,
      "logps/chosen": -102.25989532470703,
      "logps/rejected": -68.10111236572266,
      "loss": 0.6748167514801026,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.03098013997077942,
      "rewards/margins": 0.037550754845142365,
      "rewards/rejected": -0.006570611149072647,
      "step": 110
    },
    {
      "epoch": 0.12844527696012845,
      "grad_norm": 8.479535102844238,
      "learning_rate": 4.886227544910179e-07,
      "logits/chosen": 1.5477255582809448,
      "logits/rejected": 1.6556965112686157,
      "logps/chosen": -98.18047332763672,
      "logps/rejected": -69.49666595458984,
      "loss": 0.6664756298065185,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": 0.03427378088235855,
      "rewards/margins": 0.054745931178331375,
      "rewards/rejected": -0.020472148433327675,
      "step": 120
    },
    {
      "epoch": 0.13914905004013914,
      "grad_norm": 9.705656051635742,
      "learning_rate": 4.826347305389221e-07,
      "logits/chosen": 1.5088087320327759,
      "logits/rejected": 1.6631864309310913,
      "logps/chosen": -90.45843505859375,
      "logps/rejected": -69.1974868774414,
      "loss": 0.6600105285644531,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": 0.04008815437555313,
      "rewards/margins": 0.06805978715419769,
      "rewards/rejected": -0.027971630915999413,
      "step": 130
    },
    {
      "epoch": 0.14985282312014986,
      "grad_norm": 8.278407096862793,
      "learning_rate": 4.766467065868263e-07,
      "logits/chosen": 1.524910807609558,
      "logits/rejected": 1.6695661544799805,
      "logps/chosen": -90.56741333007812,
      "logps/rejected": -68.1983871459961,
      "loss": 0.6498828411102295,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.054790329188108444,
      "rewards/margins": 0.08905218541622162,
      "rewards/rejected": -0.03426186740398407,
      "step": 140
    },
    {
      "epoch": 0.16055659620016055,
      "grad_norm": 9.161384582519531,
      "learning_rate": 4.7065868263473054e-07,
      "logits/chosen": 1.5155388116836548,
      "logits/rejected": 1.7237215042114258,
      "logps/chosen": -99.10457611083984,
      "logps/rejected": -69.4609603881836,
      "loss": 0.646856689453125,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": 0.061636824160814285,
      "rewards/margins": 0.09540145844221115,
      "rewards/rejected": -0.033764638006687164,
      "step": 150
    },
    {
      "epoch": 0.17126036928017127,
      "grad_norm": 9.973076820373535,
      "learning_rate": 4.646706586826347e-07,
      "logits/chosen": 1.6003284454345703,
      "logits/rejected": 1.697081208229065,
      "logps/chosen": -98.66423797607422,
      "logps/rejected": -69.4610595703125,
      "loss": 0.6331616878509522,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": 0.08159245550632477,
      "rewards/margins": 0.1247086375951767,
      "rewards/rejected": -0.043116189539432526,
      "step": 160
    },
    {
      "epoch": 0.18196414236018196,
      "grad_norm": 8.571202278137207,
      "learning_rate": 4.586826347305389e-07,
      "logits/chosen": 1.5911263227462769,
      "logits/rejected": 1.6706289052963257,
      "logps/chosen": -99.03817749023438,
      "logps/rejected": -70.0931167602539,
      "loss": 0.6234090805053711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09243493527173996,
      "rewards/margins": 0.1455097198486328,
      "rewards/rejected": -0.05307478830218315,
      "step": 170
    },
    {
      "epoch": 0.19266791544019266,
      "grad_norm": 8.174881935119629,
      "learning_rate": 4.5269461077844314e-07,
      "logits/chosen": 1.5722379684448242,
      "logits/rejected": 1.6388050317764282,
      "logps/chosen": -95.92591857910156,
      "logps/rejected": -69.16011810302734,
      "loss": 0.6038780689239502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11492500454187393,
      "rewards/margins": 0.18828174471855164,
      "rewards/rejected": -0.07335672527551651,
      "step": 180
    },
    {
      "epoch": 0.20337168852020338,
      "grad_norm": 8.453973770141602,
      "learning_rate": 4.4670658682634725e-07,
      "logits/chosen": 1.6810516119003296,
      "logits/rejected": 1.6408863067626953,
      "logps/chosen": -98.49278259277344,
      "logps/rejected": -70.6387710571289,
      "loss": 0.6022417545318604,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.11506612598896027,
      "rewards/margins": 0.1922977715730667,
      "rewards/rejected": -0.07723163813352585,
      "step": 190
    },
    {
      "epoch": 0.21407546160021407,
      "grad_norm": 8.054610252380371,
      "learning_rate": 4.4071856287425147e-07,
      "logits/chosen": 1.5649921894073486,
      "logits/rejected": 1.6489553451538086,
      "logps/chosen": -92.58233642578125,
      "logps/rejected": -68.34495544433594,
      "loss": 0.5924675941467286,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.13528597354888916,
      "rewards/margins": 0.2138102501630783,
      "rewards/rejected": -0.07852427661418915,
      "step": 200
    },
    {
      "epoch": 0.2247792346802248,
      "grad_norm": 9.819232940673828,
      "learning_rate": 4.347305389221557e-07,
      "logits/chosen": 1.5479886531829834,
      "logits/rejected": 1.7383744716644287,
      "logps/chosen": -100.10493469238281,
      "logps/rejected": -70.84512329101562,
      "loss": 0.5756711006164551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.15901491045951843,
      "rewards/margins": 0.2525728642940521,
      "rewards/rejected": -0.09355796873569489,
      "step": 210
    },
    {
      "epoch": 0.23548300776023548,
      "grad_norm": 7.087208271026611,
      "learning_rate": 4.2874251497005985e-07,
      "logits/chosen": 1.5610172748565674,
      "logits/rejected": 1.7009871006011963,
      "logps/chosen": -94.79389953613281,
      "logps/rejected": -69.43296813964844,
      "loss": 0.5619078636169433,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.17162112891674042,
      "rewards/margins": 0.28410452604293823,
      "rewards/rejected": -0.1124834269285202,
      "step": 220
    },
    {
      "epoch": 0.2461867808402462,
      "grad_norm": 7.856379985809326,
      "learning_rate": 4.2275449101796407e-07,
      "logits/chosen": 1.4823147058486938,
      "logits/rejected": 1.7282905578613281,
      "logps/chosen": -89.38038635253906,
      "logps/rejected": -70.40660095214844,
      "loss": 0.5503712654113769,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.19074074923992157,
      "rewards/margins": 0.31166332960128784,
      "rewards/rejected": -0.12092256546020508,
      "step": 230
    },
    {
      "epoch": 0.2568905539202569,
      "grad_norm": 7.489407539367676,
      "learning_rate": 4.167664670658683e-07,
      "logits/chosen": 1.5966589450836182,
      "logits/rejected": 1.7562414407730103,
      "logps/chosen": -100.88385772705078,
      "logps/rejected": -70.61569213867188,
      "loss": 0.5412288665771484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.20187297463417053,
      "rewards/margins": 0.33501893281936646,
      "rewards/rejected": -0.1331459879875183,
      "step": 240
    },
    {
      "epoch": 0.2675943270002676,
      "grad_norm": 7.757894992828369,
      "learning_rate": 4.107784431137724e-07,
      "logits/chosen": 1.638357400894165,
      "logits/rejected": 1.6881768703460693,
      "logps/chosen": -99.85393524169922,
      "logps/rejected": -70.73631286621094,
      "loss": 0.5263247013092041,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.22895050048828125,
      "rewards/margins": 0.3698437511920929,
      "rewards/rejected": -0.14089326560497284,
      "step": 250
    },
    {
      "epoch": 0.2782981000802783,
      "grad_norm": 7.4479851722717285,
      "learning_rate": 4.047904191616766e-07,
      "logits/chosen": 1.6495978832244873,
      "logits/rejected": 1.7126394510269165,
      "logps/chosen": -98.19386291503906,
      "logps/rejected": -69.6965103149414,
      "loss": 0.5141325950622558,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.249807208776474,
      "rewards/margins": 0.40186962485313416,
      "rewards/rejected": -0.15206241607666016,
      "step": 260
    },
    {
      "epoch": 0.289001873160289,
      "grad_norm": 7.0618462562561035,
      "learning_rate": 3.9880239520958084e-07,
      "logits/chosen": 1.5478734970092773,
      "logits/rejected": 1.7197999954223633,
      "logps/chosen": -98.96894073486328,
      "logps/rejected": -70.8837890625,
      "loss": 0.5042704582214356,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25116997957229614,
      "rewards/margins": 0.4274437427520752,
      "rewards/rejected": -0.17627373337745667,
      "step": 270
    },
    {
      "epoch": 0.2997056462402997,
      "grad_norm": 7.098910331726074,
      "learning_rate": 3.92814371257485e-07,
      "logits/chosen": 1.6080620288848877,
      "logits/rejected": 1.739174485206604,
      "logps/chosen": -93.48577880859375,
      "logps/rejected": -70.62389373779297,
      "loss": 0.49785604476928713,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.25901538133621216,
      "rewards/margins": 0.44246333837509155,
      "rewards/rejected": -0.18344800174236298,
      "step": 280
    },
    {
      "epoch": 0.3104094193203104,
      "grad_norm": 8.209229469299316,
      "learning_rate": 3.868263473053892e-07,
      "logits/chosen": 1.6969859600067139,
      "logits/rejected": 1.7968254089355469,
      "logps/chosen": -99.03827667236328,
      "logps/rejected": -72.38906860351562,
      "loss": 0.4695486068725586,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.29927676916122437,
      "rewards/margins": 0.5175185203552246,
      "rewards/rejected": -0.21824176609516144,
      "step": 290
    },
    {
      "epoch": 0.3211131924003211,
      "grad_norm": 6.914257049560547,
      "learning_rate": 3.8083832335329344e-07,
      "logits/chosen": 1.5457210540771484,
      "logits/rejected": 1.7393678426742554,
      "logps/chosen": -89.77306365966797,
      "logps/rejected": -70.17650604248047,
      "loss": 0.463011360168457,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32002362608909607,
      "rewards/margins": 0.5344886183738708,
      "rewards/rejected": -0.21446505188941956,
      "step": 300
    },
    {
      "epoch": 0.3318169654803318,
      "grad_norm": 6.719634056091309,
      "learning_rate": 3.748502994011976e-07,
      "logits/chosen": 1.6695798635482788,
      "logits/rejected": 1.7295268774032593,
      "logps/chosen": -90.53406524658203,
      "logps/rejected": -71.26698303222656,
      "loss": 0.45705761909484866,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.32206642627716064,
      "rewards/margins": 0.5520795583724976,
      "rewards/rejected": -0.23001310229301453,
      "step": 310
    },
    {
      "epoch": 0.34252073856034254,
      "grad_norm": 6.576138019561768,
      "learning_rate": 3.6886227544910177e-07,
      "logits/chosen": 1.6436488628387451,
      "logits/rejected": 1.7413718700408936,
      "logps/chosen": -101.37760925292969,
      "logps/rejected": -71.17918395996094,
      "loss": 0.43967881202697756,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.34505581855773926,
      "rewards/margins": 0.602986752986908,
      "rewards/rejected": -0.2579309344291687,
      "step": 320
    },
    {
      "epoch": 0.35322451164035323,
      "grad_norm": 6.496006011962891,
      "learning_rate": 3.6287425149700593e-07,
      "logits/chosen": 1.662093162536621,
      "logits/rejected": 1.7380307912826538,
      "logps/chosen": -95.29132843017578,
      "logps/rejected": -71.30264282226562,
      "loss": 0.42283291816711427,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.3701649308204651,
      "rewards/margins": 0.6487516164779663,
      "rewards/rejected": -0.2785867154598236,
      "step": 330
    },
    {
      "epoch": 0.3639282847203639,
      "grad_norm": 6.677147388458252,
      "learning_rate": 3.5688622754491015e-07,
      "logits/chosen": 1.6489474773406982,
      "logits/rejected": 1.7989866733551025,
      "logps/chosen": -92.63616180419922,
      "logps/rejected": -71.27923583984375,
      "loss": 0.4017041683197021,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4128795266151428,
      "rewards/margins": 0.7152994275093079,
      "rewards/rejected": -0.3024199604988098,
      "step": 340
    },
    {
      "epoch": 0.3746320578003746,
      "grad_norm": 5.897606372833252,
      "learning_rate": 3.5089820359281437e-07,
      "logits/chosen": 1.6566699743270874,
      "logits/rejected": 1.7608058452606201,
      "logps/chosen": -94.15969848632812,
      "logps/rejected": -70.76769256591797,
      "loss": 0.4114583969116211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.38643866777420044,
      "rewards/margins": 0.6839457750320435,
      "rewards/rejected": -0.297507107257843,
      "step": 350
    },
    {
      "epoch": 0.3853358308803853,
      "grad_norm": 6.492706775665283,
      "learning_rate": 3.4491017964071854e-07,
      "logits/chosen": 1.6202013492584229,
      "logits/rejected": 1.77265202999115,
      "logps/chosen": -92.70109558105469,
      "logps/rejected": -71.14518737792969,
      "loss": 0.3902395486831665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41617822647094727,
      "rewards/margins": 0.7486181855201721,
      "rewards/rejected": -0.33243995904922485,
      "step": 360
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 6.193428993225098,
      "learning_rate": 3.3892215568862275e-07,
      "logits/chosen": 1.6211570501327515,
      "logits/rejected": 1.7373650074005127,
      "logps/chosen": -90.1979751586914,
      "logps/rejected": -71.37921905517578,
      "loss": 0.3881149053573608,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.41052594780921936,
      "rewards/margins": 0.7598143219947815,
      "rewards/rejected": -0.34928831458091736,
      "step": 370
    },
    {
      "epoch": 0.40674337704040675,
      "grad_norm": 6.197150707244873,
      "learning_rate": 3.3293413173652697e-07,
      "logits/chosen": 1.5564836263656616,
      "logits/rejected": 1.7266842126846313,
      "logps/chosen": -95.49320983886719,
      "logps/rejected": -72.54872131347656,
      "loss": 0.36820387840270996,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4559079110622406,
      "rewards/margins": 0.8260034322738647,
      "rewards/rejected": -0.3700955808162689,
      "step": 380
    },
    {
      "epoch": 0.41744715012041744,
      "grad_norm": 5.682110786437988,
      "learning_rate": 3.269461077844311e-07,
      "logits/chosen": 1.5680351257324219,
      "logits/rejected": 1.7714035511016846,
      "logps/chosen": -90.64232635498047,
      "logps/rejected": -73.0176010131836,
      "loss": 0.3437328815460205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5225237011909485,
      "rewards/margins": 0.9017510414123535,
      "rewards/rejected": -0.37922734022140503,
      "step": 390
    },
    {
      "epoch": 0.42815092320042814,
      "grad_norm": 5.8264994621276855,
      "learning_rate": 3.209580838323353e-07,
      "logits/chosen": 1.6181936264038086,
      "logits/rejected": 1.7681995630264282,
      "logps/chosen": -94.05583953857422,
      "logps/rejected": -72.37445068359375,
      "loss": 0.34638774394989014,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.49568861722946167,
      "rewards/margins": 0.8957290649414062,
      "rewards/rejected": -0.4000404477119446,
      "step": 400
    },
    {
      "epoch": 0.4388546962804388,
      "grad_norm": 5.834861755371094,
      "learning_rate": 3.149700598802395e-07,
      "logits/chosen": 1.6122732162475586,
      "logits/rejected": 1.7244033813476562,
      "logps/chosen": -91.63870239257812,
      "logps/rejected": -73.1224365234375,
      "loss": 0.33021016120910646,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5486727952957153,
      "rewards/margins": 0.9576877355575562,
      "rewards/rejected": -0.4090149402618408,
      "step": 410
    },
    {
      "epoch": 0.4495584693604496,
      "grad_norm": 5.51858377456665,
      "learning_rate": 3.089820359281437e-07,
      "logits/chosen": 1.6775171756744385,
      "logits/rejected": 1.8410613536834717,
      "logps/chosen": -95.22389221191406,
      "logps/rejected": -72.4255142211914,
      "loss": 0.33907532691955566,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4861533045768738,
      "rewards/margins": 0.9185035824775696,
      "rewards/rejected": -0.432350218296051,
      "step": 420
    },
    {
      "epoch": 0.46026224244046027,
      "grad_norm": 5.675708770751953,
      "learning_rate": 3.029940119760479e-07,
      "logits/chosen": 1.636405348777771,
      "logits/rejected": 1.7928879261016846,
      "logps/chosen": -97.23365783691406,
      "logps/rejected": -72.67338562011719,
      "loss": 0.3372178554534912,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.4979669451713562,
      "rewards/margins": 0.9371122121810913,
      "rewards/rejected": -0.43914517760276794,
      "step": 430
    },
    {
      "epoch": 0.47096601552047096,
      "grad_norm": 5.508388519287109,
      "learning_rate": 2.970059880239521e-07,
      "logits/chosen": 1.6702356338500977,
      "logits/rejected": 1.807557463645935,
      "logps/chosen": -83.1475830078125,
      "logps/rejected": -73.44693756103516,
      "loss": 0.31704206466674806,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5440910458564758,
      "rewards/margins": 1.007099986076355,
      "rewards/rejected": -0.4630088210105896,
      "step": 440
    },
    {
      "epoch": 0.48166978860048165,
      "grad_norm": 5.862466335296631,
      "learning_rate": 2.9101796407185623e-07,
      "logits/chosen": 1.6620204448699951,
      "logits/rejected": 1.7857038974761963,
      "logps/chosen": -93.39292907714844,
      "logps/rejected": -74.21806335449219,
      "loss": 0.3062004089355469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5721822381019592,
      "rewards/margins": 1.0536423921585083,
      "rewards/rejected": -0.4814601540565491,
      "step": 450
    },
    {
      "epoch": 0.4923735616804924,
      "grad_norm": 5.086695194244385,
      "learning_rate": 2.8502994011976045e-07,
      "logits/chosen": 1.6780589818954468,
      "logits/rejected": 1.7611554861068726,
      "logps/chosen": -93.4439926147461,
      "logps/rejected": -73.86016845703125,
      "loss": 0.2953150749206543,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5849720239639282,
      "rewards/margins": 1.0891199111938477,
      "rewards/rejected": -0.5041478872299194,
      "step": 460
    },
    {
      "epoch": 0.5030773347605031,
      "grad_norm": 5.000400543212891,
      "learning_rate": 2.7904191616766467e-07,
      "logits/chosen": 1.722110390663147,
      "logits/rejected": 1.8043245077133179,
      "logps/chosen": -95.8530044555664,
      "logps/rejected": -74.17149353027344,
      "loss": 0.2876912832260132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5920961499214172,
      "rewards/margins": 1.1115853786468506,
      "rewards/rejected": -0.5194891691207886,
      "step": 470
    },
    {
      "epoch": 0.5137811078405138,
      "grad_norm": 4.843569755554199,
      "learning_rate": 2.7305389221556884e-07,
      "logits/chosen": 1.6513891220092773,
      "logits/rejected": 1.7580721378326416,
      "logps/chosen": -88.65401458740234,
      "logps/rejected": -74.3830337524414,
      "loss": 0.2707385063171387,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6374225616455078,
      "rewards/margins": 1.187923789024353,
      "rewards/rejected": -0.5505013465881348,
      "step": 480
    },
    {
      "epoch": 0.5244848809205245,
      "grad_norm": 4.905799865722656,
      "learning_rate": 2.6706586826347305e-07,
      "logits/chosen": 1.662369966506958,
      "logits/rejected": 1.8304805755615234,
      "logps/chosen": -102.0279769897461,
      "logps/rejected": -75.33492279052734,
      "loss": 0.2732326745986938,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6177634000778198,
      "rewards/margins": 1.179307222366333,
      "rewards/rejected": -0.5615440011024475,
      "step": 490
    },
    {
      "epoch": 0.5351886540005352,
      "grad_norm": 4.733295917510986,
      "learning_rate": 2.6107784431137727e-07,
      "logits/chosen": 1.7069475650787354,
      "logits/rejected": 1.8011726140975952,
      "logps/chosen": -87.66189575195312,
      "logps/rejected": -74.02265930175781,
      "loss": 0.27316253185272216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6247161626815796,
      "rewards/margins": 1.1876275539398193,
      "rewards/rejected": -0.562911331653595,
      "step": 500
    },
    {
      "epoch": 0.5458924270805459,
      "grad_norm": 4.8323750495910645,
      "learning_rate": 2.5508982035928144e-07,
      "logits/chosen": 1.673409104347229,
      "logits/rejected": 1.7710580825805664,
      "logps/chosen": -93.25462341308594,
      "logps/rejected": -73.79750061035156,
      "loss": 0.2702951908111572,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6142935752868652,
      "rewards/margins": 1.1952719688415527,
      "rewards/rejected": -0.5809783935546875,
      "step": 510
    },
    {
      "epoch": 0.5565962001605566,
      "grad_norm": 4.474382400512695,
      "learning_rate": 2.491017964071856e-07,
      "logits/chosen": 1.6711156368255615,
      "logits/rejected": 1.756090760231018,
      "logps/chosen": -88.78832244873047,
      "logps/rejected": -74.42101287841797,
      "loss": 0.2530112028121948,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6802138090133667,
      "rewards/margins": 1.2722969055175781,
      "rewards/rejected": -0.5920831561088562,
      "step": 520
    },
    {
      "epoch": 0.5672999732405672,
      "grad_norm": 4.381737232208252,
      "learning_rate": 2.431137724550898e-07,
      "logits/chosen": 1.6540660858154297,
      "logits/rejected": 1.7969061136245728,
      "logps/chosen": -91.30738830566406,
      "logps/rejected": -74.4197769165039,
      "loss": 0.26184208393096925,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6369196176528931,
      "rewards/margins": 1.2429739236831665,
      "rewards/rejected": -0.6060542464256287,
      "step": 530
    },
    {
      "epoch": 0.578003746320578,
      "grad_norm": 4.659915924072266,
      "learning_rate": 2.3712574850299399e-07,
      "logits/chosen": 1.6202383041381836,
      "logits/rejected": 1.7927322387695312,
      "logps/chosen": -86.14110565185547,
      "logps/rejected": -75.35411834716797,
      "loss": 0.2453221321105957,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6478351354598999,
      "rewards/margins": 1.3101121187210083,
      "rewards/rejected": -0.6622768640518188,
      "step": 540
    },
    {
      "epoch": 0.5887075194005887,
      "grad_norm": 4.109188079833984,
      "learning_rate": 2.311377245508982e-07,
      "logits/chosen": 1.6030902862548828,
      "logits/rejected": 1.7665773630142212,
      "logps/chosen": -85.1181411743164,
      "logps/rejected": -74.65866088867188,
      "loss": 0.23270683288574218,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7052653431892395,
      "rewards/margins": 1.3679258823394775,
      "rewards/rejected": -0.6626607775688171,
      "step": 550
    },
    {
      "epoch": 0.5994112924805994,
      "grad_norm": 3.994331121444702,
      "learning_rate": 2.251497005988024e-07,
      "logits/chosen": 1.6793935298919678,
      "logits/rejected": 1.786303162574768,
      "logps/chosen": -84.62678527832031,
      "logps/rejected": -75.80341339111328,
      "loss": 0.234452486038208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6960364580154419,
      "rewards/margins": 1.3683829307556152,
      "rewards/rejected": -0.6723464727401733,
      "step": 560
    },
    {
      "epoch": 0.6101150655606101,
      "grad_norm": 4.185056209564209,
      "learning_rate": 2.1916167664670656e-07,
      "logits/chosen": 1.6761308908462524,
      "logits/rejected": 1.8041868209838867,
      "logps/chosen": -95.13810729980469,
      "logps/rejected": -77.24950408935547,
      "loss": 0.2207775354385376,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6959063410758972,
      "rewards/margins": 1.4329745769500732,
      "rewards/rejected": -0.7370683550834656,
      "step": 570
    },
    {
      "epoch": 0.6208188386406208,
      "grad_norm": 4.101385593414307,
      "learning_rate": 2.1317365269461078e-07,
      "logits/chosen": 1.5728423595428467,
      "logits/rejected": 1.7927745580673218,
      "logps/chosen": -84.63812255859375,
      "logps/rejected": -76.705322265625,
      "loss": 0.21555006504058838,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7478241920471191,
      "rewards/margins": 1.4643570184707642,
      "rewards/rejected": -0.716532826423645,
      "step": 580
    },
    {
      "epoch": 0.6315226117206315,
      "grad_norm": 4.221090793609619,
      "learning_rate": 2.0718562874251497e-07,
      "logits/chosen": 1.717303991317749,
      "logits/rejected": 1.7860889434814453,
      "logps/chosen": -100.34870147705078,
      "logps/rejected": -75.70601654052734,
      "loss": 0.207204270362854,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7686330676078796,
      "rewards/margins": 1.491900086402893,
      "rewards/rejected": -0.7232669591903687,
      "step": 590
    },
    {
      "epoch": 0.6422263848006422,
      "grad_norm": 3.9710655212402344,
      "learning_rate": 2.0119760479041914e-07,
      "logits/chosen": 1.656393051147461,
      "logits/rejected": 1.8475900888442993,
      "logps/chosen": -84.76692962646484,
      "logps/rejected": -76.09647369384766,
      "loss": 0.211175537109375,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7290211915969849,
      "rewards/margins": 1.4782037734985352,
      "rewards/rejected": -0.7491824626922607,
      "step": 600
    },
    {
      "epoch": 0.6529301578806529,
      "grad_norm": 4.231086730957031,
      "learning_rate": 1.9520958083832333e-07,
      "logits/chosen": 1.6238362789154053,
      "logits/rejected": 1.751612663269043,
      "logps/chosen": -86.59745788574219,
      "logps/rejected": -75.83220672607422,
      "loss": 0.21694672107696533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7033053636550903,
      "rewards/margins": 1.4474931955337524,
      "rewards/rejected": -0.7441878318786621,
      "step": 610
    },
    {
      "epoch": 0.6636339309606636,
      "grad_norm": 3.742210865020752,
      "learning_rate": 1.8922155688622755e-07,
      "logits/chosen": 1.6589767932891846,
      "logits/rejected": 1.8133440017700195,
      "logps/chosen": -89.32723236083984,
      "logps/rejected": -76.06159973144531,
      "loss": 0.20550999641418458,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7368818521499634,
      "rewards/margins": 1.5121421813964844,
      "rewards/rejected": -0.7752603888511658,
      "step": 620
    },
    {
      "epoch": 0.6743377040406744,
      "grad_norm": 4.017214298248291,
      "learning_rate": 1.8323353293413174e-07,
      "logits/chosen": 1.6206018924713135,
      "logits/rejected": 1.7920303344726562,
      "logps/chosen": -90.67207336425781,
      "logps/rejected": -77.31306457519531,
      "loss": 0.21603720188140868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6743212938308716,
      "rewards/margins": 1.465144395828247,
      "rewards/rejected": -0.7908230423927307,
      "step": 630
    },
    {
      "epoch": 0.6850414771206851,
      "grad_norm": 3.9977710247039795,
      "learning_rate": 1.772455089820359e-07,
      "logits/chosen": 1.6604582071304321,
      "logits/rejected": 1.765606164932251,
      "logps/chosen": -89.44172668457031,
      "logps/rejected": -75.43511199951172,
      "loss": 0.2071392059326172,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.721622109413147,
      "rewards/margins": 1.5116666555404663,
      "rewards/rejected": -0.7900444269180298,
      "step": 640
    },
    {
      "epoch": 0.6957452502006958,
      "grad_norm": 4.089716911315918,
      "learning_rate": 1.7125748502994012e-07,
      "logits/chosen": 1.7000808715820312,
      "logits/rejected": 1.7932088375091553,
      "logps/chosen": -85.01210021972656,
      "logps/rejected": -77.24175262451172,
      "loss": 0.18689823150634766,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8071044683456421,
      "rewards/margins": 1.6235519647598267,
      "rewards/rejected": -0.8164474368095398,
      "step": 650
    },
    {
      "epoch": 0.7064490232807065,
      "grad_norm": 3.6210379600524902,
      "learning_rate": 1.6526946107784431e-07,
      "logits/chosen": 1.6398051977157593,
      "logits/rejected": 1.7796825170516968,
      "logps/chosen": -86.80577850341797,
      "logps/rejected": -77.27589416503906,
      "loss": 0.19279305934906005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7563915252685547,
      "rewards/margins": 1.5926845073699951,
      "rewards/rejected": -0.8362929224967957,
      "step": 660
    },
    {
      "epoch": 0.7171527963607172,
      "grad_norm": 3.9529213905334473,
      "learning_rate": 1.5928143712574848e-07,
      "logits/chosen": 1.7460943460464478,
      "logits/rejected": 1.8258304595947266,
      "logps/chosen": -98.23575592041016,
      "logps/rejected": -76.99598693847656,
      "loss": 0.1919611692428589,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7715954184532166,
      "rewards/margins": 1.5986343622207642,
      "rewards/rejected": -0.8270389437675476,
      "step": 670
    },
    {
      "epoch": 0.7278565694407279,
      "grad_norm": 3.5018908977508545,
      "learning_rate": 1.532934131736527e-07,
      "logits/chosen": 1.6938632726669312,
      "logits/rejected": 1.8514385223388672,
      "logps/chosen": -85.4283218383789,
      "logps/rejected": -78.03507995605469,
      "loss": 0.17897313833236694,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8028625249862671,
      "rewards/margins": 1.670284628868103,
      "rewards/rejected": -0.8674219846725464,
      "step": 680
    },
    {
      "epoch": 0.7385603425207385,
      "grad_norm": 3.679431438446045,
      "learning_rate": 1.473053892215569e-07,
      "logits/chosen": 1.6237990856170654,
      "logits/rejected": 1.7360966205596924,
      "logps/chosen": -90.28801727294922,
      "logps/rejected": -77.64337158203125,
      "loss": 0.18079785108566285,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8136262893676758,
      "rewards/margins": 1.6724271774291992,
      "rewards/rejected": -0.858801007270813,
      "step": 690
    },
    {
      "epoch": 0.7492641156007492,
      "grad_norm": 3.516465425491333,
      "learning_rate": 1.4131736526946105e-07,
      "logits/chosen": 1.6429712772369385,
      "logits/rejected": 1.8131242990493774,
      "logps/chosen": -84.39461517333984,
      "logps/rejected": -77.83858489990234,
      "loss": 0.1791899561882019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7975876927375793,
      "rewards/margins": 1.665416955947876,
      "rewards/rejected": -0.8678292036056519,
      "step": 700
    },
    {
      "epoch": 0.7599678886807599,
      "grad_norm": 3.3045990467071533,
      "learning_rate": 1.3532934131736525e-07,
      "logits/chosen": 1.6624534130096436,
      "logits/rejected": 1.8063266277313232,
      "logps/chosen": -90.40947723388672,
      "logps/rejected": -77.40106964111328,
      "loss": 0.17521259784698487,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.816781222820282,
      "rewards/margins": 1.6919959783554077,
      "rewards/rejected": -0.8752147555351257,
      "step": 710
    },
    {
      "epoch": 0.7706716617607706,
      "grad_norm": 3.4477410316467285,
      "learning_rate": 1.2934131736526946e-07,
      "logits/chosen": 1.650292158126831,
      "logits/rejected": 1.8019483089447021,
      "logps/chosen": -83.9959716796875,
      "logps/rejected": -77.94789123535156,
      "loss": 0.17583982944488524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8055136799812317,
      "rewards/margins": 1.6987024545669556,
      "rewards/rejected": -0.8931888341903687,
      "step": 720
    },
    {
      "epoch": 0.7813754348407814,
      "grad_norm": 3.5863077640533447,
      "learning_rate": 1.2335329341317366e-07,
      "logits/chosen": 1.6421613693237305,
      "logits/rejected": 1.7533458471298218,
      "logps/chosen": -90.31140899658203,
      "logps/rejected": -79.08738708496094,
      "loss": 0.1718185544013977,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8132683634757996,
      "rewards/margins": 1.7263119220733643,
      "rewards/rejected": -0.9130433201789856,
      "step": 730
    },
    {
      "epoch": 0.7920792079207921,
      "grad_norm": 3.1579439640045166,
      "learning_rate": 1.1736526946107785e-07,
      "logits/chosen": 1.6607577800750732,
      "logits/rejected": 1.7409274578094482,
      "logps/chosen": -97.76799011230469,
      "logps/rejected": -78.4072036743164,
      "loss": 0.16351721286773682,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8612265586853027,
      "rewards/margins": 1.7746206521987915,
      "rewards/rejected": -0.9133938550949097,
      "step": 740
    },
    {
      "epoch": 0.8027829810008028,
      "grad_norm": 3.3917667865753174,
      "learning_rate": 1.1137724550898203e-07,
      "logits/chosen": 1.7239021062850952,
      "logits/rejected": 1.7184594869613647,
      "logps/chosen": -93.31367492675781,
      "logps/rejected": -77.8096923828125,
      "loss": 0.16629836559295655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8352745175361633,
      "rewards/margins": 1.7561897039413452,
      "rewards/rejected": -0.9209151268005371,
      "step": 750
    },
    {
      "epoch": 0.8134867540808135,
      "grad_norm": 2.9782934188842773,
      "learning_rate": 1.0538922155688622e-07,
      "logits/chosen": 1.559645652770996,
      "logits/rejected": 1.7295551300048828,
      "logps/chosen": -91.24736022949219,
      "logps/rejected": -77.59309387207031,
      "loss": 0.15688105821609497,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8657901883125305,
      "rewards/margins": 1.8162992000579834,
      "rewards/rejected": -0.950509250164032,
      "step": 760
    },
    {
      "epoch": 0.8241905271608242,
      "grad_norm": 3.1906344890594482,
      "learning_rate": 9.940119760479042e-08,
      "logits/chosen": 1.6434297561645508,
      "logits/rejected": 1.7649013996124268,
      "logps/chosen": -93.21443939208984,
      "logps/rejected": -79.16569519042969,
      "loss": 0.16696513891220094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8058477640151978,
      "rewards/margins": 1.7533737421035767,
      "rewards/rejected": -0.9475258588790894,
      "step": 770
    },
    {
      "epoch": 0.8348943002408349,
      "grad_norm": 3.122718095779419,
      "learning_rate": 9.34131736526946e-08,
      "logits/chosen": 1.6120332479476929,
      "logits/rejected": 1.833191156387329,
      "logps/chosen": -91.796875,
      "logps/rejected": -77.71040344238281,
      "loss": 0.16888495683670043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.821872889995575,
      "rewards/margins": 1.7490304708480835,
      "rewards/rejected": -0.9271574020385742,
      "step": 780
    },
    {
      "epoch": 0.8455980733208456,
      "grad_norm": 2.952974796295166,
      "learning_rate": 8.74251497005988e-08,
      "logits/chosen": 1.5732994079589844,
      "logits/rejected": 1.7493925094604492,
      "logps/chosen": -84.50822448730469,
      "logps/rejected": -78.16481018066406,
      "loss": 0.16264578104019164,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8299948573112488,
      "rewards/margins": 1.7981436252593994,
      "rewards/rejected": -0.9681485891342163,
      "step": 790
    },
    {
      "epoch": 0.8563018464008563,
      "grad_norm": 2.9119694232940674,
      "learning_rate": 8.143712574850298e-08,
      "logits/chosen": 1.6357166767120361,
      "logits/rejected": 1.6843302249908447,
      "logps/chosen": -91.07951354980469,
      "logps/rejected": -78.93928527832031,
      "loss": 0.16092780828475953,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8587906956672668,
      "rewards/margins": 1.7980623245239258,
      "rewards/rejected": -0.9392717480659485,
      "step": 800
    },
    {
      "epoch": 0.867005619480867,
      "grad_norm": 2.8930296897888184,
      "learning_rate": 7.544910179640718e-08,
      "logits/chosen": 1.6567445993423462,
      "logits/rejected": 1.7973569631576538,
      "logps/chosen": -89.31910705566406,
      "logps/rejected": -78.03697204589844,
      "loss": 0.16231664419174194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8493439555168152,
      "rewards/margins": 1.7839206457138062,
      "rewards/rejected": -0.9345768094062805,
      "step": 810
    },
    {
      "epoch": 0.8777093925608777,
      "grad_norm": 3.118067502975464,
      "learning_rate": 6.946107784431138e-08,
      "logits/chosen": 1.7217321395874023,
      "logits/rejected": 1.8631649017333984,
      "logps/chosen": -91.07904815673828,
      "logps/rejected": -78.59831237792969,
      "loss": 0.16403938531875611,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8252221941947937,
      "rewards/margins": 1.7777063846588135,
      "rewards/rejected": -0.952484130859375,
      "step": 820
    },
    {
      "epoch": 0.8884131656408885,
      "grad_norm": 3.660428285598755,
      "learning_rate": 6.347305389221556e-08,
      "logits/chosen": 1.6176328659057617,
      "logits/rejected": 1.811462163925171,
      "logps/chosen": -83.60496520996094,
      "logps/rejected": -79.38194274902344,
      "loss": 0.16004878282546997,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.823939323425293,
      "rewards/margins": 1.7976806163787842,
      "rewards/rejected": -0.9737415313720703,
      "step": 830
    },
    {
      "epoch": 0.8991169387208992,
      "grad_norm": 2.6750118732452393,
      "learning_rate": 5.748502994011976e-08,
      "logits/chosen": 1.6818653345108032,
      "logits/rejected": 1.7683902978897095,
      "logps/chosen": -93.53028106689453,
      "logps/rejected": -77.9053955078125,
      "loss": 0.15739890336990356,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8485782742500305,
      "rewards/margins": 1.8211606740951538,
      "rewards/rejected": -0.9725824594497681,
      "step": 840
    },
    {
      "epoch": 0.9098207118009098,
      "grad_norm": 2.760943651199341,
      "learning_rate": 5.149700598802395e-08,
      "logits/chosen": 1.6855487823486328,
      "logits/rejected": 1.756536841392517,
      "logps/chosen": -93.0840072631836,
      "logps/rejected": -78.27250671386719,
      "loss": 0.15378832817077637,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8769612312316895,
      "rewards/margins": 1.8450706005096436,
      "rewards/rejected": -0.9681097269058228,
      "step": 850
    },
    {
      "epoch": 0.9205244848809205,
      "grad_norm": 2.9874212741851807,
      "learning_rate": 4.550898203592814e-08,
      "logits/chosen": 1.637730598449707,
      "logits/rejected": 1.7964423894882202,
      "logps/chosen": -83.2845687866211,
      "logps/rejected": -78.23328399658203,
      "loss": 0.16114977598190308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8081039190292358,
      "rewards/margins": 1.777475357055664,
      "rewards/rejected": -0.9693711996078491,
      "step": 860
    },
    {
      "epoch": 0.9312282579609312,
      "grad_norm": 3.1285641193389893,
      "learning_rate": 3.952095808383234e-08,
      "logits/chosen": 1.6463534832000732,
      "logits/rejected": 1.818142294883728,
      "logps/chosen": -92.14315032958984,
      "logps/rejected": -79.90022277832031,
      "loss": 0.15873039960861207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.841383159160614,
      "rewards/margins": 1.8344987630844116,
      "rewards/rejected": -0.9931157827377319,
      "step": 870
    },
    {
      "epoch": 0.9419320310409419,
      "grad_norm": 3.8471076488494873,
      "learning_rate": 3.3532934131736525e-08,
      "logits/chosen": 1.6600271463394165,
      "logits/rejected": 1.8145549297332764,
      "logps/chosen": -89.87852478027344,
      "logps/rejected": -78.64590454101562,
      "loss": 0.16178345680236816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.7972803711891174,
      "rewards/margins": 1.787512183189392,
      "rewards/rejected": -0.9902318120002747,
      "step": 880
    },
    {
      "epoch": 0.9526358041209526,
      "grad_norm": 2.8688671588897705,
      "learning_rate": 2.7544910179640717e-08,
      "logits/chosen": 1.640127420425415,
      "logits/rejected": 1.7319669723510742,
      "logps/chosen": -99.06453704833984,
      "logps/rejected": -79.49870300292969,
      "loss": 0.1597280979156494,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8135381937026978,
      "rewards/margins": 1.816394567489624,
      "rewards/rejected": -1.0028564929962158,
      "step": 890
    },
    {
      "epoch": 0.9633395772009633,
      "grad_norm": 3.285233497619629,
      "learning_rate": 2.155688622754491e-08,
      "logits/chosen": 1.633610486984253,
      "logits/rejected": 1.8035800457000732,
      "logps/chosen": -83.26371002197266,
      "logps/rejected": -79.34373474121094,
      "loss": 0.14476956129074098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.9087934494018555,
      "rewards/margins": 1.907961130142212,
      "rewards/rejected": -0.9991677403450012,
      "step": 900
    },
    {
      "epoch": 0.974043350280974,
      "grad_norm": 2.965737819671631,
      "learning_rate": 1.55688622754491e-08,
      "logits/chosen": 1.6408655643463135,
      "logits/rejected": 1.8063045740127563,
      "logps/chosen": -86.9333267211914,
      "logps/rejected": -79.36103820800781,
      "loss": 0.15842496156692504,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8349052667617798,
      "rewards/margins": 1.8204656839370728,
      "rewards/rejected": -0.985560417175293,
      "step": 910
    },
    {
      "epoch": 0.9847471233609848,
      "grad_norm": 3.277984380722046,
      "learning_rate": 9.580838323353294e-09,
      "logits/chosen": 1.748547911643982,
      "logits/rejected": 1.8139140605926514,
      "logps/chosen": -98.62623596191406,
      "logps/rejected": -79.23570251464844,
      "loss": 0.15010402202606202,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.890489935874939,
      "rewards/margins": 1.8733657598495483,
      "rewards/rejected": -0.9828759431838989,
      "step": 920
    },
    {
      "epoch": 0.9954508964409955,
      "grad_norm": 2.854753017425537,
      "learning_rate": 3.592814371257485e-09,
      "logits/chosen": 1.6423447132110596,
      "logits/rejected": 1.7708911895751953,
      "logps/chosen": -86.49864959716797,
      "logps/rejected": -79.13391876220703,
      "loss": 0.15120308399200438,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.8650370836257935,
      "rewards/margins": 1.8596649169921875,
      "rewards/rejected": -0.9946276545524597,
      "step": 930
    }
  ],
  "logging_steps": 10,
  "max_steps": 935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
